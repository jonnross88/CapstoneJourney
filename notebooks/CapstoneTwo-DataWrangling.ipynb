{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This project is part of a Capstone project for Springboard Data Science Career Track.\n",
    "\n",
    "The goal of this project is to develop a machine learning model to rank and predict the likelihood that an oil company will initiate a frac job in a county within the Permian Basin in the first quarter of 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.1.min.js\", \"https://cdn.holoviz.org/panel/1.3.1/dist/panel.min.js\", \"https://cdn.jsdelivr.net/npm/@holoviz/geoviews@1.11.0/dist/geoviews.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1005'>\n",
       "  <div id=\"d133382c-212c-4c6e-ab51-d9eebd67201f\" data-root-id=\"p1005\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"44d35509-909e-41a4-a7e6-e643120dc335\":{\"version\":\"3.3.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1005\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1006\",\"attributes\":{\"plot_id\":\"p1005\",\"comm_id\":\"40b5d2a367fb4ca0b2857b0a5aab03b0\",\"client_comm_id\":\"4f338ce4117e4ba1bd5f1a086bd933a5\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"toggle_value1\",\"properties\":[{\"name\":\"active_icons\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"options\",\"kind\":\"Any\",\"default\":{\"type\":\"map\",\"entries\":[[\"favorite\",\"heart\"]]}},{\"name\":\"value\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"_reactions\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"_base_url\",\"kind\":\"Any\",\"default\":\"https://tabler-icons.io/static/tabler-icons/icons/\"}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"value\",\"kind\":\"Any\",\"default\":null},{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"44d35509-909e-41a4-a7e6-e643120dc335\",\"roots\":{\"p1005\":\"d133382c-212c-4c6e-ab51-d9eebd67201f\"},\"root_ids\":[\"p1005\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1005"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.jsdelivr.net/npm/@holoviz/geoviews@1.11.0/dist/geoviews.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.jsdelivr.net/npm/@holoviz/geoviews@1.11.0/dist/geoviews.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.1/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.1/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.3.1/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/1.3.1/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.jsdelivr.net/npm/@holoviz/geoviews@1.11.0/dist/geoviews.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.3.1/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\".tabulator{position:relative;border:1px solid #999;font-size:14px;text-align:left;overflow:hidden;-webkit-transform:translateZ(0);-moz-transform:translateZ(0);-ms-transform:translateZ(0);-o-transform:translateZ(0);transform:translateZ(0)}.tabulator[tabulator-layout=fitDataFill] .tabulator-tableholder .tabulator-table{min-width:100%}.tabulator[tabulator-layout=fitDataTable]{display:inline-block}.tabulator.tabulator-block-select{user-select:none}.tabulator .tabulator-header{position:relative;box-sizing:border-box;width:100%;border-bottom:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;overflow:hidden;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-header.tabulator-header-hidden{display:none}.tabulator .tabulator-header .tabulator-header-contents{position:relative;overflow:hidden}.tabulator .tabulator-header .tabulator-header-contents .tabulator-headers{display:inline-block}.tabulator .tabulator-header .tabulator-col{display:inline-flex;position:relative;box-sizing:border-box;flex-direction:column;justify-content:flex-start;border-right:1px solid #ddd;background:#fff;text-align:left;vertical-align:bottom;overflow:hidden}.tabulator .tabulator-header .tabulator-col.tabulator-moving{position:absolute;border:1px solid #999;background:#e6e6e6;pointer-events:none}.tabulator .tabulator-header .tabulator-col .tabulator-col-content{box-sizing:border-box;position:relative;padding:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button{padding:0 8px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button:hover{cursor:pointer;opacity:.6}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title-holder{position:relative}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title{box-sizing:border-box;width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title.tabulator-col-title-wrap{white-space:normal;text-overflow:clip}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-title-editor{box-sizing:border-box;width:100%;border:1px solid #999;padding:1px;background:#fff}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-header-popup-button+.tabulator-title-editor{width:calc(100% - 22px)}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{display:flex;align-items:center;position:absolute;top:0;bottom:0;right:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{width:0;height:0;border-left:6px solid transparent;border-right:6px solid transparent;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{position:relative;display:flex;border-top:1px solid #ddd;overflow:hidden;margin-right:-1px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter{position:relative;box-sizing:border-box;margin-top:2px;width:100%;text-align:center}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter textarea{height:auto!important}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter svg{margin-top:3px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter input::-ms-clear{width:0;height:0}.tabulator .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:25px}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable.tabulator-col-sorter-element:hover{cursor:pointer;background-color:#e6e6e6}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter{color:#bbb}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #666}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-top:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-bottom:none;border-top:6px solid #666;color:#666}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical .tabulator-col-content .tabulator-col-title{writing-mode:vertical-rl;text-orientation:mixed;display:flex;align-items:center;justify-content:center}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-col-vertical-flip .tabulator-col-title{transform:rotate(180deg)}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-title{padding-right:0;padding-top:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable.tabulator-col-vertical-flip .tabulator-col-title{padding-right:0;padding-bottom:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-sorter{justify-content:center;left:0;right:0;top:4px;bottom:auto}.tabulator .tabulator-header .tabulator-frozen{position:sticky;left:0;z-index:10}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder{box-sizing:border-box;background:#fff!important;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#fff!important}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle,.tabulator .tabulator-header .tabulator-frozen-rows-holder:empty{display:none}.tabulator .tabulator-tableholder{position:relative;width:100%;white-space:nowrap;overflow:auto;-webkit-overflow-scrolling:touch}.tabulator .tabulator-tableholder:focus{outline:none}.tabulator .tabulator-tableholder .tabulator-placeholder{box-sizing:border-box;display:flex;align-items:center;justify-content:center;width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder[tabulator-render-mode=virtual]{min-height:100%;min-width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder .tabulator-placeholder-contents{display:inline-block;text-align:center;padding:10px;color:#ccc;font-weight:700;font-size:20px;white-space:normal}.tabulator .tabulator-tableholder .tabulator-table{position:relative;display:inline-block;background-color:#fff;white-space:nowrap;overflow:visible;color:#333}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs{font-weight:700;background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-top{border-bottom:2px solid #ddd}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-bottom{border-top:2px solid #ddd}.tabulator .tabulator-footer{border-top:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;user-select:none;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-footer .tabulator-footer-contents{display:flex;flex-direction:row;align-items:center;justify-content:space-between;padding:5px 10px}.tabulator .tabulator-footer .tabulator-footer-contents:empty{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder{box-sizing:border-box;width:100%;text-align:left;background:#fff!important;border-bottom:1px solid #ddd;border-top:1px solid #ddd;overflow:hidden}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{display:inline-block;background:#fff!important}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder:only-child{margin-bottom:-5px;border-bottom:none}.tabulator .tabulator-footer>*+.tabulator-page-counter{margin-left:10px}.tabulator .tabulator-footer .tabulator-page-counter{font-weight:400}.tabulator .tabulator-footer .tabulator-paginator{flex:1;text-align:right;color:#555;font-family:inherit;font-weight:inherit;font-size:inherit}.tabulator .tabulator-footer .tabulator-page-size{display:inline-block;margin:0 5px;padding:2px 5px;border:1px solid #aaa;border-radius:3px}.tabulator .tabulator-footer .tabulator-pages{margin:0 7px}.tabulator .tabulator-footer .tabulator-page{display:inline-block;margin:0 2px;padding:2px 5px;border:1px solid #aaa;border-radius:3px;background:hsla(0,0%,100%,.2)}.tabulator .tabulator-footer .tabulator-page.active{color:#d00}.tabulator .tabulator-footer .tabulator-page:disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-footer .tabulator-page:not(.disabled):hover{cursor:pointer;background:rgba(0,0,0,.2);color:#fff}}.tabulator .tabulator-col-resize-handle{position:relative;display:inline-block;width:6px;margin-left:-3px;margin-right:-3px;z-index:10;vertical-align:middle}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-col-resize-handle:hover{cursor:ew-resize}}.tabulator .tabulator-col-resize-handle:last-of-type{width:3px;margin-right:0}.tabulator .tabulator-alert{position:absolute;display:flex;align-items:center;top:0;left:0;z-index:100;height:100%;width:100%;background:rgba(0,0,0,.4);text-align:center}.tabulator .tabulator-alert .tabulator-alert-msg{display:inline-block;margin:0 auto;padding:10px 20px;border-radius:10px;background:#fff;font-weight:700;font-size:16px}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-msg{border:4px solid #333;color:#000}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-error{border:4px solid #d00;color:#590000}.tabulator-row{position:relative;box-sizing:border-box;min-height:22px}.tabulator-row,.tabulator-row.tabulator-row-even{background-color:#fff}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selectable:hover{background-color:#bbb;cursor:pointer}}.tabulator-row.tabulator-selected{background-color:#9abcea}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selected:hover{background-color:#769bcc;cursor:pointer}}.tabulator-row.tabulator-row-moving{border:1px solid #000;background:#fff}.tabulator-row.tabulator-moving{position:absolute;border-top:1px solid #ddd;border-bottom:1px solid #ddd;pointer-events:none;z-index:15}.tabulator-row .tabulator-row-resize-handle{position:absolute;right:0;bottom:0;left:0;height:5px}.tabulator-row .tabulator-row-resize-handle.prev{top:0;bottom:auto}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-row-resize-handle:hover{cursor:ns-resize}}.tabulator-row .tabulator-responsive-collapse{box-sizing:border-box;padding:5px;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator-row .tabulator-responsive-collapse:empty{display:none}.tabulator-row .tabulator-responsive-collapse table{font-size:14px}.tabulator-row .tabulator-responsive-collapse table tr td{position:relative}.tabulator-row .tabulator-responsive-collapse table tr td:first-of-type{padding-right:10px}.tabulator-row .tabulator-cell{display:inline-block;position:relative;box-sizing:border-box;padding:4px;border-right:1px solid #ddd;vertical-align:middle;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tabulator-row .tabulator-cell.tabulator-frozen{display:inline-block;position:sticky;left:0;background-color:inherit;z-index:10}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-editing{border:1px solid #1d68cd;outline:none;padding:0}.tabulator-row .tabulator-cell.tabulator-editing input,.tabulator-row .tabulator-cell.tabulator-editing select{border:1px;background:transparent;outline:none}.tabulator-row .tabulator-cell.tabulator-validation-fail{border:1px solid #d00}.tabulator-row .tabulator-cell.tabulator-validation-fail input,.tabulator-row .tabulator-cell.tabulator-validation-fail select{border:1px;background:transparent;color:#d00}.tabulator-row .tabulator-cell.tabulator-row-handle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box{width:80%}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box .tabulator-row-handle-bar{width:100%;height:3px;margin-top:2px;background:#666}.tabulator-row .tabulator-cell .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-row .tabulator-cell .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none;height:15px;width:15px;border-radius:20px;background:#666;color:#fff;font-weight:700;font-size:1.1em}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle:hover{opacity:.7;cursor:pointer}}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-close{display:initial}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-open{display:none}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle svg{stroke:#fff}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle .tabulator-responsive-collapse-toggle-close{display:none}.tabulator-row .tabulator-cell .tabulator-traffic-light{display:inline-block;height:14px;width:14px;border-radius:14px}.tabulator-row.tabulator-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-row.tabulator-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-row.tabulator-group.tabulator-group-level-1{padding-left:30px}.tabulator-row.tabulator-group.tabulator-group-level-2{padding-left:50px}.tabulator-row.tabulator-group.tabulator-group-level-3{padding-left:70px}.tabulator-row.tabulator-group.tabulator-group-level-4{padding-left:90px}.tabulator-row.tabulator-group.tabulator-group-level-5{padding-left:110px}.tabulator-row.tabulator-group .tabulator-group-toggle{display:inline-block}.tabulator-row.tabulator-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-row.tabulator-group span{margin-left:10px;color:#d00}.tabulator-popup-container{position:absolute;display:inline-block;box-sizing:border-box;background:#fff;border:1px solid #ddd;box-shadow:0 0 5px 0 rgba(0,0,0,.2);font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch;z-index:10000}.tabulator-popup{padding:5px;border-radius:3px}.tabulator-tooltip{max-width:Min(500px,100%);padding:3px 5px;border-radius:2px;box-shadow:none;font-size:12px;pointer-events:none}.tabulator-menu .tabulator-menu-item{position:relative;box-sizing:border-box;padding:5px 10px;user-select:none}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator-menu .tabulator-menu-item:not(.tabulator-menu-item-disabled):hover{cursor:pointer;background:#fff}}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu{padding-right:25px}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu:after{display:inline-block;position:absolute;top:calc(5px + .4em);right:10px;height:7px;width:7px;content:\\\"\\\";border-color:#ddd;border-style:solid;border-width:1px 1px 0 0;vertical-align:top;transform:rotate(45deg)}.tabulator-menu .tabulator-menu-separator{border-top:1px solid #ddd}.tabulator-edit-list{max-height:200px;font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch}.tabulator-edit-list .tabulator-edit-list-item{padding:4px;color:#333;outline:none}.tabulator-edit-list .tabulator-edit-list-item.active{color:#fff;background:#1d68cd}.tabulator-edit-list .tabulator-edit-list-item.active.focused{outline:1px solid hsla(0,0%,100%,.5)}.tabulator-edit-list .tabulator-edit-list-item.focused{outline:1px solid #1d68cd}@media (hover:hover) and (pointer:fine){.tabulator-edit-list .tabulator-edit-list-item:hover{cursor:pointer;color:#fff;background:#1d68cd}}.tabulator-edit-list .tabulator-edit-list-placeholder{padding:4px;color:#333;text-align:center}.tabulator-edit-list .tabulator-edit-list-group{border-bottom:1px solid #ddd;padding:6px 4px 4px;color:#333;font-weight:700}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-2,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-2{padding-left:12px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-3,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-3{padding-left:20px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-4,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-4{padding-left:28px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-5,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-5{padding-left:36px}.tabulator.tabulator-ltr{direction:ltr}.tabulator.tabulator-rtl{text-align:initial;direction:rtl}.tabulator.tabulator-rtl .tabulator-header .tabulator-col{text-align:initial;border-left:1px solid #ddd;border-right:initial}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{margin-right:0;margin-left:-1px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:0;padding-left:25px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{left:8px;right:auto}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell{border-right:initial;border-left:1px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-branch{margin-right:0;margin-left:5px;border-bottom-left-radius:0;border-bottom-right-radius:1px;border-left:initial;border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-control{margin-right:0;margin-left:5px}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-left:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-col-resize-handle:last-of-type{width:3px;margin-left:0;margin-right:-3px}.tabulator.tabulator-rtl .tabulator-footer .tabulator-calcs-holder{text-align:initial}.tabulator-print-fullscreen{position:absolute;top:0;bottom:0;left:0;right:0;z-index:10000}body.tabulator-print-fullscreen-hide>:not(.tabulator-print-fullscreen){display:none!important}.tabulator-print-table{border-collapse:collapse}.tabulator-print-table .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-print-table .tabulator-print-table-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-print-table-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-print-table .tabulator-print-table-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-1 td{padding-left:30px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-2 td{padding-left:50px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-3 td{padding-left:70px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-4 td{padding-left:90px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-5 td{padding-left:110px!important}.tabulator-print-table .tabulator-print-table-group .tabulator-group-toggle{display:inline-block}.tabulator-print-table .tabulator-print-table-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-print-table .tabulator-print-table-group span{color:#d00}.tabulator-print-table .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator{border:none;background-color:#fff}.tabulator .tabulator-header .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #999}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-placeholder span{color:#000}.tabulator .tabulator-footer .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #fff}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator-row{border-bottom:1px solid #ddd}.tabulator-row .tabulator-cell:last-of-type{border-right:none}.tabulator-row.tabulator-group span{color:#666}.tabulator-print-table .tabulator-print-table-group span{margin-left:10px;color:#666}\\n/*# sourceMappingURL=tabulator_simple.min.css.map */\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import statements\n",
    "\n",
    "from collections import defaultdict\n",
    "from http.client import IncompleteRead\n",
    "from time import sleep\n",
    "import concurrent.futures as cf\n",
    "from datetime import datetime\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import tempfile\n",
    "import warnings\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import URLError\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import missingno as msno\n",
    "import cartopy.crs as ccrs\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "import geoviews as gv\n",
    "import geoviews.tile_sources as gts\n",
    "import colorcet as cc\n",
    "import holoviews as hv\n",
    "import hvplot.pandas  # noqa\n",
    "import hvplot.dask  # noqa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj\n",
    "from fiona.io import ZipMemoryFile\n",
    "from pyvis.network import Network\n",
    "\n",
    "# from sqlalchemy import create_engine\n",
    "# from sqlalchemy.exc import SQLAlchemyError\n",
    "from tqdm import tqdm\n",
    "import dask\n",
    "from dask import persist\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "from panel.template import FastListTemplate\n",
    "\n",
    "hv.extension(\"bokeh\")\n",
    "gv.extension(\"bokeh\")\n",
    "pn.extension(\"tabulator\", template=\"fast\", sizing_mode=\"stretch_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CapstoneJourney begins!\n"
     ]
    }
   ],
   "source": [
    "# Test initial print statement\n",
    "print(\"CapstoneJourney begins!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants\n",
    "Let's start by defining some constants that will be used throughout this notebook.\n",
    "\n",
    "Most of the data was first downloaded from external websites and then uploaded onto a cloud storage bucket. This was done to ensure consistency and availability during the project. A brief description of the data and its original source link is referenced below.\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "The following table provides an overview of the data sources used in this project:\n",
    "\n",
    "| Dataset Name | Source URL | Original Source | Description | Date Downloaded |\n",
    "|--------------|------------|-----------------|-------------|-----------------|\n",
    "| RegistryUpload Table | [link](https://fracfocus.org/data-download) | FracFocus | This table contains each disclosures header information such as the job date, API number, location, base water volume, and total vertical depth. | 2023-11-11 |\n",
    "| RBDMSWells | [link](https://gisdata-occokc.opendata.arcgis.com/datasets/OCCOKC::rbdms-wells/about) | Oklahoma Corporation Commission | This table contains Oklahoma RBDMS statewide well data | 2023-11-23 |\n",
    "| Wolfcamp Delaware Play Boundary | [link](https://www.eia.gov/maps/maps.htm)| EIA | Permian Basin, Delaware Sub-Basin: Wolfcamp play boundary (9/4/2018) | 2023-11-19 |\n",
    "| Wolfcamp Midland Play Boundaries | [link](https://www.eia.gov/maps/maps.htm)| EIA | Wolfcamp A, B, C, and D play boundaries, Midland Basin (6/4/2020) | 2023-11-21 |\n",
    "| ShalePlay Delaware | [link](https://www.eia.gov/maps/maps.htm)| EIA |Delaware play boundary (10/8/2019)  | 2023-11-21 |\n",
    "| AboYeso GlorietaYeso Spraberry | [link](https://www.eia.gov/maps/maps.htm)| EIA | Abo-Yeso, Glorieta-Yeso, and Spraberry play boundaries (3/11/2016) | 2023-11-21 |\n",
    "| NM SLO OilGas Leases | [link](https://www.nmstatelands.org/maps-gis/gis-data-download/)| New Mexico State Land Office | Active Oil and Gas Leases (11/07/2023) | 2023-11-21 |\n",
    "| NM SLO Geologic Regions | [link](https://www.nmstatelands.org/maps-gis/gis-data-download/)| New Mexico State Land Office | Geologic Regions (01/04/2010) | 2023-11-21 |\n",
    "| NM SLO STL Status Combined | [link](https://www.nmstatelands.org/maps-gis/gis-data-download/)| New Mexico State Land Office | New Mexico State Trust Lands By Subdivision (04/14/2022) | 2023-11-21 |\n",
    "| Production Data Query Dump| [link](https://rrc.texas.gov/resource-center/research/data-sets-available-for-download/)| Railroad Commission of Texas | Production Data Query Dump (11/17/2023) | 2023-11-17 |\n",
    "| All Layers By County | [link](https://rrc.texas.gov/resource-center/research/data-sets-available-for-download/)  | Railroad Commission of Texas | Map & Associated Data: Base Map, Wells, Surveys & Pipelines layers | 2023-11-17 |\n",
    "| Oil & Gas Leases | [link](https://www.glo.texas.gov/land/land-management/gis/index.html) | Texas General Land Office | Active Leases (11/17/2023) | 2023-11-17 |\n",
    "| Oil & Gas Units | [link](https://www.glo.texas.gov/land/land-management/gis/index.html) | Texas General Land Office | Active Units (11/17/2023) | 2023-11-17 |\n",
    "| U.S. County Boundaries | [link](https://www2.census.gov/geo/tiger/TIGER2022/COUNTY/tl_2022_us_county.zip) | United States Census Bureau | County (2022-10-31). Data is downloaded directly in the code. | N/A |\n",
    "| U.S. County FIPS Codes | [link](https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county) | Wikipedia | List of United States FIPS codes by county. Data is downloaded directly in the code. | N/A |\n",
    "\n",
    "Each row in the table represents a different dataset. The columns are:\n",
    "\n",
    "- **Dataset Name**: The name of the dataset.\n",
    "- **Source URL**: The URL where the dataset can be downloaded. Click on \"link\" to access the webpage.\n",
    "- **Original Source**: The original source of the data.\n",
    "- **Description**: A brief description of the dataset.\n",
    "- **Date Downloaded**: The date when the dataset was downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "# This cell generates lists of URLs to CSV files stored in a Google Cloud Storage bucket.\n",
    "# The CSV files contain data from the FracFocus Chemical Disclosure Registry.\n",
    "\n",
    "# Generate a list of URLs to the FracFocusRegistry CSV files.\n",
    "# There are 24 files in total, named FracFocusRegistry_i.csv where i ranges from 1 to 24.\n",
    "DATA_URLS1 = [\n",
    "    f\"https://storage.googleapis.com/mrprime_dataset/fracfocus/FracFocusRegistry_{i}.csv\"\n",
    "    for i in range(1, 25)\n",
    "]\n",
    "\n",
    "# Generate a list of URLs to the registryupload CSV files.\n",
    "# There are 3 files in total, named registryupload_i.csv where i ranges from 1 to 3.\n",
    "DATA_URLS2 = [\n",
    "    f\"https://storage.googleapis.com/mrprime_dataset/fracfocus/registryupload_{j}.csv\"\n",
    "    for j in range(1, 4)\n",
    "]\n",
    "\n",
    "# URL to the readme.txt file in the bucket.\n",
    "DATA_README_URL = [\n",
    "    \"https://storage.googleapis.com/mrprime_dataset/fracfocus/readme.txt\"\n",
    "]\n",
    "\n",
    "# url to the OCC (Oklahoma) well data in th bucket\n",
    "OCC_PARQUET_URL = \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/occ/rbdms_wells.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Url for the shapefile for US counties from the Census Bureau's website.\n",
    "CENSUS_COUNTY_MAP_URL = (\n",
    "    \"https://www2.census.gov/geo/tiger/TIGER2022/COUNTY/tl_2022_us_county.zip\"\n",
    ")\n",
    "# Url for a Wikipedia page containing a table of FIPS codes for US counties.\n",
    "FIPS_WIKI_URL = (\n",
    "    \"https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county\"\n",
    ")\n",
    "# Bounds of the continental US in longitude and latitude.\n",
    "USA_BOUNDS = (-124.77, 24.52, -66.95, 49.38)\n",
    "# bounds of the continental US in Web Mercator coordinates.\n",
    "USA_BOUNDS_MERCATOR = (-13874905.0, 2870341.0, -7453304.0, 6338219.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# url for the shapefiles of Permian Basin, Delaware Sub-Basin: Wolfcamp play boundary\n",
    "WOLFCAMP_ZIP_URL = \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/eia/Wolfcamp_Delaware_Play_Boundary.zip\"\n",
    "MIDLAND_ZIP_URL = \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/eia/Wolfcamp_Midland_Play_Boundaries_EIA.zip\"\n",
    "DELAWARE_ZIP_URL = \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/eia/ShalePlay_Delaware_EIA.zip\"\n",
    "ABOYESO_ZIP_URL = \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/eia/ShalePlays_AboYeso_GlorietaYeso_Spraberry_EIA.zip\"\n",
    "# PB_ZIP_URL = \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/eia/PermianBasin_Boundary_Structural_Tectonic.zip\"\n",
    "\n",
    "basins_url_list = [\n",
    "    WOLFCAMP_ZIP_URL,\n",
    "    MIDLAND_ZIP_URL,\n",
    "    DELAWARE_ZIP_URL,\n",
    "    ABOYESO_ZIP_URL,\n",
    "    # PB_ZIP_URL,\n",
    "]\n",
    "\n",
    "\n",
    "# url for shapefiles of Polygon data set intended to delineate active oil and gas leases on New Mexico State Trust Lands.\n",
    "NM_SLO_OIL_LEASE_URL = \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/nm_slo/OilGas_Leases.zip\"\n",
    "\n",
    "# url for shapefiles of Polygon layer created to highlight general boundaries of subsurface geologic basins and uplifts of New Mexico\n",
    "NM_SLO_GEO_REGION_URL = \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/nm_slo/slo_GeologicRegions.zip\"\n",
    "# url for shapefiles of Polygons of New Mexico State Trust Lands by PLSS subdivision (quarter-quarter, lot, tract, or partial).\n",
    "NM_SLO_STL_PLSS_URL = \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/nm_slo/slo_STLStatusCombined.zip\"\n",
    "\n",
    "nm_slo_url_list = [\n",
    "    NM_SLO_OIL_LEASE_URL,\n",
    "    NM_SLO_GEO_REGION_URL,\n",
    "]  # , NM_SLO_STL_PLSS_URL]\n",
    "\n",
    "# Production data query for RRC website\n",
    "PDQ_URL = (\n",
    "    \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/PDQ_DSV.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Define a list of county numbers that we want to test. These numbers correspond to counties\n",
    "# that we did not include in the data folder, but they do not cover all 254 counties.\n",
    "\n",
    "# county numbers are only odd numbers\n",
    "county_nums = [str(i).zfill(3) for i in range(1, 508) if i % 2]\n",
    "\n",
    "# Generate a list of URLs to the shapefile zip files stored in a Google Cloud Storage bucket.\n",
    "# The zip files are named Shp{num}.zip, where {num} is a county number from the county_nums list.\n",
    "SHP_ZIP_URLS = [\n",
    "    f\"https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp{num}.zip\"\n",
    "    for num in county_nums\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# url for the active leases in Texas on State land gdb\n",
    "GDB_ZIP_URLS = [\n",
    "    \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/glo/GDB_ActiveLeases.zip\",\n",
    "    \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/glo/GDB_ActiveUnits.zip\",\n",
    "    # \"https://storage.googleapis.com/mrprime_dataset/capstone_journey/glo/GDB_InactiveLeases.zip\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions\n",
    "Next, let's define some functions that will be used throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def get_county_data():\n",
    "    county = gpd.read_file(CENSUS_COUNTY_MAP_URL)[\n",
    "        [\"GEOID\", \"STATEFP\", \"COUNTYFP\", \"NAME\", \"geometry\"]\n",
    "    ]\n",
    "    county.columns = county.columns.str.lower()\n",
    "    return county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def read_csv_concurrent(urls_list):\n",
    "    \"\"\"Reads a list of CSV files concurrently\"\"\"\n",
    "    # Create a thread pool\n",
    "    with cf.ThreadPoolExecutor() as executor:\n",
    "        # Use map to apply pd.read_csv to each URL\n",
    "        results = list(tqdm(executor.map(pd.read_csv, urls_list), total=len(urls_list)))\n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def extract_specific_gdf_from_local_zip(\n",
    "    zip_paths: list[str], regex_patterns: list[str]\n",
    ") -> dict[str, gpd.GeoDataFrame]:\n",
    "    \"\"\"\n",
    "    Reads shapefiles from a list of zip files and returns a dictionary\n",
    "    where the keys are the names of the shapefiles and the values are GeoDataFrames.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to store the GeoDataFrames\n",
    "    shp_dict = {}\n",
    "    # compile the regex patterns\n",
    "    patterns = [re.compile(pattern) for pattern in regex_patterns]\n",
    "\n",
    "    # Loop over the list of zip file paths\n",
    "    for zip_path in zip_paths:\n",
    "        # Open the zip file\n",
    "        with ZipFile(zip_path) as z:\n",
    "            # Get the list of files in the zip file\n",
    "            zip_contents = z.namelist()\n",
    "            # Filter the list to get only the shapefiles that match any of the patterns\n",
    "            shp_files = [\n",
    "                f\n",
    "                for f in zip_contents\n",
    "                for pattern in patterns\n",
    "                if pattern.search(f) and f.endswith(\".shp\")\n",
    "            ]\n",
    "            # read the shapefiles into GeoDataFrames\n",
    "            for shp_file in shp_files:\n",
    "                # Get the name of the shapefile\n",
    "                shp_name = Path(shp_file).stem\n",
    "                # Read the shapefile into a GeoDataFrame and add it to the dictionary\n",
    "                shp_dict[shp_name] = gpd.read_file(f\"zip://{zip_path}!{shp_file}\")\n",
    "    # Return the dictionary of GeoDataFrames\n",
    "    return shp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def extract_matching_shp_files_from_zip_urls(\n",
    "    zip_urls: list[str], regex_patterns: list[str]\n",
    ") -> dict[str, gpd.GeoDataFrame]:\n",
    "    \"\"\"\n",
    "    Reads shapefiles from a list of zip file urls and returns a dictionary\n",
    "    where the keys are the names of the shapefiles and the values are GeoDataFrames.\n",
    "    \"\"\"\n",
    "    # Initialize an empty dictionary to store the GeoDataFrames\n",
    "    shp_dict = {}\n",
    "    # compile the regex patterns\n",
    "    patterns = [re.compile(pattern) for pattern in regex_patterns]\n",
    "\n",
    "    # Loop over the list of zip file urls\n",
    "    for zip_url in tqdm(zip_urls, desc=\"Processing zip files\"):\n",
    "        # download the zip file\n",
    "        with urlopen(zip_url) as u:\n",
    "            zip_data = u.read()\n",
    "        # create a ZipMemoryFile from the zip data\n",
    "        with ZipMemoryFile(zip_data) as z:\n",
    "            # get the list of files in the zip file\n",
    "            zip_files = z.listdir()\n",
    "            # filter for shapefiles that match any of the patterns\n",
    "            shp_files = [\n",
    "                f\n",
    "                for f in zip_files\n",
    "                for pattern in patterns\n",
    "                if pattern.search(f) and f.endswith(\".shp\")\n",
    "            ]\n",
    "            # read the shapefiles into GeoDataFrames\n",
    "            for shp_file in shp_files:\n",
    "                with z.open(shp_file) as f:\n",
    "                    shp_dict[Path(shp_file).stem] = gpd.GeoDataFrame.from_features(\n",
    "                        f, crs=f.crs\n",
    "                    )\n",
    "    # Return the dictionary of GeoDataFrames\n",
    "    return shp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def process_zip_url(\n",
    "    zip_url: str, patterns: list[re.Pattern]\n",
    ") -> Optional[dict[str, gpd.GeoDataFrame]]:\n",
    "    \"\"\"Downloads a zip file url and returns a dictionary of GeoDataFrames for shapefiles that match the patterns\"\"\"\n",
    "    shp_dict = {}\n",
    "    retries = 5\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            with urlopen(zip_url) as u:\n",
    "                zip_data = u.read()\n",
    "            with ZipMemoryFile(zip_data) as z:\n",
    "                zip_files = z.listdir()\n",
    "                shp_files = [\n",
    "                    f\n",
    "                    for f in zip_files\n",
    "                    for pattern in patterns\n",
    "                    if pattern.search(f) and f.endswith(\".shp\")\n",
    "                ]\n",
    "                for shp_file in shp_files:\n",
    "                    with z.open(shp_file) as f:\n",
    "                        shp_dict[Path(shp_file).stem] = gpd.GeoDataFrame.from_features(\n",
    "                            f, crs=f.crs\n",
    "                        )\n",
    "            return shp_dict\n",
    "        except (IncompleteRead, URLError) as e:\n",
    "            print(f\"Error: {e} on try {i+1} of {retries} for {zip_url}\")\n",
    "            if i < retries - 1:\n",
    "                sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "\n",
    "def extract_matching_shp_files_from_zip_urls_concurrent(\n",
    "    zip_urls: list[str], regex_patterns: list[str]\n",
    ") -> dict[str, gpd.GeoDataFrame]:\n",
    "    \"\"\"Reads shapefiles from a list of zip file urls and returns a dictionary\n",
    "    where the keys are the names of the shapefiles and the values are GeoDataFrames.\"\"\"\n",
    "    shp_dict = {}\n",
    "    patterns = [re.compile(pattern) for pattern in regex_patterns]\n",
    "    with cf.ThreadPoolExecutor() as executor:\n",
    "        future_to_url = {\n",
    "            executor.submit(process_zip_url, url, patterns): url for url in zip_urls\n",
    "        }\n",
    "        futures = tqdm(\n",
    "            cf.as_completed(future_to_url),\n",
    "            total=len(future_to_url),\n",
    "            desc=\"Processing URLs\",\n",
    "            dynamic_ncols=True,\n",
    "        )\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                shp_dict.update(result)\n",
    "    return shp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def concat_gdf_from_dict(gdf_dict: dict[str, gpd.GeoDataFrame]) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Given a dictionary of GeoDataFrames, returns a single GeoDataFrame\n",
    "    with a new column indicating the source of the data.\n",
    "    \"\"\"\n",
    "    # use a dictionary comprehension to create a new dictionary\n",
    "    gdf_data = {k: gdf.assign(source_file=k) for k, gdf in gdf_dict.items()}\n",
    "    # return the concatenated GeoDataFrame\n",
    "    return pd.concat(gdf_data.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def extract_gdfs_from_zip(zip_path: str) -> Optional[dict[str, gpd.GeoDataFrame]]:\n",
    "    \"\"\"\n",
    "    Reads shapefiles from a zip file and returns a dictionary of GeoDataFrames.\n",
    "    \"\"\"\n",
    "    gdfs = {}\n",
    "    # Open the zip file\n",
    "    with ZipFile(zip_path) as z:\n",
    "        # Get the list of files in the zip file\n",
    "        zip_contents = z.namelist()\n",
    "        # Find the shapefiles\n",
    "        shp_files = [f for f in zip_contents if f.endswith(\".shp\")]\n",
    "        for shp_file in shp_files:\n",
    "            # Read the shapefile into a GeoDataFrame\n",
    "            gdf = gpd.read_file(f\"zip://{zip_path}!{shp_file}\")\n",
    "            gdfs[shp_file] = gdf\n",
    "\n",
    "    # If no shapefile was found, return None\n",
    "    return gdfs if gdfs else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def extract_gdfs_from_zip_url(zip_url: str) -> Optional[dict[str, gpd.GeoDataFrame]]:\n",
    "    \"\"\"\n",
    "    Downloads a ZIP file from a URL, reads shapefiles from the ZIP file, and returns a dictionary of GeoDataFrames.\n",
    "    \"\"\"\n",
    "    gdfs = {}\n",
    "    # Open the URL\n",
    "    with urlopen(zip_url) as u:\n",
    "        # Read the content of the response into a byte stream\n",
    "        zip_data = u.read()\n",
    "        # Open the ZIP file from the byte stream\n",
    "        with ZipMemoryFile(zip_data) as z:\n",
    "            # Get the list of files in the ZIP file\n",
    "            zip_contents = z.listdir()\n",
    "            # Find the shapefiles\n",
    "            shp_files = [f for f in zip_contents if f.endswith(\".shp\")]\n",
    "            for shp_file in shp_files:\n",
    "                # Read the shapefile into a GeoDataFrame\n",
    "                with z.open(shp_file) as f:\n",
    "                    gdf = gpd.GeoDataFrame.from_features(f, crs=f.crs)\n",
    "                gdfs[Path(shp_file).stem] = gdf\n",
    "\n",
    "    # If no shapefile was found, return None\n",
    "    return gdfs if gdfs else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def process_shp_url(zip_url: str):\n",
    "    \"\"\"Downloads a zip file url and returns a dictionary of GeoDataFrames for shapefiles that match the patterns\"\"\"\n",
    "    shp_dict = {}\n",
    "    with urlopen(zip_url) as u:\n",
    "        zip_data = u.read()\n",
    "    with ZipMemoryFile(zip_data) as z:\n",
    "        zip_files = z.listdir()\n",
    "        shp_files = [f for f in zip_files if f.endswith(\".shp\")]\n",
    "        for shp_file in shp_files:\n",
    "            with z.open(shp_file) as f:\n",
    "                shp_dict[Path(shp_file).stem] = gpd.GeoDataFrame.from_features(\n",
    "                    f, crs=f.crs\n",
    "                )\n",
    "    return shp_dict\n",
    "\n",
    "\n",
    "def extract_gdfs_from_zip_url_concurrent(\n",
    "    zip_urls: list[str],\n",
    ") -> dict[str, gpd.GeoDataFrame]:\n",
    "    \"\"\"Reads shapefiles from a list of zip file urls and returns a dictionary\n",
    "    where the keys are the names of the shapefiles and the values are GeoDataFrames.\"\"\"\n",
    "    shp_dict = {}\n",
    "    with cf.ThreadPoolExecutor() as executor:\n",
    "        future_to_url = {executor.submit(process_shp_url, url): url for url in zip_urls}\n",
    "        futures = tqdm(\n",
    "            cf.as_completed(future_to_url),\n",
    "            total=len(future_to_url),\n",
    "            desc=\"Processing URLs\",\n",
    "            dynamic_ncols=True,\n",
    "        )\n",
    "        for future in futures:\n",
    "            shp_dict.update(future.result())\n",
    "    return shp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def read_gdb_from_zip(gdb_zips_list: list[str]):\n",
    "    \"\"\"Reads a list of zip files containing geodatabases and returns a dictionary of GeoDataFrames\"\"\"\n",
    "    # initialize an empty dictionary\n",
    "    gdb_dict = {}\n",
    "    # loop through each zip file\n",
    "    for gdb_zip in gdb_zips_list:\n",
    "        with ZipFile(gdb_zip, \"r\") as z:\n",
    "            # get list of files in zip\n",
    "            files = z.namelist()\n",
    "            # filter for gdb folders\n",
    "            gdb_folders = [f for f in files if f.endswith(\".gdb/\")]\n",
    "            # if there is a gdb folder in the zip file\n",
    "            if gdb_folders:\n",
    "                # get it and read it into a GeoDataFrame\n",
    "                gdb_folder = gdb_folders[0]\n",
    "                gdb_dict[Path(gdb_folder).stem] = gpd.read_file(\n",
    "                    f\"zip://{gdb_zip}!{gdb_folder}\"\n",
    "                ).to_crs(\"EPSG:4269\")\n",
    "    # return the dictionary of GeoDataFrames\n",
    "    return gdb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def read_gdb_from_zip_url(gdb_urls_list: list[str]):\n",
    "    \"\"\"Reads a list of zip file urls containing geodatabases and returns a dictionary of GeoDataFrames\"\"\"\n",
    "    # initialize an empty dictionary\n",
    "    gdb_dict = {}\n",
    "    # loop through each zip file\n",
    "    for gdb_url in gdb_urls_list:\n",
    "        # create a temporary directory\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            # download the zip file\n",
    "            with urlopen(gdb_url) as u, open(f\"{tmp_dir}/data.zip\", \"wb\") as f_out:\n",
    "                f_out.write(u.read())\n",
    "            # extract the zip file\n",
    "            with ZipFile(f\"{tmp_dir}/data.zip\", \"r\") as zip_ref:\n",
    "                zip_ref.extractall(tmp_dir)\n",
    "            # get the list of extracted files\n",
    "            extracted_files = list(Path(tmp_dir).iterdir())\n",
    "            # filter for gdb folders\n",
    "            gdb_folders = [f for f in extracted_files if f.suffix == \".gdb\"]\n",
    "            # if there is a gdb folder in the extracted files\n",
    "            if gdb_folders:\n",
    "                # get it and read it into a GeoDataFrame\n",
    "                gdb_folder = gdb_folders[0]\n",
    "                gdb_dict[Path(gdb_folder).stem] = gpd.read_file(gdb_folder).to_crs(\n",
    "                    \"EPSG:4269\"\n",
    "                )\n",
    "    # return the dictionary of GeoDataFrames\n",
    "    return gdb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def process_gdb_url(gdb_url):\n",
    "    \"\"\"Downloads a zip file url containing a geodatabase and returns a GeoDataFrame\"\"\"\n",
    "    with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "        # download the zip file\n",
    "        with urlopen(gdb_url) as u, open(f\"{tmp_dir}/data.zip\", \"wb\") as f_out:\n",
    "            f_out.write(u.read())\n",
    "        # extract the zip file\n",
    "        with ZipFile(f\"{tmp_dir}/data.zip\", \"r\") as zip_ref:\n",
    "            zip_ref.extractall(tmp_dir)\n",
    "        # get the list of extracted files\n",
    "        extracted_files = list(Path(tmp_dir).iterdir())\n",
    "        # filter for gdb folders\n",
    "        gdb_folders = [f for f in extracted_files if f.suffix == \".gdb\"]\n",
    "        # if there is a gdb folder in the extracted files\n",
    "        if gdb_folders:\n",
    "            # get it and read it into a GeoDataFrame\n",
    "            gdb_folder = gdb_folders[0]\n",
    "            return Path(gdb_folder).stem, gpd.read_file(gdb_folder)\n",
    "\n",
    "\n",
    "def read_gdb_from_zip_url_concurrent(gdb_urls_list: list[str]):\n",
    "    \"\"\"Reads a list of zip file urls containing geodatabases and returns a dictionary of GeoDataFrames\"\"\"\n",
    "    # initialize an empty dictionary\n",
    "    gdb_dict = {}\n",
    "    # create a ThreadPoolExecutor\n",
    "    with cf.ThreadPoolExecutor() as executor:\n",
    "        # submit the process_gdb_url function for each url and gather the results\n",
    "        future_to_url = {\n",
    "            executor.submit(process_gdb_url, url): url for url in gdb_urls_list\n",
    "        }\n",
    "        for future in cf.as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                key, data = future.result()\n",
    "                gdb_dict[key] = data\n",
    "            except Exception as exc:\n",
    "                print(f\"{url} generated an exception: {exc}\")\n",
    "    # return the dictionary of GeoDataFrames\n",
    "    return gdb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "def pascal_to_snake(name: str):\n",
    "    \"\"\"Converts a string from PascalCase to snake_case\"\"\"\n",
    "    # (?<=[A-Za-z0-9]) - positive lookbehind for any alphanumeric character\n",
    "    # (?=[A-Z][a-z]) - positive lookahead for any uppercase followed by lowercase\n",
    "    pattern = re.compile(r\"(?<=[A-Za-z0-9])(?=[A-Z][a-z])\")\n",
    "    name = pattern.sub(\"_\", name).lower()\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def plot_statistics_table_nonmissing_hbar(df):\n",
    "    # Calculate the percentage of non-missing values in each column\n",
    "    missing_data_percent = (df.notnull().mean()).rename(\"Percent\")\n",
    "\n",
    "    # Create a DataFrame of the counts of non-missing values\n",
    "    if isinstance(df, dd.DataFrame):\n",
    "        non_missing_count, missing_data_percent = dask.compute(\n",
    "            df.count().rename(\"Count\"), (missing_data_percent * 100)\n",
    "        )\n",
    "    else:\n",
    "        missing_data_percent = missing_data_percent * 100\n",
    "        non_missing_count = df.notnull().sum().rename(\"Count\")\n",
    "\n",
    "    # Concatenate the two DataFrames along the columns\n",
    "    non_missing_data = pd.concat([missing_data_percent, non_missing_count], axis=1)\n",
    "\n",
    "    # Create a horizontal bar plot of the percentage of non-missing data\n",
    "    hbar_plot = non_missing_data.hvplot.barh(\n",
    "        y=\"Percent\",\n",
    "        width=800,\n",
    "        height=600,\n",
    "        title=\"Percentage of Non-Missing Data in Each Column\",\n",
    "        ylabel=\"\",\n",
    "        xlabel=\"\",\n",
    "        xaxis=\"bare\",\n",
    "        hover_cols=\"all\",\n",
    "    ).opts(\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        toolbar=\"above\",\n",
    "    )\n",
    "\n",
    "    return hbar_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def unify_crs(\n",
    "    dataframe: pd.DataFrame,\n",
    "    lon_col: str = \"longitude\",\n",
    "    lat_col: str = \"latitude\",\n",
    "    crs_col: str = \"crs\",\n",
    "    final_crs: str = \"EPSG:4269\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a DataFrame with lon/lat or x/y coordinates,\n",
    "    converts the coordinates to a unified crs and combines\n",
    "    into a single GeoDataframe with a geometry column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the main columns that will be used for the conversion\n",
    "    main_cols = [lon_col, lat_col, crs_col]\n",
    "\n",
    "    # Get the other columns in the dataframe\n",
    "    other_cols = list(set(dataframe.columns) - set(main_cols))\n",
    "\n",
    "    # Create a subframe with only the main columns\n",
    "    subframe = dataframe[main_cols]\n",
    "\n",
    "    # Create a list of GeoDataFrames, each with a different CRS\n",
    "    geo_dfs = [\n",
    "        gpd.GeoDataFrame(\n",
    "            # Use the data for this CRS\n",
    "            data=data,\n",
    "            # Create a geometry column from the lon/lat columns\n",
    "            geometry=gpd.points_from_xy(x=data[lon_col].values, y=data[lat_col].values),\n",
    "            # Set the CRS for this GeoDataFrame\n",
    "            crs=pyproj.CRS(crs_val),\n",
    "            # Convert the GeoDataFrame to the final CRS\n",
    "        ).to_crs(final_crs)\n",
    "        # Do this for each unique CRS in the subframe\n",
    "        for crs_val, data in subframe.groupby(crs_col)\n",
    "    ]\n",
    "\n",
    "    # Merge the GeoDataFrames back together and return the result\n",
    "    return pd.merge(\n",
    "        # Concatenate the GeoDataFrames\n",
    "        pd.concat(geo_dfs, sort=True),\n",
    "        # Add the other columns back in\n",
    "        dataframe[other_cols],\n",
    "        # Merge on the index\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# @lru_cache(maxsize=3)\n",
    "def get_background_map(bgcolor=\"black\", alpha=0.5):\n",
    "    \"\"\"Returns a GeoViews background map\"\"\"\n",
    "    return gts.CartoLight().opts(bgcolor=bgcolor, alpha=alpha)\n",
    "\n",
    "\n",
    "def platecaree_to_mercator_vectorised(x, y):\n",
    "    \"\"\"Use Cartopy to convert PlateCarree coordinates to Mercator\"\"\"\n",
    "    return ccrs.GOOGLE_MERCATOR.transform_points(ccrs.PlateCarree(), x, y)[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def format_in_000(num):\n",
    "    \"\"\"Formats a number in thousands\"\"\"\n",
    "    for unit in [\"\", \"thousand\", \"million\", \"billion\", \"trillion\"]:\n",
    "        if abs(num) < 1000.0:\n",
    "            return f\"{num:3.2f} {unit}\"\n",
    "        num /= 1000.0\n",
    "    return f\"{num:.2f} quadrillion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def split_datetime(df, column):\n",
    "    \"\"\"Splits a datetime column into year, month, and day columns\"\"\"\n",
    "    # remove '_date' from the column name\n",
    "    column_stem = column.replace(\"_date\", \"\") if \"_date\" in column else column\n",
    "    try:\n",
    "        datetime_series = pd.to_datetime(df[column], errors=\"coerce\")\n",
    "        if datetime_series.isna().any():\n",
    "            print(f\"Errors occurred during conversion of column {column}.\")\n",
    "        df[column_stem + \"_year\"] = datetime_series.dt.year\n",
    "        df[column_stem + \"_month\"] = datetime_series.dt.month\n",
    "        df[column_stem + \"_day\"] = datetime_series.dt.day\n",
    "    except KeyError:\n",
    "        print(f\"Column {column} not found in the DataFrame.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First dataset is from FracFocus. There is also a readme file which contains the data dictionary for the dataset. Let's have a look at both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Readme file with data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# get readme data\n",
    "readme = urlopen(DATA_README_URL[0]).read().decode(\"windows-1252\")\n",
    "display(readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print function goes beyond 'hello world' and takes care of the escape characters\n",
    "print(readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3/3 [00:04<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# We can collect all the dataframe into a list and then concatenate them\n",
    "df_list = read_csv_concurrent(DATA_URLS2)\n",
    "\n",
    "dfs = pd.concat(df_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213883 entries, 0 to 213882\n",
      "Data columns (total 21 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   pKey                     213883 non-null  object \n",
      " 1   JobStartDate             213868 non-null  object \n",
      " 2   JobEndDate               213883 non-null  object \n",
      " 3   APINumber                213883 non-null  object \n",
      " 4   StateNumber              213883 non-null  int64  \n",
      " 5   CountyNumber             213883 non-null  int64  \n",
      " 6   OperatorName             213883 non-null  object \n",
      " 7   WellName                 213883 non-null  object \n",
      " 8   Latitude                 213883 non-null  float64\n",
      " 9   Longitude                213883 non-null  float64\n",
      " 10  Projection               213883 non-null  object \n",
      " 11  TVD                      183743 non-null  float64\n",
      " 12  TotalBaseWaterVolume     183714 non-null  float64\n",
      " 13  TotalBaseNonWaterVolume  163574 non-null  float64\n",
      " 14  StateName                213881 non-null  object \n",
      " 15  CountyName               213875 non-null  object \n",
      " 16  FFVersion                213883 non-null  int64  \n",
      " 17  FederalWell              213883 non-null  bool   \n",
      " 18  IndianWell               213883 non-null  bool   \n",
      " 19  Source                   0 non-null       float64\n",
      " 20  DTMOD                    0 non-null       float64\n",
      "dtypes: bool(2), float64(7), int64(3), object(9)\n",
      "memory usage: 31.4+ MB\n"
     ]
    }
   ],
   "source": [
    "registry_df = pd.DataFrame()\n",
    "registry_df = dfs.copy()\n",
    "registry_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the missing values it is interesting to see that most missing values are from the `TVD`, `TotalBaseWaterVolume` and `TotalBaseNonWaterVolume`. One reason for this may be found in the data limitations on terms of use on the FracFocus website. It states:\n",
    "-  Disclosures submitted using the FracFocus 1.0 format (January, 2011 to May 31, 2013) will contain only header data. \n",
    "-  Disclosures submitted using the FracFocus 2.0 format (November 2012 to present) will contain both header and chemical data. NOTE: Between November, 2012 and May 31, 2013 disclosures in both 1.0 and 2.0 formats were submitted to the system. \n",
    "-  After May 31, 2013 only disclosures submitted in the 2.0 format were accepted.\n",
    "-  Data submitted appears as it was submitted by the operator or operators authorized agent. FracFocus does not warrant the data in any way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the missing data\n",
    "plot_statistics_table_nonmissing_hbar(registry_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of non-missing values in each column\n",
    "missing_data_percent = (registry_df.notna().mean() * 100).rename(\"Percent\")\n",
    "\n",
    "# Create a DataFrame of the counts of non-missing values\n",
    "non_missing_count = registry_df.notna().sum().rename(\"Count\")\n",
    "\n",
    "# Concatenate the two DataFrames along the columns\n",
    "non_missing_data = pd.concat([missing_data_percent, non_missing_count], axis=1)\n",
    "\n",
    "# Create a horizontal bar plot of the percentage of non-missing data\n",
    "barh_plot = non_missing_data.hvplot.barh(\n",
    "    y=\"Percent\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title=\"Percentage of Non-Missing Data in Each Column\",\n",
    "    ylabel=\"\",\n",
    "    xlabel=\"\",\n",
    "    xaxis=\"bare\",\n",
    "    hover_cols=\"all\",\n",
    ").opts(\n",
    "    active_tools=[\"box_zoom\"],\n",
    "    toolbar=\"above\",\n",
    ")\n",
    "\n",
    "barh_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some of the rows of the dataframe\n",
    "display(registry_df.head(3))\n",
    "display(registry_df.sample(5, random_state=628))\n",
    "display(registry_df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our first look at a few sample rows some things stick out immediately.\n",
    "1. The dataset may be in chronological order and the values of the `JobStartDate`/`JobEndDate` at both of the extremes may be incorrect.\n",
    "2. There may be an abundance for `StateNumber` `42` if 4 out of the 5 draws of the 200k+ rows drawn at random had a `StateNumber` of `42`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we jump into cleaning the data in the columns, let's make the columns look more pythonic by changing the column names to snake_case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213883 entries, 0 to 213882\n",
      "Data columns (total 21 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   p_key                        213883 non-null  object \n",
      " 1   job_start_date               213868 non-null  object \n",
      " 2   job_end_date                 213883 non-null  object \n",
      " 3   api_number                   213883 non-null  object \n",
      " 4   state_number                 213883 non-null  int64  \n",
      " 5   county_number                213883 non-null  int64  \n",
      " 6   operator_name                213883 non-null  object \n",
      " 7   well_name                    213883 non-null  object \n",
      " 8   latitude                     213883 non-null  float64\n",
      " 9   longitude                    213883 non-null  float64\n",
      " 10  projection                   213883 non-null  object \n",
      " 11  tvd                          183743 non-null  float64\n",
      " 12  total_base_water_volume      183714 non-null  float64\n",
      " 13  total_base_non_water_volume  163574 non-null  float64\n",
      " 14  state_name                   213881 non-null  object \n",
      " 15  county_name                  213875 non-null  object \n",
      " 16  ff_version                   213883 non-null  int64  \n",
      " 17  federal_well                 213883 non-null  bool   \n",
      " 18  indian_well                  213883 non-null  bool   \n",
      " 19  source                       0 non-null       float64\n",
      " 20  dtmod                        0 non-null       float64\n",
      "dtypes: bool(2), float64(7), int64(3), object(9)\n",
      "memory usage: 147.0 MB\n"
     ]
    }
   ],
   "source": [
    "registry_df.columns = [pascal_to_snake(col) for col in registry_df.columns]\n",
    "registry_df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can remove the columns with only null values. These are the last 2 columns in the dataframe, `source` and `dtmod`. Also we can drop the `total_non_base_water_volume` column since we may not have much need for it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213883 entries, 0 to 213882\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   p_key                    213883 non-null  object \n",
      " 1   job_start_date           213868 non-null  object \n",
      " 2   job_end_date             213883 non-null  object \n",
      " 3   api_number               213883 non-null  object \n",
      " 4   state_number             213883 non-null  int64  \n",
      " 5   county_number            213883 non-null  int64  \n",
      " 6   operator_name            213883 non-null  object \n",
      " 7   well_name                213883 non-null  object \n",
      " 8   latitude                 213883 non-null  float64\n",
      " 9   longitude                213883 non-null  float64\n",
      " 10  projection               213883 non-null  object \n",
      " 11  tvd                      183743 non-null  float64\n",
      " 12  total_base_water_volume  183714 non-null  float64\n",
      " 13  state_name               213881 non-null  object \n",
      " 14  county_name              213875 non-null  object \n",
      " 15  ff_version               213883 non-null  int64  \n",
      " 16  federal_well             213883 non-null  bool   \n",
      " 17  indian_well              213883 non-null  bool   \n",
      "dtypes: bool(2), float64(4), int64(3), object(9)\n",
      "memory usage: 142.1 MB\n"
     ]
    }
   ],
   "source": [
    "registry_df = registry_df.drop(\n",
    "    columns=[\"source\", \"dtmod\", \"total_base_non_water_volume\"]\n",
    ")\n",
    "registry_df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will fix some of the dtypes of the columns.\n",
    "- Both the `job_start_date` and the `job_end_date` columns are object dtypes, so we will convert those to datetime dtypes and drop the timestamp.\n",
    "- We can also separate out the date components into its various components. This may come in handy for feature engineering later on.\n",
    "- The `projection` column is an object dtype. That can be converted to a string dtype and shorten to `crs` as it represents the Cooordinate Reference System used in the `latitude` and `longitude` columns values. We can dig into what CRS is later on.\n",
    "- The `federal_well` and `indian_well` columns are both boolean type columns. They may be more aptly named as `is_federal_well` and `is_indian_well` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors occurred during conversion of column job_start_date.\n",
      "Errors occurred during conversion of column job_end_date.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213883 entries, 0 to 213882\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   job_start_date   213868 non-null  object \n",
      " 1   job_end_date     213883 non-null  object \n",
      " 2   job_start_year   213866 non-null  float64\n",
      " 3   job_start_month  213866 non-null  float64\n",
      " 4   job_start_day    213866 non-null  float64\n",
      " 5   job_end_year     213882 non-null  float64\n",
      " 6   job_end_month    213882 non-null  float64\n",
      " 7   job_end_day      213882 non-null  float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 41.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17, 24)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the function on 'job_start_date' and 'job_end_date'\n",
    "split_datetime(registry_df, \"job_start_date\")\n",
    "split_datetime(registry_df, \"job_end_date\")\n",
    "registry_df[[col for col in registry_df.columns if re.search(\"start|end\", col)]].info(\n",
    "    memory_usage=\"deep\"\n",
    ")\n",
    "# show the values which are null still\n",
    "registry_df[\n",
    "    registry_df[[col for col in registry_df.columns if re.search(\"start|end\", col)]]\n",
    "    .isna()\n",
    "    .any(axis=1)\n",
    "].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 213883 entries, 0 to 213882\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   p_key                    213883 non-null  object \n",
      " 1   job_start_date           213866 non-null  object \n",
      " 2   job_end_date             213882 non-null  object \n",
      " 3   api_number               213883 non-null  object \n",
      " 4   state_number             213883 non-null  int64  \n",
      " 5   county_number            213883 non-null  int64  \n",
      " 6   operator_name            213883 non-null  object \n",
      " 7   well_name                213883 non-null  object \n",
      " 8   latitude                 213883 non-null  float64\n",
      " 9   longitude                213883 non-null  float64\n",
      " 10  crs                      213883 non-null  object \n",
      " 11  tvd                      183743 non-null  float64\n",
      " 12  total_base_water_volume  183714 non-null  float64\n",
      " 13  state_name               213881 non-null  object \n",
      " 14  county_name              213875 non-null  object \n",
      " 15  ff_version               213883 non-null  int64  \n",
      " 16  is_federal_well          213883 non-null  bool   \n",
      " 17  is_indian_well           213883 non-null  bool   \n",
      " 18  job_start_year           213866 non-null  float64\n",
      " 19  job_start_month          213866 non-null  float64\n",
      " 20  job_start_day            213866 non-null  float64\n",
      " 21  job_end_year             213882 non-null  float64\n",
      " 22  job_end_month            213882 non-null  float64\n",
      " 23  job_end_day              213882 non-null  float64\n",
      "dtypes: bool(2), float64(10), int64(3), object(9)\n",
      "memory usage: 147.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Convert 'job_start_date' to datetime format and format it as 'YYYY-MM-DD'\n",
    "registry_df[\"job_start_date\"] = pd.to_datetime(\n",
    "    registry_df[\"job_start_date\"], errors=\"coerce\"\n",
    ").dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Convert 'job_end_date' to datetime format and format it as 'YYYY-MM-DD'\n",
    "registry_df[\"job_end_date\"] = pd.to_datetime(\n",
    "    registry_df[\"job_end_date\"], errors=\"coerce\"\n",
    ").dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# drop rows with null values in 'job_start_date' and 'job_end_date'\n",
    "# registry_df = registry_df.dropna(subset=[\"job_start_date\", \"job_end_date\"])\n",
    "\n",
    "\n",
    "# Rename some columns for clarity\n",
    "registry_df.rename(\n",
    "    columns={\n",
    "        \"federal_well\": \"is_federal_well\",\n",
    "        \"indian_well\": \"is_indian_well\",\n",
    "        \"projection\": \"crs\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Display the information of the DataFrame\n",
    "registry_df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will look at the `api_number` column.\n",
    "We learned from the read me that \n",
    "> APINumber - The American Petroleum Institute well identification number formatted as follows xx-xxx-xxxxx0000 Where: \n",
    "> - First two digits represent the state, \n",
    "> - second three digits represent the county, \n",
    "> - third 5 digits represent the well.\n",
    "\n",
    "Theoretically, we could just grab the first two characters of the `APINnumber` and use that as the state number according to the definition of the `APINumber` above. Actually, that would not be a good idea, and here is why.<br>\n",
    "Although the column was called `APINumber`, it is not actually a number, so if it starts with a leading `0` that first character `0`, cannot be omitted from the value. Let's look at some of the rows with a single digit state numbers.\n",
    "\n",
    "Right now, \n",
    "- the `api_number` column is an object dtype, but a better option would be a `string` dtype, as `object` dtype can be mixed . We can also shorten that column name to `api`.\n",
    "- the `state_number` column and the `county_number` column are both `int64` dtypes right now. `string` type may be a stronger option.\n",
    "- `state_code` and `county_code` may be better names for the `state_number` and `county_number` columns respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows where the state_number is a single digit\n",
    "registry_df[\n",
    "    (registry_df[\"state_number\"] == 3) | (registry_df[\"state_number\"] == 5)\n",
    "].sample(5, random_state=628)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some rows' `api_number` values have leading `0`, which is correct, but some do not. The rows without the leading `0` though are 13 characters long instead of 14. Maybe we can just add a leading `0` where needed until all API number values are 14 characters long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of characters in the api_number column\n",
    "registry_df[\"api_number\"].astype(\"string\").str.len().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most are 14 characters long, but some are 13 characters long, like the ones we saw above without the leading `0`. Let's assume the ones with 13 characters are missing the leading `0` and not something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# Convert 'api' to string and pad it with zeros to make it 14 characters long\n",
    "registry_df[\"api\"] = registry_df[\"api_number\"].astype(\"string\").str.zfill(14)\n",
    "\n",
    "# Convert 'state_number' to string and pad it with zeros to make it 2 characters long\n",
    "registry_df[\"state_code\"] = registry_df[\"state_number\"].astype(\"string\").str.zfill(2)\n",
    "\n",
    "# Convert 'county_number' to string and pad it with zeros to make it 3 characters long\n",
    "registry_df[\"county_code\"] = registry_df[\"county_number\"].astype(\"string\").str.zfill(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# check which rows may have the api with the first two digits not matching the state number\n",
    "api_state_mismatch_mask = registry_df[\"state_code\"] != registry_df[\"api\"].str[0:2]\n",
    "# api_state_mismatch_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which rows may have the api with the first two digits not matching the state number\n",
    "registry_df[api_state_mismatch_mask][\n",
    "    [\"api_number\", \"api\", \"state_code\", \"state_name\", \"county_code\", \"county_name\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expected to get 2 rows here, since we checked the length of the `api_number` column above we saw that 1 row had 10 and another row had 12 characters. It is only two rows, so this may be an easy fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# Remove leading zeros and pad to 14 digits on mismatches\n",
    "registry_df.loc[api_state_mismatch_mask, \"api\"] = (\n",
    "    registry_df.loc[api_state_mismatch_mask, \"api\"].str.lstrip(\"0\").str.ljust(14, \"0\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which rows may have the api with the first two digits not matching the state number\n",
    "registry_df[api_state_mismatch_mask][\n",
    "    [\"api_number\", \"api\", \"state_code\", \"state_name\", \"county_code\", \"county_name\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_key</th>\n",
       "      <th>job_start_date</th>\n",
       "      <th>job_end_date</th>\n",
       "      <th>api_number</th>\n",
       "      <th>state_number</th>\n",
       "      <th>county_number</th>\n",
       "      <th>operator_name</th>\n",
       "      <th>well_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crs</th>\n",
       "      <th>tvd</th>\n",
       "      <th>total_base_water_volume</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>ff_version</th>\n",
       "      <th>is_federal_well</th>\n",
       "      <th>is_indian_well</th>\n",
       "      <th>job_start_year</th>\n",
       "      <th>job_start_month</th>\n",
       "      <th>job_start_day</th>\n",
       "      <th>job_end_year</th>\n",
       "      <th>job_end_month</th>\n",
       "      <th>job_end_day</th>\n",
       "      <th>api</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [p_key, job_start_date, job_end_date, api_number, state_number, county_number, operator_name, well_name, latitude, longitude, crs, tvd, total_base_water_volume, state_name, county_name, ff_version, is_federal_well, is_indian_well, job_start_year, job_start_month, job_start_day, job_end_year, job_end_month, job_end_day, api, state_code, county_code]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which rows may have the api with the 3-5 digits not matching the county number\n",
    "api_county_mismatch_mask = registry_df[\"county_code\"] != registry_df[\"api\"].str[2:5]\n",
    "registry_df[api_county_mismatch_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State name should not have more than 50 possible values, given that there are only 50 states in the US. If we were to check the number of unique values in the `state_name` column, we would see 95. This is due to the variation in the way the `state_name` value is entered. Although not as obvious, we can assume the same for the `county_name` column. Luckily, the `api` includes both the `state_number` and the `county_number`. With this we can do \n",
    "1. data validation ensuring that these corresponding columns match\n",
    "2. Ensure that the `state_name` and the `county_name` columns are correct. Important to note that \n",
    "> The state codes used in an API number are DIFFERENT from another standard which is the Federal Information Processing Standard (FIPS) state code established in 1987 by NIST. ([source](https://en.wikipedia.org/wiki/API_well_number#State_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'Number of different values in state_name column: {registry_df[\"state_name\"].nunique()}'\n",
    ")\n",
    "print(\n",
    "    f'Number of different values in state_number column: {registry_df[\"state_number\"].nunique()}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Idaho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>Illinois</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>Indiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>Kansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>Louisiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>Michigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>Mississippi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>Montana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26</td>\n",
       "      <td>Nebraska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27</td>\n",
       "      <td>Nevada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30</td>\n",
       "      <td>New Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>North Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>34</td>\n",
       "      <td>Ohio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>35</td>\n",
       "      <td>Oklahoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>37</td>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47</td>\n",
       "      <td>West Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>49</td>\n",
       "      <td>Wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_code           state\n",
       "0          01         Alabama\n",
       "1          03        Arkansas\n",
       "2          04      California\n",
       "3          05        Colorado\n",
       "4          11           Idaho\n",
       "5          12        Illinois\n",
       "6          13         Indiana\n",
       "7          15          Kansas\n",
       "8          16        Kentucky\n",
       "9          17       Louisiana\n",
       "10         21        Michigan\n",
       "11         23     Mississippi\n",
       "12         25         Montana\n",
       "13         26        Nebraska\n",
       "14         27          Nevada\n",
       "15         30      New Mexico\n",
       "16         31        New York\n",
       "17         32  North Carolina\n",
       "18         33    North Dakota\n",
       "19         34            Ohio\n",
       "20         35        Oklahoma\n",
       "21         37    Pennsylvania\n",
       "22         42           Texas\n",
       "23         43            Utah\n",
       "24         45        Virginia\n",
       "25         47   West Virginia\n",
       "26         49         Wyoming\n",
       "27         50          Alaska"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by state_code and find the mode of the state_name\n",
    "state_code_mode = (\n",
    "    registry_df.groupby(\"state_code\")[\"state_name\"]\n",
    "    .apply(lambda x: x.mode().iloc[0])\n",
    "    .reset_index()\n",
    ")\n",
    "state_code_mode = state_code_mode.rename(columns={\"state_name\": \"state\"})\n",
    "state_code_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_key</th>\n",
       "      <th>job_start_date</th>\n",
       "      <th>job_end_date</th>\n",
       "      <th>api_number</th>\n",
       "      <th>state_number</th>\n",
       "      <th>county_number</th>\n",
       "      <th>operator_name</th>\n",
       "      <th>well_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crs</th>\n",
       "      <th>tvd</th>\n",
       "      <th>total_base_water_volume</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>ff_version</th>\n",
       "      <th>is_federal_well</th>\n",
       "      <th>is_indian_well</th>\n",
       "      <th>job_start_year</th>\n",
       "      <th>job_start_month</th>\n",
       "      <th>job_start_day</th>\n",
       "      <th>job_end_year</th>\n",
       "      <th>job_end_month</th>\n",
       "      <th>job_end_day</th>\n",
       "      <th>api</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192605</th>\n",
       "      <td>d45ffa9c-25cc-42a3-92ab-09fcc74d032f</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>2018-11-18</td>\n",
       "      <td>35083244260000</td>\n",
       "      <td>35</td>\n",
       "      <td>83</td>\n",
       "      <td>chisholm Oil and Gas Operating, LLC</td>\n",
       "      <td>King Ranch #18-4-32 1H</td>\n",
       "      <td>36.000705</td>\n",
       "      <td>-97.653121</td>\n",
       "      <td>NAD27</td>\n",
       "      <td>6569.0</td>\n",
       "      <td>12481014.0</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Logan</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35083244260000</td>\n",
       "      <td>35</td>\n",
       "      <td>083</td>\n",
       "      <td>Oklahoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>e3a3d6d1-d409-4e7c-ad57-703cbff32eef</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>42097341930000</td>\n",
       "      <td>42</td>\n",
       "      <td>97</td>\n",
       "      <td>EOG Resources, Inc.</td>\n",
       "      <td>Herbert Unit #3H</td>\n",
       "      <td>33.536889</td>\n",
       "      <td>-97.474433</td>\n",
       "      <td>NAD27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Cooke</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>42097341930000</td>\n",
       "      <td>42</td>\n",
       "      <td>097</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47360</th>\n",
       "      <td>702c7c38-053f-4b28-930d-b75fd0d1623d</td>\n",
       "      <td>2014-12-07</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>42255337360000</td>\n",
       "      <td>42</td>\n",
       "      <td>255</td>\n",
       "      <td>Encana Oil &amp; Gas (USA) Inc.</td>\n",
       "      <td>Charger 9H</td>\n",
       "      <td>29.037556</td>\n",
       "      <td>-97.934511</td>\n",
       "      <td>NAD27</td>\n",
       "      <td>10395.0</td>\n",
       "      <td>14672682.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Karnes</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>42255337360000</td>\n",
       "      <td>42</td>\n",
       "      <td>255</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       p_key job_start_date job_end_date  \\\n",
       "192605  d45ffa9c-25cc-42a3-92ab-09fcc74d032f     2018-11-13   2018-11-18   \n",
       "286     e3a3d6d1-d409-4e7c-ad57-703cbff32eef     2011-02-14   2011-02-14   \n",
       "47360   702c7c38-053f-4b28-930d-b75fd0d1623d     2014-12-07   2015-01-07   \n",
       "\n",
       "            api_number  state_number  county_number  \\\n",
       "192605  35083244260000            35             83   \n",
       "286     42097341930000            42             97   \n",
       "47360   42255337360000            42            255   \n",
       "\n",
       "                              operator_name               well_name  \\\n",
       "192605  chisholm Oil and Gas Operating, LLC  King Ranch #18-4-32 1H   \n",
       "286                     EOG Resources, Inc.        Herbert Unit #3H   \n",
       "47360           Encana Oil & Gas (USA) Inc.              Charger 9H   \n",
       "\n",
       "         latitude  longitude    crs      tvd  total_base_water_volume  \\\n",
       "192605  36.000705 -97.653121  NAD27   6569.0               12481014.0   \n",
       "286     33.536889 -97.474433  NAD27      NaN                      NaN   \n",
       "47360   29.037556 -97.934511  NAD27  10395.0               14672682.0   \n",
       "\n",
       "       state_name county_name  ff_version  is_federal_well  is_indian_well  \\\n",
       "192605   Oklahoma       Logan           3            False           False   \n",
       "286         Texas       Cooke           1            False           False   \n",
       "47360       Texas      Karnes           2            False           False   \n",
       "\n",
       "        job_start_year  job_start_month  job_start_day  job_end_year  \\\n",
       "192605          2018.0             11.0           13.0        2018.0   \n",
       "286             2011.0              2.0           14.0        2011.0   \n",
       "47360           2014.0             12.0            7.0        2015.0   \n",
       "\n",
       "        job_end_month  job_end_day             api state_code county_code  \\\n",
       "192605           11.0         18.0  35083244260000         35         083   \n",
       "286               2.0         14.0  42097341930000         42         097   \n",
       "47360             1.0          7.0  42255337360000         42         255   \n",
       "\n",
       "           state  \n",
       "192605  Oklahoma  \n",
       "286        Texas  \n",
       "47360      Texas  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry_df = registry_df.merge(state_code_mode.rename(columns={\"state_name\": \"state\"}))\n",
    "registry_df.sample(3, random_state=628)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will focus our efforts in the most recent 10 years. Although more data is usually better, data too far in the past may distract whatever model we may build since unconventional drilling practices have really taken over the industry. We will also put our focus in one specific area, the Permian Basin. The Permian Basin has been instrumental in the shale boom transformation and is the most active area of exploration and production in the US presently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_key</th>\n",
       "      <th>job_start_date</th>\n",
       "      <th>job_end_date</th>\n",
       "      <th>api_number</th>\n",
       "      <th>state_number</th>\n",
       "      <th>county_number</th>\n",
       "      <th>operator_name</th>\n",
       "      <th>well_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crs</th>\n",
       "      <th>tvd</th>\n",
       "      <th>total_base_water_volume</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>ff_version</th>\n",
       "      <th>is_federal_well</th>\n",
       "      <th>is_indian_well</th>\n",
       "      <th>job_start_year</th>\n",
       "      <th>job_start_month</th>\n",
       "      <th>job_start_day</th>\n",
       "      <th>job_end_year</th>\n",
       "      <th>job_end_month</th>\n",
       "      <th>job_end_day</th>\n",
       "      <th>api</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61454</th>\n",
       "      <td>7534cb0b-9f85-4ca2-a21c-31be328456f8</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>42173374020000</td>\n",
       "      <td>42</td>\n",
       "      <td>173</td>\n",
       "      <td>Cinnabar Energy, LTD.</td>\n",
       "      <td>Thomas 4101HD</td>\n",
       "      <td>31.996472</td>\n",
       "      <td>-101.568598</td>\n",
       "      <td>NAD27</td>\n",
       "      <td>9310.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Glasscock</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42173374020000</td>\n",
       "      <td>42</td>\n",
       "      <td>173</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61965</th>\n",
       "      <td>c57e59c6-d132-4a13-bb0b-8fb3e58ce918</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>42077352710000</td>\n",
       "      <td>42</td>\n",
       "      <td>77</td>\n",
       "      <td>Lane Operating Company</td>\n",
       "      <td>Dillard A Unit No. 1</td>\n",
       "      <td>33.591273</td>\n",
       "      <td>-98.138934</td>\n",
       "      <td>NAD27</td>\n",
       "      <td>4600.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Clay</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42077352710000</td>\n",
       "      <td>42</td>\n",
       "      <td>077</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62626</th>\n",
       "      <td>a2ad142e-6a38-44ed-8ebc-8572e43236b7</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>42237401310000</td>\n",
       "      <td>42</td>\n",
       "      <td>237</td>\n",
       "      <td>Blakenergy Operating, LLC</td>\n",
       "      <td>Garner #2</td>\n",
       "      <td>33.434316</td>\n",
       "      <td>-98.227896</td>\n",
       "      <td>NAD27</td>\n",
       "      <td>6350.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Jack</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>42237401310000</td>\n",
       "      <td>42</td>\n",
       "      <td>237</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84840</th>\n",
       "      <td>fcbf3967-867e-4e4e-af18-d83e7a82c604</td>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>2020-04-19</td>\n",
       "      <td>42461378800000</td>\n",
       "      <td>42</td>\n",
       "      <td>461</td>\n",
       "      <td>COG Operating LLC</td>\n",
       "      <td>Powell 36 7</td>\n",
       "      <td>31.523085</td>\n",
       "      <td>-102.118329</td>\n",
       "      <td>NAD27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Upton</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>42461378800000</td>\n",
       "      <td>42</td>\n",
       "      <td>461</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89052</th>\n",
       "      <td>ead37751-a53f-4ed9-99df-8cac1ebf1e15</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>2021-05-23</td>\n",
       "      <td>42173346750000</td>\n",
       "      <td>42</td>\n",
       "      <td>173</td>\n",
       "      <td>Berry Petroleum</td>\n",
       "      <td>Talon #4</td>\n",
       "      <td>31.950785</td>\n",
       "      <td>-101.775302</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Glasscock</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>42173346750000</td>\n",
       "      <td>42</td>\n",
       "      <td>173</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89305</th>\n",
       "      <td>4753a32e-39cb-4994-b69b-8acb36597463</td>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>42115334560000</td>\n",
       "      <td>42</td>\n",
       "      <td>115</td>\n",
       "      <td>Pioneer Natural Resources</td>\n",
       "      <td>Echols 10 #1</td>\n",
       "      <td>32.531683</td>\n",
       "      <td>-102.096109</td>\n",
       "      <td>NAD27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Dawson</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42115334560000</td>\n",
       "      <td>42</td>\n",
       "      <td>115</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98083</th>\n",
       "      <td>b76c7cc4-f1c1-4711-9168-ba819f41d070</td>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>42479446890000</td>\n",
       "      <td>42</td>\n",
       "      <td>479</td>\n",
       "      <td>Lewis Energy Group</td>\n",
       "      <td>HAMILTON NO. 34H</td>\n",
       "      <td>27.958510</td>\n",
       "      <td>-99.567909</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>10456.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Webb</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42479446890000</td>\n",
       "      <td>42</td>\n",
       "      <td>479</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98087</th>\n",
       "      <td>99463560-ccb5-4c07-9537-8abdc731208b</td>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>42479446880000</td>\n",
       "      <td>42</td>\n",
       "      <td>479</td>\n",
       "      <td>Lewis Energy Group</td>\n",
       "      <td>HAMILTON NO. 33H</td>\n",
       "      <td>27.958510</td>\n",
       "      <td>-99.567956</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>10437.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Webb</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>42479446880000</td>\n",
       "      <td>42</td>\n",
       "      <td>479</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139253</th>\n",
       "      <td>0f8e944c-87d7-4d84-8d56-4b8a5f1cba94</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>33610338000000</td>\n",
       "      <td>33</td>\n",
       "      <td>610</td>\n",
       "      <td>Hunt Oil Company</td>\n",
       "      <td>TRULSON 156-90-11-14H-3</td>\n",
       "      <td>48.355506</td>\n",
       "      <td>-102.212124</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>8872.40</td>\n",
       "      <td>13496802.0</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33610338000000</td>\n",
       "      <td>33</td>\n",
       "      <td>610</td>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139256</th>\n",
       "      <td>6e5d8284-29d1-4b3d-a72c-729d95c327de</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>33610338100000</td>\n",
       "      <td>33</td>\n",
       "      <td>610</td>\n",
       "      <td>Hunt Oil Company</td>\n",
       "      <td>PALERMO 156-90-2-31H-5</td>\n",
       "      <td>48.355506</td>\n",
       "      <td>-102.212330</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>8782.65</td>\n",
       "      <td>14820967.0</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33610338100000</td>\n",
       "      <td>33</td>\n",
       "      <td>610</td>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149319</th>\n",
       "      <td>08dc68e6-3055-443f-b71b-4228a4ad3838</td>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>30025466380000</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>BTA Oil Producers LLC</td>\n",
       "      <td>Mesa B 8115 Federal Com #21H</td>\n",
       "      <td>32.063342</td>\n",
       "      <td>-103.617873</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>12812.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Lea</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30025466380000</td>\n",
       "      <td>30</td>\n",
       "      <td>025</td>\n",
       "      <td>New Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178445</th>\n",
       "      <td>692d9381-748e-4e5f-b83f-30f868f18882</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>03729439000000</td>\n",
       "      <td>3</td>\n",
       "      <td>729</td>\n",
       "      <td>WFD Oil Corporation</td>\n",
       "      <td>Vanorsdale</td>\n",
       "      <td>0.123455</td>\n",
       "      <td>-0.123450</td>\n",
       "      <td>NAD27</td>\n",
       "      <td>2442.00</td>\n",
       "      <td>22134.0</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>03729439000000</td>\n",
       "      <td>03</td>\n",
       "      <td>729</td>\n",
       "      <td>Arkansas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206589</th>\n",
       "      <td>87ea1a50-ab40-4956-8051-d39bf139ae53</td>\n",
       "      <td>2020-11-11</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>43317428660000</td>\n",
       "      <td>43</td>\n",
       "      <td>317</td>\n",
       "      <td>Endeavor Energy Resources</td>\n",
       "      <td>Rhea 1-6 Unit 1 #133</td>\n",
       "      <td>32.409144</td>\n",
       "      <td>-101.808518</td>\n",
       "      <td>NAD83</td>\n",
       "      <td>8262.00</td>\n",
       "      <td>17519292.0</td>\n",
       "      <td>Utah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43317428660000</td>\n",
       "      <td>43</td>\n",
       "      <td>317</td>\n",
       "      <td>Utah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213811</th>\n",
       "      <td>7d019130-c641-4bfc-a14d-3d28ab064fcc</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>23095201430000</td>\n",
       "      <td>23</td>\n",
       "      <td>95</td>\n",
       "      <td>Dallas Production, Inc</td>\n",
       "      <td>TA Richardson 5</td>\n",
       "      <td>33.697871</td>\n",
       "      <td>-88.505110</td>\n",
       "      <td>WGS84</td>\n",
       "      <td>5250.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>Monroe</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23095201430000</td>\n",
       "      <td>23</td>\n",
       "      <td>095</td>\n",
       "      <td>Mississippi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       p_key job_start_date job_end_date  \\\n",
       "61454   7534cb0b-9f85-4ca2-a21c-31be328456f8     2017-04-10   2017-04-10   \n",
       "61965   c57e59c6-d132-4a13-bb0b-8fb3e58ce918     2017-05-08   2017-05-08   \n",
       "62626   a2ad142e-6a38-44ed-8ebc-8572e43236b7     2017-06-13   2017-06-13   \n",
       "84840   fcbf3967-867e-4e4e-af18-d83e7a82c604     2020-04-19   2020-04-19   \n",
       "89052   ead37751-a53f-4ed9-99df-8cac1ebf1e15     2021-05-23   2021-05-23   \n",
       "89305   4753a32e-39cb-4994-b69b-8acb36597463     2021-06-08   2021-06-08   \n",
       "98083   b76c7cc4-f1c1-4711-9168-ba819f41d070     2022-10-16   2022-10-27   \n",
       "98087   99463560-ccb5-4c07-9537-8abdc731208b     2022-10-16   2022-10-27   \n",
       "139253  0f8e944c-87d7-4d84-8d56-4b8a5f1cba94     2022-05-28   2022-06-08   \n",
       "139256  6e5d8284-29d1-4b3d-a72c-729d95c327de     2022-05-28   2022-06-09   \n",
       "149319  08dc68e6-3055-443f-b71b-4228a4ad3838     2021-12-16   2021-12-23   \n",
       "178445  692d9381-748e-4e5f-b83f-30f868f18882     2019-11-19   2019-11-19   \n",
       "206589  87ea1a50-ab40-4956-8051-d39bf139ae53     2020-11-11   2020-12-01   \n",
       "213811  7d019130-c641-4bfc-a14d-3d28ab064fcc     2022-09-28   2022-09-28   \n",
       "\n",
       "            api_number  state_number  county_number  \\\n",
       "61454   42173374020000            42            173   \n",
       "61965   42077352710000            42             77   \n",
       "62626   42237401310000            42            237   \n",
       "84840   42461378800000            42            461   \n",
       "89052   42173346750000            42            173   \n",
       "89305   42115334560000            42            115   \n",
       "98083   42479446890000            42            479   \n",
       "98087   42479446880000            42            479   \n",
       "139253  33610338000000            33            610   \n",
       "139256  33610338100000            33            610   \n",
       "149319  30025466380000            30             25   \n",
       "178445  03729439000000             3            729   \n",
       "206589  43317428660000            43            317   \n",
       "213811  23095201430000            23             95   \n",
       "\n",
       "                    operator_name                     well_name   latitude  \\\n",
       "61454       Cinnabar Energy, LTD.                 Thomas 4101HD  31.996472   \n",
       "61965      Lane Operating Company          Dillard A Unit No. 1  33.591273   \n",
       "62626   Blakenergy Operating, LLC                     Garner #2  33.434316   \n",
       "84840           COG Operating LLC                   Powell 36 7  31.523085   \n",
       "89052             Berry Petroleum                      Talon #4  31.950785   \n",
       "89305   Pioneer Natural Resources                  Echols 10 #1  32.531683   \n",
       "98083          Lewis Energy Group              HAMILTON NO. 34H  27.958510   \n",
       "98087          Lewis Energy Group              HAMILTON NO. 33H  27.958510   \n",
       "139253           Hunt Oil Company       TRULSON 156-90-11-14H-3  48.355506   \n",
       "139256           Hunt Oil Company        PALERMO 156-90-2-31H-5  48.355506   \n",
       "149319      BTA Oil Producers LLC  Mesa B 8115 Federal Com #21H  32.063342   \n",
       "178445        WFD Oil Corporation                    Vanorsdale   0.123455   \n",
       "206589  Endeavor Energy Resources          Rhea 1-6 Unit 1 #133  32.409144   \n",
       "213811     Dallas Production, Inc               TA Richardson 5  33.697871   \n",
       "\n",
       "         longitude    crs       tvd  total_base_water_volume    state_name  \\\n",
       "61454  -101.568598  NAD27   9310.00                      NaN         Texas   \n",
       "61965   -98.138934  NAD27   4600.00                      NaN         Texas   \n",
       "62626   -98.227896  NAD27   6350.00                      NaN         Texas   \n",
       "84840  -102.118329  NAD27       NaN                      NaN         Texas   \n",
       "89052  -101.775302  NAD83       NaN                      NaN         Texas   \n",
       "89305  -102.096109  NAD27       NaN                      NaN         Texas   \n",
       "98083   -99.567909  WGS84  10456.00                      NaN         Texas   \n",
       "98087   -99.567956  WGS84  10437.00                      NaN         Texas   \n",
       "139253 -102.212124  NAD83   8872.40               13496802.0  North Dakota   \n",
       "139256 -102.212330  NAD83   8782.65               14820967.0  North Dakota   \n",
       "149319 -103.617873  NAD83  12812.00                      NaN    New Mexico   \n",
       "178445   -0.123450  NAD27   2442.00                  22134.0      Arkansas   \n",
       "206589 -101.808518  NAD83   8262.00               17519292.0          Utah   \n",
       "213811  -88.505110  WGS84   5250.00                      NaN   Mississippi   \n",
       "\n",
       "       county_name  ff_version  is_federal_well  is_indian_well  \\\n",
       "61454    Glasscock           3            False           False   \n",
       "61965         Clay           3            False           False   \n",
       "62626         Jack           3            False           False   \n",
       "84840        Upton           1            False           False   \n",
       "89052    Glasscock           1            False           False   \n",
       "89305       Dawson           1            False           False   \n",
       "98083         Webb           3            False           False   \n",
       "98087         Webb           3            False           False   \n",
       "139253         NaN           3            False           False   \n",
       "139256         NaN           3            False           False   \n",
       "149319         Lea           3             True           False   \n",
       "178445         NaN           3            False           False   \n",
       "206589         NaN           3            False           False   \n",
       "213811      Monroe           3            False           False   \n",
       "\n",
       "        job_start_year  job_start_month  job_start_day  job_end_year  \\\n",
       "61454           2017.0              4.0           10.0        2017.0   \n",
       "61965           2017.0              5.0            8.0        2017.0   \n",
       "62626           2017.0              6.0           13.0        2017.0   \n",
       "84840           2020.0              4.0           19.0        2020.0   \n",
       "89052           2021.0              5.0           23.0        2021.0   \n",
       "89305           2021.0              6.0            8.0        2021.0   \n",
       "98083           2022.0             10.0           16.0        2022.0   \n",
       "98087           2022.0             10.0           16.0        2022.0   \n",
       "139253          2022.0              5.0           28.0        2022.0   \n",
       "139256          2022.0              5.0           28.0        2022.0   \n",
       "149319          2021.0             12.0           16.0        2021.0   \n",
       "178445          2019.0             11.0           19.0        2019.0   \n",
       "206589          2020.0             11.0           11.0        2020.0   \n",
       "213811          2022.0              9.0           28.0        2022.0   \n",
       "\n",
       "        job_end_month  job_end_day             api state_code county_code  \\\n",
       "61454             4.0         10.0  42173374020000         42         173   \n",
       "61965             5.0          8.0  42077352710000         42         077   \n",
       "62626             6.0         13.0  42237401310000         42         237   \n",
       "84840             4.0         19.0  42461378800000         42         461   \n",
       "89052             5.0         23.0  42173346750000         42         173   \n",
       "89305             6.0          8.0  42115334560000         42         115   \n",
       "98083            10.0         27.0  42479446890000         42         479   \n",
       "98087            10.0         27.0  42479446880000         42         479   \n",
       "139253            6.0          8.0  33610338000000         33         610   \n",
       "139256            6.0          9.0  33610338100000         33         610   \n",
       "149319           12.0         23.0  30025466380000         30         025   \n",
       "178445           11.0         19.0  03729439000000         03         729   \n",
       "206589           12.0          1.0  43317428660000         43         317   \n",
       "213811            9.0         28.0  23095201430000         23         095   \n",
       "\n",
       "               state  \n",
       "61454          Texas  \n",
       "61965          Texas  \n",
       "62626          Texas  \n",
       "84840          Texas  \n",
       "89052          Texas  \n",
       "89305          Texas  \n",
       "98083          Texas  \n",
       "98087          Texas  \n",
       "139253  North Dakota  \n",
       "139256  North Dakota  \n",
       "149319    New Mexico  \n",
       "178445      Arkansas  \n",
       "206589          Utah  \n",
       "213811   Mississippi  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mask for from 2013 onwards\n",
    "post_2012_mask = registry_df[\"job_start_date\"] >= \"2013-01-01\"\n",
    "registry_df_post_2012 = registry_df[post_2012_mask].copy()\n",
    "\n",
    "# find all the rows with null values\n",
    "null_mask = registry_df_post_2012.isna().any(axis=1)\n",
    "registry_df_post_2012[null_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how many nans we still have in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_df_post_2012.info(memory_usage=\"deep\")\n",
    "registry_df_post_2012.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the `county_number` for the rows with a nan value in the `county_name` column, we can see why there is a nan for the `county_name`. Those numbers are most likely incorrect as small states like `North Dakota` and `Arkansas` do not have large `county_number` values. However we can still try to impute what the correct values by cross referencing with other sources or by using the `latitude` and `longitude` values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the rows with a null value for the county_name column\n",
    "registry_df_post_2012[registry_df_post_2012[\"county_name\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# get the index of one of the rows with a null value for the county_name column (3rd one down)\n",
    "index_vanorsdale = registry_df_post_2012.query(\"api_number == '03729439000000'\").index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oklahoma Commission Corporation (OOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some search engine investigating, we can learn that WFD Oil Corporation is a PC in Oklahoma. We also learn that the well name is `VANORSDOL` ,the well number is `#1-29`, and the API number is `3503729439` `0000`. We can correct some of the data which was entered incorrectly in FracFocus.\n",
    "\n",
    "The data are looking for is in this markdown cell so we can manually input it in but we will do it through code instead. We will query the api number in the data we have on the wells in OK.\n",
    "\n",
    "| Column Name | Value |\n",
    "| --- | --- |\n",
    "API\t|3503729439\n",
    "WELL_NAME|\tVANORSDOL\n",
    "WELL_NUM|\t#1-29\n",
    "OPERATOR|\tWFD OIL CORPORATION\n",
    "WELLSTATUS|\tAC\n",
    "WELLTYPE|\tOIL\n",
    "SH_LAT\t|35.749381\n",
    "SH_LON\t|-96.370355\n",
    "COUNTY\t|CREEK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 445575 entries, 0 to 445574\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   objectid           445575 non-null  int64   \n",
      " 1   api                445575 non-null  float64 \n",
      " 2   well_browse_link   445575 non-null  object  \n",
      " 3   well_records_docs  445575 non-null  object  \n",
      " 4   well_name          445568 non-null  object  \n",
      " 5   well_num           445570 non-null  object  \n",
      " 6   operator           445575 non-null  object  \n",
      " 7   wellstatus         443813 non-null  object  \n",
      " 8   welltype           365021 non-null  object  \n",
      " 9   symbol_class       445575 non-null  object  \n",
      " 10  sh_lat             437073 non-null  float64 \n",
      " 11  sh_lon             437073 non-null  float64 \n",
      " 12  county             445575 non-null  object  \n",
      " 13  section            445454 non-null  float64 \n",
      " 14  township           445450 non-null  object  \n",
      " 15  range              445575 non-null  object  \n",
      " 16  qtr4               143201 non-null  object  \n",
      " 17  qtr3               363463 non-null  object  \n",
      " 18  qtr2               419921 non-null  object  \n",
      " 19  qtr1               444912 non-null  object  \n",
      " 20  pm                 444882 non-null  object  \n",
      " 21  footage_ew         441608 non-null  float64 \n",
      " 22  ew                 340280 non-null  object  \n",
      " 23  footage_ns         441597 non-null  float64 \n",
      " 24  ns                 340350 non-null  object  \n",
      " 25  geometry           437073 non-null  geometry\n",
      " 26  crs                445575 non-null  object  \n",
      "dtypes: float64(6), geometry(1), int64(1), object(19)\n",
      "memory usage: 91.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid</th>\n",
       "      <th>api</th>\n",
       "      <th>well_browse_link</th>\n",
       "      <th>well_records_docs</th>\n",
       "      <th>well_name</th>\n",
       "      <th>well_num</th>\n",
       "      <th>operator</th>\n",
       "      <th>wellstatus</th>\n",
       "      <th>welltype</th>\n",
       "      <th>symbol_class</th>\n",
       "      <th>sh_lat</th>\n",
       "      <th>sh_lon</th>\n",
       "      <th>county</th>\n",
       "      <th>section</th>\n",
       "      <th>township</th>\n",
       "      <th>range</th>\n",
       "      <th>qtr4</th>\n",
       "      <th>qtr3</th>\n",
       "      <th>qtr2</th>\n",
       "      <th>qtr1</th>\n",
       "      <th>pm</th>\n",
       "      <th>footage_ew</th>\n",
       "      <th>ew</th>\n",
       "      <th>footage_ns</th>\n",
       "      <th>ns</th>\n",
       "      <th>geometry</th>\n",
       "      <th>crs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343803</th>\n",
       "      <td>343804</td>\n",
       "      <td>3.513101e+09</td>\n",
       "      <td>http://wellbrowse.occ.ok.gov/Webforms/WellInfo...</td>\n",
       "      <td>https://public.occ.ok.gov/OGCDWebLink/Search.a...</td>\n",
       "      <td>ENGERSOL</td>\n",
       "      <td>#1</td>\n",
       "      <td>OTC/OCC NOT ASSIGNED</td>\n",
       "      <td>PA</td>\n",
       "      <td>DRY</td>\n",
       "      <td>PLUGGED</td>\n",
       "      <td>36.32894</td>\n",
       "      <td>-95.44452</td>\n",
       "      <td>ROGERS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21N</td>\n",
       "      <td>17E</td>\n",
       "      <td>None</td>\n",
       "      <td>NE</td>\n",
       "      <td>NE</td>\n",
       "      <td>SE</td>\n",
       "      <td>IM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (-95.44452 36.32894)</td>\n",
       "      <td>EPSG:4326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        objectid           api  \\\n",
       "343803    343804  3.513101e+09   \n",
       "\n",
       "                                         well_browse_link  \\\n",
       "343803  http://wellbrowse.occ.ok.gov/Webforms/WellInfo...   \n",
       "\n",
       "                                        well_records_docs well_name well_num  \\\n",
       "343803  https://public.occ.ok.gov/OGCDWebLink/Search.a...  ENGERSOL       #1   \n",
       "\n",
       "                    operator wellstatus welltype symbol_class    sh_lat  \\\n",
       "343803  OTC/OCC NOT ASSIGNED         PA      DRY      PLUGGED  36.32894   \n",
       "\n",
       "          sh_lon  county  section township range  qtr4 qtr3 qtr2 qtr1  pm  \\\n",
       "343803 -95.44452  ROGERS      1.0      21N   17E  None   NE   NE   SE  IM   \n",
       "\n",
       "        footage_ew    ew  footage_ns    ns                    geometry  \\\n",
       "343803         0.0  None         0.0  None  POINT (-95.44452 36.32894)   \n",
       "\n",
       "              crs  \n",
       "343803  EPSG:4326  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When reading the Parquet file\n",
    "occ_wells = pd.read_parquet(OCC_PARQUET_URL)\n",
    "# Convert the WKT column back to a geometry column\n",
    "occ_wells[\"geometry\"] = occ_wells[\"geometry\"].apply(lambda x: wkt.loads(x))\n",
    "\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame, specifying the CRS\n",
    "occ_wells = gpd.GeoDataFrame(\n",
    "    occ_wells, geometry=\"geometry\", crs=occ_wells[\"crs\"].iloc[0]\n",
    ")\n",
    "occ_wells.info()\n",
    "# look at 1 sample row of the dataframe\n",
    "occ_wells.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectid</th>\n",
       "      <th>api</th>\n",
       "      <th>well_browse_link</th>\n",
       "      <th>well_records_docs</th>\n",
       "      <th>well_name</th>\n",
       "      <th>well_num</th>\n",
       "      <th>operator</th>\n",
       "      <th>wellstatus</th>\n",
       "      <th>welltype</th>\n",
       "      <th>symbol_class</th>\n",
       "      <th>sh_lat</th>\n",
       "      <th>sh_lon</th>\n",
       "      <th>county</th>\n",
       "      <th>section</th>\n",
       "      <th>township</th>\n",
       "      <th>range</th>\n",
       "      <th>qtr4</th>\n",
       "      <th>qtr3</th>\n",
       "      <th>qtr2</th>\n",
       "      <th>qtr1</th>\n",
       "      <th>pm</th>\n",
       "      <th>footage_ew</th>\n",
       "      <th>ew</th>\n",
       "      <th>footage_ns</th>\n",
       "      <th>ns</th>\n",
       "      <th>geometry</th>\n",
       "      <th>crs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168044</th>\n",
       "      <td>168045</td>\n",
       "      <td>3507120763</td>\n",
       "      <td>http://wellbrowse.occ.ok.gov/Webforms/WellInfo...</td>\n",
       "      <td>https://public.occ.ok.gov/OGCDWebLink/Search.a...</td>\n",
       "      <td>BICENTENNIAL</td>\n",
       "      <td>#1</td>\n",
       "      <td>JEFFRIES PUMPING SERVICE INC</td>\n",
       "      <td>AC</td>\n",
       "      <td>OIL</td>\n",
       "      <td>OIL</td>\n",
       "      <td>36.829925</td>\n",
       "      <td>-96.96361</td>\n",
       "      <td>KAY</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27N</td>\n",
       "      <td>03E</td>\n",
       "      <td>None</td>\n",
       "      <td>SE</td>\n",
       "      <td>NW</td>\n",
       "      <td>SE</td>\n",
       "      <td>IM</td>\n",
       "      <td>990.0</td>\n",
       "      <td>W</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>S</td>\n",
       "      <td>POINT (-96.96361 36.82993)</td>\n",
       "      <td>EPSG:4326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        objectid         api  \\\n",
       "168044    168045  3507120763   \n",
       "\n",
       "                                         well_browse_link  \\\n",
       "168044  http://wellbrowse.occ.ok.gov/Webforms/WellInfo...   \n",
       "\n",
       "                                        well_records_docs     well_name  \\\n",
       "168044  https://public.occ.ok.gov/OGCDWebLink/Search.a...  BICENTENNIAL   \n",
       "\n",
       "       well_num                      operator wellstatus welltype  \\\n",
       "168044       #1  JEFFRIES PUMPING SERVICE INC         AC      OIL   \n",
       "\n",
       "       symbol_class     sh_lat    sh_lon county  section township range  qtr4  \\\n",
       "168044          OIL  36.829925 -96.96361    KAY     10.0      27N   03E  None   \n",
       "\n",
       "       qtr3 qtr2 qtr1  pm  footage_ew ew  footage_ns ns  \\\n",
       "168044   SE   NW   SE  IM       990.0  W      1650.0  S   \n",
       "\n",
       "                          geometry        crs  \n",
       "168044  POINT (-96.96361 36.82993)  EPSG:4326  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'api' column to string\n",
    "occ_wells[\"api\"] = occ_wells[\"api\"].astype(\"int64\").astype(\"string\")\n",
    "occ_wells.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# make a copy of the well_name column\n",
    "registry_df_post_2012[\"well\"] = registry_df_post_2012[\"well_name\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_key</th>\n",
       "      <th>job_start_date</th>\n",
       "      <th>job_end_date</th>\n",
       "      <th>api_number</th>\n",
       "      <th>state_number</th>\n",
       "      <th>county_number</th>\n",
       "      <th>operator_name</th>\n",
       "      <th>well_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>crs</th>\n",
       "      <th>tvd</th>\n",
       "      <th>total_base_water_volume</th>\n",
       "      <th>state_name</th>\n",
       "      <th>county_name</th>\n",
       "      <th>ff_version</th>\n",
       "      <th>is_federal_well</th>\n",
       "      <th>is_indian_well</th>\n",
       "      <th>job_start_year</th>\n",
       "      <th>job_start_month</th>\n",
       "      <th>job_start_day</th>\n",
       "      <th>job_end_year</th>\n",
       "      <th>job_end_month</th>\n",
       "      <th>job_end_day</th>\n",
       "      <th>api</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_code</th>\n",
       "      <th>state</th>\n",
       "      <th>well</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [p_key, job_start_date, job_end_date, api_number, state_number, county_number, operator_name, well_name, latitude, longitude, crs, tvd, total_base_water_volume, state_name, county_name, ff_version, is_federal_well, is_indian_well, job_start_year, job_start_month, job_start_day, job_end_year, job_end_month, job_end_day, api, state_code, county_code, state, well]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry_df_post_2012[registry_df_post_2012[\"api\"].str.contains(\"11533124\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api</th>\n",
       "      <th>well</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178445</th>\n",
       "      <td>3503729439</td>\n",
       "      <td>Vanorsdol #1-29</td>\n",
       "      <td>35.749381</td>\n",
       "      <td>-96.370355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               api             well   latitude  longitude\n",
       "178445  3503729439  Vanorsdol #1-29  35.749381 -96.370355"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query the well_name column for 'vanors\n",
    "# occ_wells[occ_wells[\"well_name\"].str.contains(\"vanors\", case=False, na=False)]\n",
    "vanorsdol_row = occ_wells.query(\n",
    "    'well_name.fillna(\"\").str.contains(\"vanors\", case=False) & (api == \"3503729439\")',\n",
    ")[\n",
    "    [\n",
    "        \"api\",\n",
    "        \"well_name\",\n",
    "        \"well_num\",\n",
    "        \"operator\",\n",
    "        \"sh_lat\",\n",
    "        \"sh_lon\",\n",
    "        \"county\",\n",
    "    ]\n",
    "].rename(\n",
    "    columns={\"sh_lat\": \"latitude\", \"sh_lon\": \"longitude\"}\n",
    ")\n",
    "vanorsdol_row[\"well\"] = (\n",
    "    vanorsdol_row[\"well_name\"].str.title()\n",
    "    + \" \"\n",
    "    + vanorsdol_row[\"well_num\"].astype(\"string\")\n",
    ")\n",
    "index_vanorsdol = vanorsdol_row.index\n",
    "\n",
    "columns_to_replace = [\"api\", \"well\", \"latitude\", \"longitude\"]\n",
    "for col in columns_to_replace:\n",
    "    registry_df_post_2012.loc[index_vanorsdale, col] = vanorsdol_row.loc[\n",
    "        index_vanorsdol, col\n",
    "    ].values\n",
    "\n",
    "# check that the values have been replaced\n",
    "registry_df_post_2012.loc[index_vanorsdale, columns_to_replace]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the api column to 14 characters again\n",
    "registry_df_post_2012[\"api\"] = registry_df_post_2012[\"api\"].str.ljust(14, \"0\")\n",
    "\n",
    "registry_df_post_2012[registry_df_post_2012[\"county_name\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with `latitude` and `longitude` coordinates for all 4 rows with missing `county_name`, let's find out which counties they belong to spatially.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geodataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the boundary coordinates for all the counties in the US from the [census.gov](https://www.census.gov/) website. We saved the URL for this as `CENSUS_COUNTY_MAP_URL` at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>statefp</th>\n",
       "      <th>countyfp</th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>48167</td>\n",
       "      <td>48</td>\n",
       "      <td>167</td>\n",
       "      <td>Galveston</td>\n",
       "      <td>POLYGON ((-95.23298 29.46616, -95.23294 29.466...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>08107</td>\n",
       "      <td>08</td>\n",
       "      <td>107</td>\n",
       "      <td>Routt</td>\n",
       "      <td>POLYGON ((-106.65274 40.38897, -106.65274 40.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>19027</td>\n",
       "      <td>19</td>\n",
       "      <td>027</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>POLYGON ((-94.74490 42.20952, -94.74389 42.209...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      geoid statefp countyfp       name  \\\n",
       "1313  48167      48      167  Galveston   \n",
       "1692  08107      08      107      Routt   \n",
       "184   19027      19      027    Carroll   \n",
       "\n",
       "                                               geometry  \n",
       "1313  POLYGON ((-95.23298 29.46616, -95.23294 29.466...  \n",
       "1692  POLYGON ((-106.65274 40.38897, -106.65274 40.3...  \n",
       "184   POLYGON ((-94.74490 42.20952, -94.74389 42.209...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the US countiesmap data\n",
    "county_gdf = get_county_data()\n",
    "county_gdf.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will scrape the FIPS table from wikipedia since the county dataframe does not have the state name and merge the 2 tables just for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>36015</td>\n",
       "      <td>Chemung County</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>36071</td>\n",
       "      <td>Orange County</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>19187</td>\n",
       "      <td>Webster County</td>\n",
       "      <td>Iowa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      geoid          county     state\n",
       "1842  36015  Chemung County  New York\n",
       "1870  36071   Orange County  New York\n",
       "889   19187  Webster County      Iowa"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fips_df = pd.read_html(FIPS_WIKI_URL)[1]\n",
    "fips_df.columns = [\"geoid\", \"county\", \"state\"]\n",
    "fips_df[\"geoid\"] = fips_df[\"geoid\"].astype(\"string\").str.zfill(5)\n",
    "fips_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geoid</th>\n",
       "      <th>statefp</th>\n",
       "      <th>countyfp</th>\n",
       "      <th>name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>31045</td>\n",
       "      <td>31</td>\n",
       "      <td>045</td>\n",
       "      <td>Dawes</td>\n",
       "      <td>POLYGON ((-102.77315 42.52564, -102.77298 42.5...</td>\n",
       "      <td>Dawes County</td>\n",
       "      <td>Nebraska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>51149</td>\n",
       "      <td>51</td>\n",
       "      <td>149</td>\n",
       "      <td>Prince George</td>\n",
       "      <td>POLYGON ((-77.13939 37.12645, -77.14097 37.125...</td>\n",
       "      <td>Prince George County</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>22015</td>\n",
       "      <td>22</td>\n",
       "      <td>015</td>\n",
       "      <td>Bossier</td>\n",
       "      <td>POLYGON ((-93.84522 32.95043, -93.84486 32.951...</td>\n",
       "      <td>Bossier Parish</td>\n",
       "      <td>Louisiana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      geoid statefp countyfp           name  \\\n",
       "824   31045      31      045          Dawes   \n",
       "3058  51149      51      149  Prince George   \n",
       "2315  22015      22      015        Bossier   \n",
       "\n",
       "                                               geometry                county  \\\n",
       "824   POLYGON ((-102.77315 42.52564, -102.77298 42.5...          Dawes County   \n",
       "3058  POLYGON ((-77.13939 37.12645, -77.14097 37.125...  Prince George County   \n",
       "2315  POLYGON ((-93.84522 32.95043, -93.84486 32.951...        Bossier Parish   \n",
       "\n",
       "          state  \n",
       "824    Nebraska  \n",
       "3058   Virginia  \n",
       "2315  Louisiana  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_fips_gdf = county_gdf.merge(fips_df, on=\"geoid\")\n",
    "county_fips_gdf.sample(3, random_state=628)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick note about `GeoDataFrames`: they must have a column called `geometry` and this column contains the geometric objects. This call is what enables `geopandas` to perform spatial operations, and can also contain certain attributes like `.crs` which is the coordinate reference system.\n",
    "\n",
    "\n",
    "Commonly used datums in North America are NAD27, NAD83, and WGS84. More info [here](https://webhelp.esri.com/arcgisdesktop/9.3/index.cfm?TopicName=Projection_basics_the_GIS_professional_needs_to_know).<br>\n",
    "\n",
    "The county geodataframe uses `EPSG:4269` which is the EPSG code for the NAD83 coordinate system. Let's create a geodataframe with the `latitude` and `longitude` values that we have and put all of the points to the same CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_fips_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# ensures each row of the geodataframe is in the same CRS\n",
    "registry_gdf = unify_crs(registry_df_post_2012, crs_col=\"crs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crs</th>\n",
       "      <th>geometry</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>p_key</th>\n",
       "      <th>tvd</th>\n",
       "      <th>is_indian_well</th>\n",
       "      <th>state_left</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_number</th>\n",
       "      <th>well</th>\n",
       "      <th>operator_name</th>\n",
       "      <th>county_number</th>\n",
       "      <th>county_name</th>\n",
       "      <th>api</th>\n",
       "      <th>county_code</th>\n",
       "      <th>job_end_date</th>\n",
       "      <th>job_start_year</th>\n",
       "      <th>job_start_day</th>\n",
       "      <th>api_number</th>\n",
       "      <th>job_start_month</th>\n",
       "      <th>job_start_date</th>\n",
       "      <th>is_federal_well</th>\n",
       "      <th>well_name</th>\n",
       "      <th>total_base_water_volume</th>\n",
       "      <th>ff_version</th>\n",
       "      <th>job_end_year</th>\n",
       "      <th>job_end_month</th>\n",
       "      <th>job_end_day</th>\n",
       "      <th>state_code</th>\n",
       "      <th>geoid</th>\n",
       "      <th>statefp</th>\n",
       "      <th>countyfp</th>\n",
       "      <th>name</th>\n",
       "      <th>state_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178445</th>\n",
       "      <td>NAD27</td>\n",
       "      <td>POINT (-96.37064 35.74946)</td>\n",
       "      <td>35.749381</td>\n",
       "      <td>-96.370355</td>\n",
       "      <td>692d9381-748e-4e5f-b83f-30f868f18882</td>\n",
       "      <td>2442.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>Vanorsdol #1-29</td>\n",
       "      <td>WFD Oil Corporation</td>\n",
       "      <td>729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3503729439</td>\n",
       "      <td>729</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>03729439000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>False</td>\n",
       "      <td>Vanorsdale</td>\n",
       "      <td>22134.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>03</td>\n",
       "      <td>40037</td>\n",
       "      <td>40</td>\n",
       "      <td>037</td>\n",
       "      <td>Creek</td>\n",
       "      <td>Oklahoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139253</th>\n",
       "      <td>NAD83</td>\n",
       "      <td>POINT (-102.21212 48.35551)</td>\n",
       "      <td>48.355506</td>\n",
       "      <td>-102.212124</td>\n",
       "      <td>0f8e944c-87d7-4d84-8d56-4b8a5f1cba94</td>\n",
       "      <td>8872.40</td>\n",
       "      <td>False</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>33</td>\n",
       "      <td>TRULSON 156-90-11-14H-3</td>\n",
       "      <td>Hunt Oil Company</td>\n",
       "      <td>610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33610338000000</td>\n",
       "      <td>610</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33610338000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>False</td>\n",
       "      <td>TRULSON 156-90-11-14H-3</td>\n",
       "      <td>13496802.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33</td>\n",
       "      <td>38061</td>\n",
       "      <td>38</td>\n",
       "      <td>061</td>\n",
       "      <td>Mountrail</td>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139256</th>\n",
       "      <td>NAD83</td>\n",
       "      <td>POINT (-102.21233 48.35551)</td>\n",
       "      <td>48.355506</td>\n",
       "      <td>-102.212330</td>\n",
       "      <td>6e5d8284-29d1-4b3d-a72c-729d95c327de</td>\n",
       "      <td>8782.65</td>\n",
       "      <td>False</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>33</td>\n",
       "      <td>PALERMO 156-90-2-31H-5</td>\n",
       "      <td>Hunt Oil Company</td>\n",
       "      <td>610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33610338100000</td>\n",
       "      <td>610</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33610338100000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>False</td>\n",
       "      <td>PALERMO 156-90-2-31H-5</td>\n",
       "      <td>14820967.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33</td>\n",
       "      <td>38061</td>\n",
       "      <td>38</td>\n",
       "      <td>061</td>\n",
       "      <td>Mountrail</td>\n",
       "      <td>North Dakota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206589</th>\n",
       "      <td>NAD83</td>\n",
       "      <td>POINT (-101.80852 32.40914)</td>\n",
       "      <td>32.409144</td>\n",
       "      <td>-101.808518</td>\n",
       "      <td>87ea1a50-ab40-4956-8051-d39bf139ae53</td>\n",
       "      <td>8262.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Utah</td>\n",
       "      <td>43</td>\n",
       "      <td>Rhea 1-6 Unit 1 #133</td>\n",
       "      <td>Endeavor Energy Resources</td>\n",
       "      <td>317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43317428660000</td>\n",
       "      <td>317</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43317428660000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2020-11-11</td>\n",
       "      <td>False</td>\n",
       "      <td>Rhea 1-6 Unit 1 #133</td>\n",
       "      <td>17519292.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>48317</td>\n",
       "      <td>48</td>\n",
       "      <td>317</td>\n",
       "      <td>Martin</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          crs                     geometry   latitude   longitude  \\\n",
       "178445  NAD27   POINT (-96.37064 35.74946)  35.749381  -96.370355   \n",
       "139253  NAD83  POINT (-102.21212 48.35551)  48.355506 -102.212124   \n",
       "139256  NAD83  POINT (-102.21233 48.35551)  48.355506 -102.212330   \n",
       "206589  NAD83  POINT (-101.80852 32.40914)  32.409144 -101.808518   \n",
       "\n",
       "                                       p_key      tvd  is_indian_well  \\\n",
       "178445  692d9381-748e-4e5f-b83f-30f868f18882  2442.00           False   \n",
       "139253  0f8e944c-87d7-4d84-8d56-4b8a5f1cba94  8872.40           False   \n",
       "139256  6e5d8284-29d1-4b3d-a72c-729d95c327de  8782.65           False   \n",
       "206589  87ea1a50-ab40-4956-8051-d39bf139ae53  8262.00           False   \n",
       "\n",
       "          state_left    state_name  state_number                     well  \\\n",
       "178445      Arkansas      Arkansas             3          Vanorsdol #1-29   \n",
       "139253  North Dakota  North Dakota            33  TRULSON 156-90-11-14H-3   \n",
       "139256  North Dakota  North Dakota            33   PALERMO 156-90-2-31H-5   \n",
       "206589          Utah          Utah            43     Rhea 1-6 Unit 1 #133   \n",
       "\n",
       "                    operator_name  county_number county_name             api  \\\n",
       "178445        WFD Oil Corporation            729         NaN      3503729439   \n",
       "139253           Hunt Oil Company            610         NaN  33610338000000   \n",
       "139256           Hunt Oil Company            610         NaN  33610338100000   \n",
       "206589  Endeavor Energy Resources            317         NaN  43317428660000   \n",
       "\n",
       "       county_code job_end_date  job_start_year  job_start_day  \\\n",
       "178445         729   2019-11-19          2019.0           19.0   \n",
       "139253         610   2022-06-08          2022.0           28.0   \n",
       "139256         610   2022-06-09          2022.0           28.0   \n",
       "206589         317   2020-12-01          2020.0           11.0   \n",
       "\n",
       "            api_number  job_start_month job_start_date  is_federal_well  \\\n",
       "178445  03729439000000             11.0     2019-11-19            False   \n",
       "139253  33610338000000              5.0     2022-05-28            False   \n",
       "139256  33610338100000              5.0     2022-05-28            False   \n",
       "206589  43317428660000             11.0     2020-11-11            False   \n",
       "\n",
       "                      well_name  total_base_water_volume  ff_version  \\\n",
       "178445               Vanorsdale                  22134.0           3   \n",
       "139253  TRULSON 156-90-11-14H-3               13496802.0           3   \n",
       "139256   PALERMO 156-90-2-31H-5               14820967.0           3   \n",
       "206589     Rhea 1-6 Unit 1 #133               17519292.0           3   \n",
       "\n",
       "        job_end_year  job_end_month  job_end_day state_code  geoid statefp  \\\n",
       "178445        2019.0           11.0         19.0         03  40037      40   \n",
       "139253        2022.0            6.0          8.0         33  38061      38   \n",
       "139256        2022.0            6.0          9.0         33  38061      38   \n",
       "206589        2020.0           12.0          1.0         43  48317      48   \n",
       "\n",
       "       countyfp       name   state_right  \n",
       "178445      037      Creek      Oklahoma  \n",
       "139253      061  Mountrail  North Dakota  \n",
       "139256      061  Mountrail  North Dakota  \n",
       "206589      317     Martin         Texas  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now perform a spatial join on the 2 GeoDataFrame.\n",
    "# fitler for rows with null county_name\n",
    "\n",
    "joined_gdf = (\n",
    "    registry_gdf[registry_gdf[\"county_name\"].isna()]\n",
    "    .sjoin(county_fips_gdf.drop(columns=[\"county\"]), how=\"left\", predicate=\"intersects\")\n",
    "    .drop(columns=[\"index_right\"])\n",
    ")\n",
    "joined_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `North Dakota` `county_number` should be `061`, which is `Mountrail` county, not `610`. \n",
    "- The `Utah` `county_number` though was actually correct. The error was the state number which should have been `42`, not `43`. This error is somewhat significant as according to the data dictionary:\n",
    "> APINumber - The American Petroleum Institute well identification number formatted as follows xx-xxx-xxxxx0000 Where: First two digits \n",
    "represent the state, second three digits represent the county, third 5 digits represent the well.<br>\n",
    "\n",
    "All this means is the `api` number is also incorrect. It should be `42317428660000` (<u><b>42</b></u>-317-42866-0000) instead of `43317428660000` (<u><b>43</b></u>-317-42866-0000).<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_code_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crs</th>\n",
       "      <th>geometry</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>p_key</th>\n",
       "      <th>tvd</th>\n",
       "      <th>is_indian_well</th>\n",
       "      <th>state</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_number</th>\n",
       "      <th>well</th>\n",
       "      <th>operator_name</th>\n",
       "      <th>county_number</th>\n",
       "      <th>county_name</th>\n",
       "      <th>api</th>\n",
       "      <th>county_code</th>\n",
       "      <th>job_end_date</th>\n",
       "      <th>job_start_year</th>\n",
       "      <th>job_start_day</th>\n",
       "      <th>api_number</th>\n",
       "      <th>job_start_month</th>\n",
       "      <th>job_start_date</th>\n",
       "      <th>is_federal_well</th>\n",
       "      <th>well_name</th>\n",
       "      <th>total_base_water_volume</th>\n",
       "      <th>ff_version</th>\n",
       "      <th>job_end_year</th>\n",
       "      <th>job_end_month</th>\n",
       "      <th>job_end_day</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178445</th>\n",
       "      <td>NAD27</td>\n",
       "      <td>POINT (-96.37064 35.74946)</td>\n",
       "      <td>35.749381</td>\n",
       "      <td>-96.370355</td>\n",
       "      <td>692d9381-748e-4e5f-b83f-30f868f18882</td>\n",
       "      <td>2442.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3</td>\n",
       "      <td>Vanorsdol #1-29</td>\n",
       "      <td>WFD Oil Corporation</td>\n",
       "      <td>729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3503729439</td>\n",
       "      <td>037</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>03729439000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2019-11-19</td>\n",
       "      <td>False</td>\n",
       "      <td>Vanorsdale</td>\n",
       "      <td>22134.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35</td>\n",
       "      <td>Creek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139253</th>\n",
       "      <td>NAD83</td>\n",
       "      <td>POINT (-102.21212 48.35551)</td>\n",
       "      <td>48.355506</td>\n",
       "      <td>-102.212124</td>\n",
       "      <td>0f8e944c-87d7-4d84-8d56-4b8a5f1cba94</td>\n",
       "      <td>8872.40</td>\n",
       "      <td>False</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>33</td>\n",
       "      <td>TRULSON 156-90-11-14H-3</td>\n",
       "      <td>Hunt Oil Company</td>\n",
       "      <td>610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33610338000000</td>\n",
       "      <td>061</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33610338000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>False</td>\n",
       "      <td>TRULSON 156-90-11-14H-3</td>\n",
       "      <td>13496802.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33</td>\n",
       "      <td>Mountrail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139256</th>\n",
       "      <td>NAD83</td>\n",
       "      <td>POINT (-102.21233 48.35551)</td>\n",
       "      <td>48.355506</td>\n",
       "      <td>-102.212330</td>\n",
       "      <td>6e5d8284-29d1-4b3d-a72c-729d95c327de</td>\n",
       "      <td>8782.65</td>\n",
       "      <td>False</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>33</td>\n",
       "      <td>PALERMO 156-90-2-31H-5</td>\n",
       "      <td>Hunt Oil Company</td>\n",
       "      <td>610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33610338100000</td>\n",
       "      <td>061</td>\n",
       "      <td>2022-06-09</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33610338100000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-05-28</td>\n",
       "      <td>False</td>\n",
       "      <td>PALERMO 156-90-2-31H-5</td>\n",
       "      <td>14820967.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33</td>\n",
       "      <td>Mountrail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206589</th>\n",
       "      <td>NAD83</td>\n",
       "      <td>POINT (-101.80852 32.40914)</td>\n",
       "      <td>32.409144</td>\n",
       "      <td>-101.808518</td>\n",
       "      <td>87ea1a50-ab40-4956-8051-d39bf139ae53</td>\n",
       "      <td>8262.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Utah</td>\n",
       "      <td>43</td>\n",
       "      <td>Rhea 1-6 Unit 1 #133</td>\n",
       "      <td>Endeavor Energy Resources</td>\n",
       "      <td>317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42317428660000</td>\n",
       "      <td>317</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43317428660000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2020-11-11</td>\n",
       "      <td>False</td>\n",
       "      <td>Rhea 1-6 Unit 1 #133</td>\n",
       "      <td>17519292.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Martin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          crs                     geometry   latitude   longitude  \\\n",
       "178445  NAD27   POINT (-96.37064 35.74946)  35.749381  -96.370355   \n",
       "139253  NAD83  POINT (-102.21212 48.35551)  48.355506 -102.212124   \n",
       "139256  NAD83  POINT (-102.21233 48.35551)  48.355506 -102.212330   \n",
       "206589  NAD83  POINT (-101.80852 32.40914)  32.409144 -101.808518   \n",
       "\n",
       "                                       p_key      tvd  is_indian_well  \\\n",
       "178445  692d9381-748e-4e5f-b83f-30f868f18882  2442.00           False   \n",
       "139253  0f8e944c-87d7-4d84-8d56-4b8a5f1cba94  8872.40           False   \n",
       "139256  6e5d8284-29d1-4b3d-a72c-729d95c327de  8782.65           False   \n",
       "206589  87ea1a50-ab40-4956-8051-d39bf139ae53  8262.00           False   \n",
       "\n",
       "               state    state_name  state_number                     well  \\\n",
       "178445      Oklahoma      Arkansas             3          Vanorsdol #1-29   \n",
       "139253  North Dakota  North Dakota            33  TRULSON 156-90-11-14H-3   \n",
       "139256  North Dakota  North Dakota            33   PALERMO 156-90-2-31H-5   \n",
       "206589         Texas          Utah            43     Rhea 1-6 Unit 1 #133   \n",
       "\n",
       "                    operator_name  county_number county_name             api  \\\n",
       "178445        WFD Oil Corporation            729         NaN      3503729439   \n",
       "139253           Hunt Oil Company            610         NaN  33610338000000   \n",
       "139256           Hunt Oil Company            610         NaN  33610338100000   \n",
       "206589  Endeavor Energy Resources            317         NaN  42317428660000   \n",
       "\n",
       "       county_code job_end_date  job_start_year  job_start_day  \\\n",
       "178445         037   2019-11-19          2019.0           19.0   \n",
       "139253         061   2022-06-08          2022.0           28.0   \n",
       "139256         061   2022-06-09          2022.0           28.0   \n",
       "206589         317   2020-12-01          2020.0           11.0   \n",
       "\n",
       "            api_number  job_start_month job_start_date  is_federal_well  \\\n",
       "178445  03729439000000             11.0     2019-11-19            False   \n",
       "139253  33610338000000              5.0     2022-05-28            False   \n",
       "139256  33610338100000              5.0     2022-05-28            False   \n",
       "206589  43317428660000             11.0     2020-11-11            False   \n",
       "\n",
       "                      well_name  total_base_water_volume  ff_version  \\\n",
       "178445               Vanorsdale                  22134.0           3   \n",
       "139253  TRULSON 156-90-11-14H-3               13496802.0           3   \n",
       "139256   PALERMO 156-90-2-31H-5               14820967.0           3   \n",
       "206589     Rhea 1-6 Unit 1 #133               17519292.0           3   \n",
       "\n",
       "        job_end_year  job_end_month  job_end_day state_code     county  \n",
       "178445        2019.0           11.0         19.0         35      Creek  \n",
       "139253        2022.0            6.0          8.0         33  Mountrail  \n",
       "139256        2022.0            6.0          9.0         33  Mountrail  \n",
       "206589        2020.0           12.0          1.0         42     Martin  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's corect theos values putting the county_code and\n",
    "registry_gdf[\"county\"] = registry_gdf[\"county_name\"].copy()\n",
    "\n",
    "# replace the county_code and county columns with the values from the joined_gdf\n",
    "registry_gdf.loc[joined_gdf.index, \"county\"] = joined_gdf[\"name\"]\n",
    "registry_gdf.loc[joined_gdf.index, \"county_code\"] = joined_gdf[\"countyfp\"]\n",
    "\n",
    "# change the api column of the last row in joined_gdf to 42317428660000 instead of 43317428660000\n",
    "# registry_gdf.loc[joined_gdf.index[-1], \"api\"] = \"42317428660000\"\n",
    "registry_gdf[\"api\"] = registry_gdf[\"api\"].replace(\"43317428660000\", \"42317428660000\")\n",
    "# correct the state_code values for where the api was changed\n",
    "registry_gdf[\"state_code\"] = registry_gdf[\"api\"].str[0:2]\n",
    "# Create a mapping from 'state_code' to 'state'\n",
    "state_mapping = state_code_mode.set_index(\"state_code\")[\"state\"].to_dict()\n",
    "\n",
    "# Use the mapping to update the 'state' column in 'registry_gdf'\n",
    "registry_gdf[\"state\"] = registry_gdf[\"state_code\"].map(state_mapping)\n",
    "\n",
    "\n",
    "# check that the values have been replaced\n",
    "registry_gdf[registry_gdf[\"county_name\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to impute the missing `county_name` values would have been by using the `well_name` in the `registry_df_post_2012` dataframe. Assuming the other wells on the same pad has the correct `state_code` and `state` values. However, this may not have worked with `Vanorsdol` as there's only one well with that name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_df_post_2012[\n",
    "    registry_df_post_2012[\"well_name\"].str.contains(\"vanors\", case=False, na=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show other wells with a similar name to rhea 1-6\n",
    "registry_df_post_2012[\n",
    "    registry_df_post_2012[\"well\"].str.contains(\"Rhea 1-6\", case=False, na=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_df_post_2012[registry_df_post_2012[\"well\"].str.contains(\"Trulson\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_fips_gdf[county_fips_gdf[\"state\"].isin(permian_states)]\n",
    "registry_df_post_2012[registry_df_post_2012[\"well\"].str.contains(\"palermo\", case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# make the well column uppercase to lower variation among for wells on the same pad\n",
    "registry_gdf[\"well\"] = registry_gdf[\"well\"].str.upper()\n",
    "# make the operator column uppercase to lower the variation among entry for the same operator\n",
    "registry_gdf[\"operator\"] = registry_gdf[\"operator_name\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we did for those 4 wells to find the `county` and `state` for which they belong to, we can do that for all the wells. Let's see which well have a different `county` and `state` than what their coordinates suggest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 155\n"
     ]
    }
   ],
   "source": [
    "# create 2 new columns, lat and lon in the registry_gdf for corrections\n",
    "registry_gdf[\"lat\"] = registry_gdf[\"latitude\"].copy()\n",
    "registry_gdf[\"lon\"] = registry_gdf[\"longitude\"].copy()\n",
    "\n",
    "# Check which other wells may have a state value which did not agree with the spatial join result\n",
    "registry_county_gdf = registry_gdf.sjoin(\n",
    "    county_fips_gdf, how=\"left\", predicate=\"intersects\"\n",
    ").drop(columns=[\"index_right\"])\n",
    "\n",
    "trimmed_column_set = [\n",
    "    \"api\",\n",
    "    \"well\",\n",
    "    \"state_left\",\n",
    "    \"state_right\",\n",
    "    \"county_left\",\n",
    "    \"county_right\",\n",
    "    \"county_code\",\n",
    "    \"countyfp\",\n",
    "    \"operator\",\n",
    "    \"lon\",\n",
    "    \"lat\",\n",
    "    \"geometry\",\n",
    "]\n",
    "\n",
    "# rows which the spatial join did not match for the both dataframes\n",
    "mismatch_geo = registry_county_gdf[\n",
    "    registry_county_gdf[\"state_left\"] != registry_county_gdf[\"state_right\"]\n",
    "]\n",
    "print(f\"Number of rows: {len(mismatch_geo)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ones with a nan in the `state_right` column are those that we could not find a match for based on the `geometry`. We can match those for OK using the `api` number and see if the coordinates match for the wells in FracFocus match those from the OCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows from OK state: 27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crs</th>\n",
       "      <th>geometry</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>p_key</th>\n",
       "      <th>tvd</th>\n",
       "      <th>is_indian_well</th>\n",
       "      <th>state_left</th>\n",
       "      <th>state_name</th>\n",
       "      <th>state_number</th>\n",
       "      <th>well</th>\n",
       "      <th>operator_name</th>\n",
       "      <th>county_number</th>\n",
       "      <th>county_name</th>\n",
       "      <th>api</th>\n",
       "      <th>county_code</th>\n",
       "      <th>job_end_date</th>\n",
       "      <th>job_start_year</th>\n",
       "      <th>job_start_day</th>\n",
       "      <th>api_number</th>\n",
       "      <th>job_start_month</th>\n",
       "      <th>job_start_date</th>\n",
       "      <th>is_federal_well</th>\n",
       "      <th>well_name</th>\n",
       "      <th>total_base_water_volume</th>\n",
       "      <th>ff_version</th>\n",
       "      <th>job_end_year</th>\n",
       "      <th>job_end_month</th>\n",
       "      <th>job_end_day</th>\n",
       "      <th>state_code</th>\n",
       "      <th>county_left</th>\n",
       "      <th>operator</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>geoid</th>\n",
       "      <th>statefp</th>\n",
       "      <th>countyfp</th>\n",
       "      <th>name</th>\n",
       "      <th>county_right</th>\n",
       "      <th>state_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193302</th>\n",
       "      <td>NAD27</td>\n",
       "      <td>POINT (-98.91895 32.72479)</td>\n",
       "      <td>32.724655</td>\n",
       "      <td>-98.918603</td>\n",
       "      <td>3e82e6e4-3d1e-4a10-90ad-7079fdcebb4c</td>\n",
       "      <td>14476.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>35</td>\n",
       "      <td>TRIPLE J 1H-5-8</td>\n",
       "      <td>Citizen Energy II</td>\n",
       "      <td>39</td>\n",
       "      <td>Custer</td>\n",
       "      <td>35039225490000</td>\n",
       "      <td>039</td>\n",
       "      <td>2019-04-02</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35039225490000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>False</td>\n",
       "      <td>Triple J 1H-5-8</td>\n",
       "      <td>15273846.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35</td>\n",
       "      <td>Custer</td>\n",
       "      <td>CITIZEN ENERGY II</td>\n",
       "      <td>32.724655</td>\n",
       "      <td>-98.918603</td>\n",
       "      <td>48429</td>\n",
       "      <td>48</td>\n",
       "      <td>429</td>\n",
       "      <td>Stephens</td>\n",
       "      <td>Stephens County</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          crs                    geometry   latitude  longitude  \\\n",
       "193302  NAD27  POINT (-98.91895 32.72479)  32.724655 -98.918603   \n",
       "\n",
       "                                       p_key      tvd  is_indian_well  \\\n",
       "193302  3e82e6e4-3d1e-4a10-90ad-7079fdcebb4c  14476.0           False   \n",
       "\n",
       "       state_left state_name  state_number             well  \\\n",
       "193302   Oklahoma   Oklahoma            35  TRIPLE J 1H-5-8   \n",
       "\n",
       "            operator_name  county_number county_name             api  \\\n",
       "193302  Citizen Energy II             39      Custer  35039225490000   \n",
       "\n",
       "       county_code job_end_date  job_start_year  job_start_day  \\\n",
       "193302         039   2019-04-02          2019.0           26.0   \n",
       "\n",
       "            api_number  job_start_month job_start_date  is_federal_well  \\\n",
       "193302  35039225490000              3.0     2019-03-26            False   \n",
       "\n",
       "              well_name  total_base_water_volume  ff_version  job_end_year  \\\n",
       "193302  Triple J 1H-5-8               15273846.0           3        2019.0   \n",
       "\n",
       "        job_end_month  job_end_day state_code county_left           operator  \\\n",
       "193302            4.0          2.0         35      Custer  CITIZEN ENERGY II   \n",
       "\n",
       "              lat        lon  geoid statefp countyfp      name  \\\n",
       "193302  32.724655 -98.918603  48429      48      429  Stephens   \n",
       "\n",
       "           county_right state_right  \n",
       "193302  Stephens County       Texas  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the rows with Oklahoma in the state_left column\n",
    "mismatch_geo_ok = mismatch_geo.query('state_left.str.contains(\"Oklahoma\")')\n",
    "print(f\"Number of rows from OK state: {len(mismatch_geo_ok)}\")\n",
    "if len(mismatch_geo_ok) > 1:\n",
    "    display(mismatch_geo_ok.sample(1, random_state=628))\n",
    "else:\n",
    "    display(\"No rows from OK state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sh_lat</th>\n",
       "      <th>sh_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (-98.84517 37.97053)</td>\n",
       "      <td>37.970500</td>\n",
       "      <td>-9.884480e+01</td>\n",
       "      <td>36.970261</td>\n",
       "      <td>-97.844927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (-99.95937 33.74175)</td>\n",
       "      <td>33.741644</td>\n",
       "      <td>-9.995899e+01</td>\n",
       "      <td>35.407310</td>\n",
       "      <td>-99.998870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (-98.39757 37.59893)</td>\n",
       "      <td>37.598889</td>\n",
       "      <td>-9.839722e+01</td>\n",
       "      <td>36.955708</td>\n",
       "      <td>-97.835542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (-98.40035 37.60004)</td>\n",
       "      <td>37.600000</td>\n",
       "      <td>-9.840000e+01</td>\n",
       "      <td>36.955708</td>\n",
       "      <td>-97.835542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (-97.69883 37.04772)</td>\n",
       "      <td>37.047667</td>\n",
       "      <td>-9.769850e+01</td>\n",
       "      <td>36.107460</td>\n",
       "      <td>-98.880690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>POINT (-98732102099.00000 36.20187)</td>\n",
       "      <td>36.201866</td>\n",
       "      <td>-9.873210e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>POINT (35.82785 -97.77623)</td>\n",
       "      <td>-97.776229</td>\n",
       "      <td>3.582785e+01</td>\n",
       "      <td>35.827851</td>\n",
       "      <td>-97.776229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>POINT (36.18891 -98.07005)</td>\n",
       "      <td>-98.070053</td>\n",
       "      <td>3.618891e+01</td>\n",
       "      <td>36.188967</td>\n",
       "      <td>-98.070053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>POINT (36.11700 -98.01788)</td>\n",
       "      <td>-98.017878</td>\n",
       "      <td>3.611700e+01</td>\n",
       "      <td>36.117041</td>\n",
       "      <td>-98.018222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>POINT (36.14611 -97.98831)</td>\n",
       "      <td>-97.988311</td>\n",
       "      <td>3.614611e+01</td>\n",
       "      <td>36.146174</td>\n",
       "      <td>-97.896670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>POINT (34.92702 -96.25597)</td>\n",
       "      <td>-96.255972</td>\n",
       "      <td>3.492702e+01</td>\n",
       "      <td>34.927665</td>\n",
       "      <td>-96.263397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>POINT (-98.68312 33.66838)</td>\n",
       "      <td>33.668260</td>\n",
       "      <td>-9.868278e+01</td>\n",
       "      <td>35.668260</td>\n",
       "      <td>-98.682940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>POINT (-96.48668 -96.28407)</td>\n",
       "      <td>-96.284071</td>\n",
       "      <td>-9.648668e+01</td>\n",
       "      <td>36.284071</td>\n",
       "      <td>-96.486678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>POINT (0.00000 34.42038)</td>\n",
       "      <td>34.420379</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>34.420440</td>\n",
       "      <td>-99.645250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>POINT (-10.12346 10.12346)</td>\n",
       "      <td>10.123456</td>\n",
       "      <td>-1.012346e+01</td>\n",
       "      <td>36.927560</td>\n",
       "      <td>-98.406740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>POINT (35.01488 -96.38965)</td>\n",
       "      <td>-96.389653</td>\n",
       "      <td>3.501488e+01</td>\n",
       "      <td>35.014880</td>\n",
       "      <td>-96.389653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>POINT (-92.45072 36.88812)</td>\n",
       "      <td>36.888056</td>\n",
       "      <td>-9.245056e+01</td>\n",
       "      <td>36.888167</td>\n",
       "      <td>-95.450375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>POINT (-98.91895 32.72479)</td>\n",
       "      <td>32.724655</td>\n",
       "      <td>-9.891860e+01</td>\n",
       "      <td>35.724655</td>\n",
       "      <td>-98.918603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>POINT (35.88457 96.93887)</td>\n",
       "      <td>96.938868</td>\n",
       "      <td>3.588457e+01</td>\n",
       "      <td>35.884572</td>\n",
       "      <td>-96.938868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>POINT (0.00000 34.47072)</td>\n",
       "      <td>34.470721</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>POINT (-99.26561 33.43441)</td>\n",
       "      <td>33.434288</td>\n",
       "      <td>-9.926525e+01</td>\n",
       "      <td>35.434364</td>\n",
       "      <td>-99.265642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>POINT (-100.00275 36.21587)</td>\n",
       "      <td>36.215817</td>\n",
       "      <td>-1.000024e+02</td>\n",
       "      <td>36.215817</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>POINT (0.00000 36.42601)</td>\n",
       "      <td>36.426008</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>36.426061</td>\n",
       "      <td>-97.253253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>POINT (-36.05387 98.83640)</td>\n",
       "      <td>98.836398</td>\n",
       "      <td>-3.605387e+01</td>\n",
       "      <td>36.053840</td>\n",
       "      <td>-98.836400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POINT (35.49400 -97.97485)</td>\n",
       "      <td>-97.974847</td>\n",
       "      <td>3.549400e+01</td>\n",
       "      <td>35.494057</td>\n",
       "      <td>-97.975183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>POINT (98.33800 36.73836)</td>\n",
       "      <td>36.738356</td>\n",
       "      <td>9.833800e+01</td>\n",
       "      <td>36.738354</td>\n",
       "      <td>-98.337999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>POINT (-97.18220 37.57450)</td>\n",
       "      <td>37.574500</td>\n",
       "      <td>-9.718220e+01</td>\n",
       "      <td>36.962614</td>\n",
       "      <td>-97.306168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               geometry   latitude     longitude     sh_lat  \\\n",
       "0            POINT (-98.84517 37.97053)  37.970500 -9.884480e+01  36.970261   \n",
       "1            POINT (-99.95937 33.74175)  33.741644 -9.995899e+01  35.407310   \n",
       "2            POINT (-98.39757 37.59893)  37.598889 -9.839722e+01  36.955708   \n",
       "3            POINT (-98.40035 37.60004)  37.600000 -9.840000e+01  36.955708   \n",
       "4            POINT (-97.69883 37.04772)  37.047667 -9.769850e+01  36.107460   \n",
       "5   POINT (-98732102099.00000 36.20187)  36.201866 -9.873210e+10        NaN   \n",
       "6            POINT (35.82785 -97.77623) -97.776229  3.582785e+01  35.827851   \n",
       "7            POINT (36.18891 -98.07005) -98.070053  3.618891e+01  36.188967   \n",
       "8            POINT (36.11700 -98.01788) -98.017878  3.611700e+01  36.117041   \n",
       "9            POINT (36.14611 -97.98831) -97.988311  3.614611e+01  36.146174   \n",
       "10           POINT (34.92702 -96.25597) -96.255972  3.492702e+01  34.927665   \n",
       "11           POINT (-98.68312 33.66838)  33.668260 -9.868278e+01  35.668260   \n",
       "12          POINT (-96.48668 -96.28407) -96.284071 -9.648668e+01  36.284071   \n",
       "13             POINT (0.00000 34.42038)  34.420379  0.000000e+00  34.420440   \n",
       "14           POINT (-10.12346 10.12346)  10.123456 -1.012346e+01  36.927560   \n",
       "15           POINT (35.01488 -96.38965) -96.389653  3.501488e+01  35.014880   \n",
       "16           POINT (-92.45072 36.88812)  36.888056 -9.245056e+01  36.888167   \n",
       "17           POINT (-98.91895 32.72479)  32.724655 -9.891860e+01  35.724655   \n",
       "18            POINT (35.88457 96.93887)  96.938868  3.588457e+01  35.884572   \n",
       "19             POINT (0.00000 34.47072)  34.470721  0.000000e+00        NaN   \n",
       "20           POINT (-99.26561 33.43441)  33.434288 -9.926525e+01  35.434364   \n",
       "21          POINT (-100.00275 36.21587)  36.215817 -1.000024e+02  36.215817   \n",
       "22             POINT (0.00000 36.42601)  36.426008  0.000000e+00  36.426061   \n",
       "23           POINT (-36.05387 98.83640)  98.836398 -3.605387e+01  36.053840   \n",
       "24           POINT (35.49400 -97.97485) -97.974847  3.549400e+01  35.494057   \n",
       "25            POINT (98.33800 36.73836)  36.738356  9.833800e+01  36.738354   \n",
       "26           POINT (-97.18220 37.57450)  37.574500 -9.718220e+01  36.962614   \n",
       "\n",
       "        sh_lon  \n",
       "0   -97.844927  \n",
       "1   -99.998870  \n",
       "2   -97.835542  \n",
       "3   -97.835542  \n",
       "4   -98.880690  \n",
       "5          NaN  \n",
       "6   -97.776229  \n",
       "7   -98.070053  \n",
       "8   -98.018222  \n",
       "9   -97.896670  \n",
       "10  -96.263397  \n",
       "11  -98.682940  \n",
       "12  -96.486678  \n",
       "13  -99.645250  \n",
       "14  -98.406740  \n",
       "15  -96.389653  \n",
       "16  -95.450375  \n",
       "17  -98.918603  \n",
       "18  -96.938868  \n",
       "19         NaN  \n",
       "20  -99.265642  \n",
       "21 -100.000000  \n",
       "22  -97.253253  \n",
       "23  -98.836400  \n",
       "24  -97.975183  \n",
       "25  -98.337999  \n",
       "26  -97.306168  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the original index in a new column\n",
    "mismatch_geo_ok[\"original_index\"] = mismatch_geo_ok.index\n",
    "# alter api to match the format in the occ_wells dataframe\n",
    "mismatch_geo_ok[\"ok_api\"] = mismatch_geo_ok[\"api\"].str[:10]  # ok for Oklahoma\n",
    "# drop the api column\n",
    "mismatch_geo_ok.drop(columns=[\"api\"], inplace=True)\n",
    "# rename the api column in occ_wells to ok_api\n",
    "occ_wells.rename(columns={\"api\": \"ok_api\"}, inplace=True)\n",
    "# look for the api in the occ_wells dataframe and merge that row to mismatch_geo_ok\n",
    "joined_mismatch_ok = mismatch_geo_ok.merge(\n",
    "    occ_wells[\n",
    "        [\"ok_api\", \"well_name\", \"well_num\", \"operator\", \"sh_lat\", \"sh_lon\", \"county\"]\n",
    "    ],\n",
    "    how=\"left\",\n",
    "    on=\"ok_api\",\n",
    ")\n",
    "joined_mismatch_ok[[\"geometry\", \"latitude\", \"longitude\", \"sh_lat\", \"sh_lon\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# replace the lat and lon values with the sh_lat and sh_lon values\n",
    "# Replace the 'lat' and 'lon' values\n",
    "joined_mismatch_ok.loc[\n",
    "    joined_mismatch_ok[\"sh_lat\"].notna(), \"lat\"\n",
    "] = joined_mismatch_ok[\"sh_lat\"]\n",
    "joined_mismatch_ok.loc[\n",
    "    joined_mismatch_ok[\"sh_lon\"].notna(), \"lon\"\n",
    "] = joined_mismatch_ok[\"sh_lon\"]\n",
    "\n",
    "joined_mismatch_ok.set_index(\"original_index\", inplace=True)\n",
    "\n",
    "# occ_wells[occ_wells[\"api\"].isin(mismatch_geo_ok[\"ok_api\"])][\n",
    "#     [\"api\", \"well_name\", \"well_num\", \"operator\", \"sh_lat\", \"sh_lon\", \"county\"]\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with mismatched state values: 130\n"
     ]
    }
   ],
   "source": [
    "# Update 'lat' and 'lon' in the original DataFrame\n",
    "registry_gdf.loc[joined_mismatch_ok.index, \"lat\"] = joined_mismatch_ok[\"lat\"]\n",
    "registry_gdf.loc[joined_mismatch_ok.index, \"lon\"] = joined_mismatch_ok[\"lon\"]\n",
    "# registry_gdf\n",
    "\n",
    "\n",
    "# Update 'geometry' in the original DataFrame\n",
    "registry_gdf.loc[joined_mismatch_ok.index, \"geometry\"] = [\n",
    "    Point(xy) for xy in zip(joined_mismatch_ok.lon, joined_mismatch_ok.lat)\n",
    "]\n",
    "# Check which other wells may have a state value which did not agree with the spatial join result again\n",
    "registry_county_gdf = registry_gdf.sjoin(\n",
    "    county_fips_gdf, how=\"left\", predicate=\"intersects\"\n",
    ").drop(columns=[\"index_right\"])\n",
    "\n",
    "# mismatch_geo = registry_county_gdf[registry_county_gdf[\"state_right\"].isna()]\n",
    "\n",
    "mismatch_geo = registry_county_gdf[\n",
    "    registry_county_gdf[\"state_left\"] != registry_county_gdf[\"state_right\"]\n",
    "]\n",
    "print(f\"Number of rows with mismatched state values: {mismatch_geo.shape[0]}\")\n",
    "# mismatch_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25 rows had incorrect Coordinates for OK. We can do the same for Texas. The `state_left` column is the state from the FracFocus data and the `state_right` column is the state from the `county_fips_gdf` geodataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api</th>\n",
       "      <th>well</th>\n",
       "      <th>state_left</th>\n",
       "      <th>state_right</th>\n",
       "      <th>county_left</th>\n",
       "      <th>county_right</th>\n",
       "      <th>county_code</th>\n",
       "      <th>countyfp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18718</th>\n",
       "      <td>42177327040000</td>\n",
       "      <td>DOROTHY SPRINGS 1H</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Gonzales</td>\n",
       "      <td>Clark County</td>\n",
       "      <td>177</td>\n",
       "      <td>019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18906</th>\n",
       "      <td>42283334450000</td>\n",
       "      <td>GUTIERREZ LEYENDER 3H</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>La Salle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18977</th>\n",
       "      <td>42419317080000</td>\n",
       "      <td>SMITH I 1H</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Shelby</td>\n",
       "      <td>Sabine Parish</td>\n",
       "      <td>419</td>\n",
       "      <td>085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>42283334250000</td>\n",
       "      <td>HUBBARD B UNIT NO. 1H</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LA SALLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19200</th>\n",
       "      <td>42283334270000</td>\n",
       "      <td>RAMSEY FAULKNER B NO. 1H</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LA SALLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141853</th>\n",
       "      <td>30025409130000</td>\n",
       "      <td>ESDU #30</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Lea</td>\n",
       "      <td>Jeff Davis County</td>\n",
       "      <td>025</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148157</th>\n",
       "      <td>30015469200000</td>\n",
       "      <td>PALE RIDE W0OB STATE COM #1H</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Eddy</td>\n",
       "      <td>Culberson County</td>\n",
       "      <td>015</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199347</th>\n",
       "      <td>17011210040000</td>\n",
       "      <td>IRBY #3</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Beauregard</td>\n",
       "      <td>Walker County</td>\n",
       "      <td>011</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211333</th>\n",
       "      <td>04222382800000</td>\n",
       "      <td>CHALK, G. O.-D- 29</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - San Nicolas Offshore Islands</td>\n",
       "      <td>Howard County</td>\n",
       "      <td>222</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212350</th>\n",
       "      <td>04241324760000</td>\n",
       "      <td>THORNY DEVIL 1H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Marin County</td>\n",
       "      <td>Brazos County</td>\n",
       "      <td>241</td>\n",
       "      <td>041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   api                          well  state_left state_right  \\\n",
       "18718   42177327040000            DOROTHY SPRINGS 1H       Texas    Arkansas   \n",
       "18906   42283334450000         GUTIERREZ LEYENDER 3H       Texas         NaN   \n",
       "18977   42419317080000                    SMITH I 1H       Texas   Louisiana   \n",
       "19199   42283334250000         HUBBARD B UNIT NO. 1H       Texas         NaN   \n",
       "19200   42283334270000      RAMSEY FAULKNER B NO. 1H       Texas         NaN   \n",
       "...                ...                           ...         ...         ...   \n",
       "141853  30025409130000                      ESDU #30  New Mexico       Texas   \n",
       "148157  30015469200000  PALE RIDE W0OB STATE COM #1H  New Mexico       Texas   \n",
       "199347  17011210040000                       IRBY #3   Louisiana       Texas   \n",
       "211333  04222382800000            CHALK, G. O.-D- 29  California       Texas   \n",
       "212350  04241324760000               THORNY DEVIL 1H  California       Texas   \n",
       "\n",
       "                                        county_left       county_right  \\\n",
       "18718                                      Gonzales       Clark County   \n",
       "18906                                      La Salle                NaN   \n",
       "18977                                        Shelby      Sabine Parish   \n",
       "19199                                      LA SALLE                NaN   \n",
       "19200                                      LA SALLE                NaN   \n",
       "...                                             ...                ...   \n",
       "141853                                          Lea  Jeff Davis County   \n",
       "148157                                         Eddy   Culberson County   \n",
       "199347                                   Beauregard      Walker County   \n",
       "211333  State Waters - San Nicolas Offshore Islands      Howard County   \n",
       "212350                  State Waters - Marin County      Brazos County   \n",
       "\n",
       "       county_code countyfp  \n",
       "18718          177      019  \n",
       "18906          283      NaN  \n",
       "18977          419      085  \n",
       "19199          283      NaN  \n",
       "19200          283      NaN  \n",
       "...            ...      ...  \n",
       "141853         025      243  \n",
       "148157         015      109  \n",
       "199347         011      471  \n",
       "211333         222      227  \n",
       "212350         241      041  \n",
       "\n",
       "[78 rows x 8 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query for the wells in Texas\n",
    "mismatch_geo_tx = mismatch_geo[trimmed_column_set].query(\n",
    "    'state_left.str.contains(\"Texas\") | state_right.str.contains(\"Texas\")'\n",
    ")\n",
    "# store the original index in a new column\n",
    "mismatch_geo_tx[\"original_index\"] = mismatch_geo_tx.index\n",
    "\n",
    "mismatch_geo_tx[\"tx_api\"] = mismatch_geo_tx[\"api\"].str[2:10]\n",
    "mismatch_geo_tx.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"api\",\n",
    "        \"well\",\n",
    "        \"state_left\",\n",
    "        \"state_right\",\n",
    "        \"county_left\",\n",
    "        \"county_right\",\n",
    "        \"county_code\",\n",
    "        \"countyfp\",\n",
    "    ],\n",
    "]\n",
    "# len(mismatch_geo_tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Texas Railroad Commission (RRC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Land survey data, bottom well data, and surface well data were taken from the RRC website. The data was then uploaded to GCP for easier reliabiliity. They are 254 zipfiles, one for each county, in the state of Texas. Each of those zipfiles contained various file extensions, and spatial data format that is usually contained in shapefiles, and contained info for various categories ranging from Airport lines to Offshore survey polys.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:   6%|         | 14/254 [00:29<06:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: IncompleteRead(2944078 bytes read, 1253737 more expected) on try 1 of 5 for https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp013.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  11%|         | 28/254 [01:06<08:24,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: IncompleteRead(6764282 bytes read, 268354 more expected) on try 1 of 5 for https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp009.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  22%|       | 56/254 [02:08<06:10,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: IncompleteRead(6257034 bytes read, 775602 more expected) on try 2 of 5 for https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp009.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  26%|       | 67/254 [02:50<13:40,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: IncompleteRead(9614590 bytes read, 1108490 more expected) on try 1 of 5 for https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp127.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  40%|      | 102/254 [04:17<04:17,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: IncompleteRead(1571598 bytes read, 393540 more expected) on try 1 of 5 for https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp207.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  52%|    | 133/254 [05:36<02:56,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: IncompleteRead(7881826 bytes read, 468189 more expected) on try 1 of 5 for https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp167.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  77%|  | 196/254 [08:00<01:31,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: IncompleteRead(3192875 bytes read, 970911 more expected) on try 1 of 5 for https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp373.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  80%|  | 204/254 [08:30<02:10,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: IncompleteRead(10174464 bytes read, 1311031 more expected) on try 1 of 5 for https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp389.zip\n",
      "Error: IncompleteRead(6188957 bytes read, 1267646 more expected) on try 1 of 5 for https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp355.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  84%| | 214/254 [09:04<01:24,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: IncompleteRead(30927390 bytes read, 338911 more expected) on try 1 of 5 for https://storage.googleapis.com/mrprime_dataset/capstone_journey/rrc/all_layers_rrc_20231117/Shp201.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|| 254/254 [11:40<00:00,  2.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# regex patterns to identify which shapefiles to extract\n",
    "# we are grabbing the survey lines, surface wells, and bottom well locations shp files\n",
    "patterns = [r\"surv\\d{3}p\", r\"well\\d{3}s\", r\"well\\d{3}b\"]\n",
    "\n",
    "# Look at the survey lines polygons and the surface wells points. Data saved from RRC website\n",
    "shp_dict = extract_matching_shp_files_from_zip_urls_concurrent(SHP_ZIP_URLS, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def deep_getsizeof(obj):\n",
    "    \"\"\"Recursively find size of object and its elements\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum(deep_getsizeof(k) + deep_getsizeof(v) for k, v in obj.items())\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        size += sum(deep_getsizeof(x) for x in obj)\n",
    "    return size\n",
    "\n",
    "\n",
    "# Assume 'my_dict' is your dictionary\n",
    "total_size_in_bytes = deep_getsizeof(shp_dict)\n",
    "total_size_in_mb = total_size_in_bytes / 1e6\n",
    "print(f\"The total size of the dictionary is {total_size_in_mb:.2f} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the patterns to separate the gdf in the dict based on the pattern\n",
    "surv_dict = {k: shp_dict[k] for k, v in shp_dict.items() if re.search(patterns[0], k)}\n",
    "swell_dict = {k: shp_dict[k] for k, v in shp_dict.items() if re.search(patterns[1], k)}\n",
    "bwell_dict = {k: shp_dict[k] for k, v in shp_dict.items() if re.search(patterns[2], k)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Texas RRC land survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O&G well symnum is a number that indicates the type of well simplified for fewer bins\n",
    "well_symnum_dict = {\n",
    "    2: \"Permitted Location\",\n",
    "    3: \"Dry Hole\",\n",
    "    4: \"Oil/Gas\",  # oil\n",
    "    5: \"Oil/Gas\",  # gas\n",
    "    6: \"Oil/Gas\",  # oil/ gas\n",
    "    7: \"Plugged/Shut-in\",  # oil\n",
    "    8: \"Plugged/Shut-in\",  # gas\n",
    "    9: \"Canceled Location\",\n",
    "    10: \"Plugged/Shut-in\",\n",
    "    11: \"Injection/Disposal\",\n",
    "    12: \"Core Test\",\n",
    "    17: \"Storage\",  # oil\n",
    "    18: \"Storage\",  # gas\n",
    "    19: \"Plugged/Shut-in\",  # oil\n",
    "    20: \"Plugged/Shut-in\",  # gas\n",
    "    21: \"Injection/Disposal\",  # oil\n",
    "    22: \"Injection/Disposal\",  # gas\n",
    "    23: \"Injection/Disposal\",  # oil/ gas\n",
    "    73: \"Brine Mining\",\n",
    "    74: \"Water Supply\",\n",
    "    75: \"Water Supply\",  # oil\n",
    "    76: \"Water Supply\",  # gas\n",
    "    77: \"Water Supply\",  # oil/ gas\n",
    "    86: \"Horizontal\",  # Horizontal Well Surface Location\",\n",
    "    87: \"Horizontal\",  # Directional/Sidetrack Well Surface Location,\n",
    "    88: \"Storage\",\n",
    "    103: \"Storage\",  # oil/gas\n",
    "}\n",
    "# well_symnum_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>abstract_n</th>\n",
       "      <th>level1_sur</th>\n",
       "      <th>level2_blo</th>\n",
       "      <th>level3_sur</th>\n",
       "      <th>level4_sur</th>\n",
       "      <th>abstract_l</th>\n",
       "      <th>scrap_file</th>\n",
       "      <th>source_file</th>\n",
       "      <th>county_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257253</th>\n",
       "      <td>POLYGON ((-98.91351 32.64414, -98.92465 32.644...</td>\n",
       "      <td>429913</td>\n",
       "      <td>TE&amp;L CO</td>\n",
       "      <td>None</td>\n",
       "      <td>3397</td>\n",
       "      <td>None</td>\n",
       "      <td>A-913</td>\n",
       "      <td>None</td>\n",
       "      <td>surv429p</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99712</th>\n",
       "      <td>POLYGON ((-99.01243 28.89601, -99.02427 28.885...</td>\n",
       "      <td>16331</td>\n",
       "      <td>AB&amp;M</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>A-31</td>\n",
       "      <td>None</td>\n",
       "      <td>surv163p</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264823</th>\n",
       "      <td>POLYGON ((-100.73387 30.44265, -100.73377 30.4...</td>\n",
       "      <td>4351568</td>\n",
       "      <td>HE&amp;WT RR CO</td>\n",
       "      <td>C</td>\n",
       "      <td>164</td>\n",
       "      <td>WORD, O T</td>\n",
       "      <td>A-1568</td>\n",
       "      <td>None</td>\n",
       "      <td>surv435p</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 geometry abstract_n  \\\n",
       "257253  POLYGON ((-98.91351 32.64414, -98.92465 32.644...     429913   \n",
       "99712   POLYGON ((-99.01243 28.89601, -99.02427 28.885...      16331   \n",
       "264823  POLYGON ((-100.73387 30.44265, -100.73377 30.4...    4351568   \n",
       "\n",
       "         level1_sur level2_blo level3_sur level4_sur abstract_l scrap_file  \\\n",
       "257253      TE&L CO       None       3397       None      A-913       None   \n",
       "99712          AB&M       None          9       None       A-31       None   \n",
       "264823  HE&WT RR CO          C        164  WORD, O T     A-1568       None   \n",
       "\n",
       "       source_file county_code  \n",
       "257253    surv429p         429  \n",
       "99712     surv163p         163  \n",
       "264823    surv435p         435  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 311248 entries, 0 to 311247\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype   \n",
      "---  ------       --------------   -----   \n",
      " 0   geometry     311248 non-null  geometry\n",
      " 1   abstract_n   311127 non-null  object  \n",
      " 2   level1_sur   310857 non-null  object  \n",
      " 3   level2_blo   139664 non-null  object  \n",
      " 4   level3_sur   221353 non-null  object  \n",
      " 5   level4_sur   108712 non-null  object  \n",
      " 6   abstract_l   311240 non-null  object  \n",
      " 7   scrap_file   9271 non-null    object  \n",
      " 8   source_file  311248 non-null  object  \n",
      " 9   county_code  311248 non-null  object  \n",
      "dtypes: geometry(1), object(9)\n",
      "memory usage: 142.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the GeoDataFrames in surv_dict into a single GeoDataFrame\n",
    "surv_data_gdf = concat_gdf_from_dict(surv_dict)\n",
    "\n",
    "# Convert the column names to snake case for consistency\n",
    "surv_data_gdf.columns = [pascal_to_snake(col) for col in surv_data_gdf.columns]\n",
    "# addd a coulmn for the county_code\n",
    "surv_data_gdf[\"county_code\"] = surv_data_gdf[\"source_file\"].str.extract(r\"(\\d{3})\")\n",
    "\n",
    "# Display a sample of 3 rows from the DataFrame\n",
    "display(surv_data_gdf.sample(3))\n",
    "\n",
    "# Display information about the DataFrame, including the number of non-null entries in each column\n",
    "surv_data_gdf.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Texas RRC surface well data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>surface_id</th>\n",
       "      <th>symnum</th>\n",
       "      <th>api</th>\n",
       "      <th>reliab</th>\n",
       "      <th>long27</th>\n",
       "      <th>lat27</th>\n",
       "      <th>long83</th>\n",
       "      <th>lat83</th>\n",
       "      <th>wellid</th>\n",
       "      <th>source_file</th>\n",
       "      <th>county_code</th>\n",
       "      <th>well_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1056544</th>\n",
       "      <td>POINT (-100.12863 32.40754)</td>\n",
       "      <td>1242518</td>\n",
       "      <td>4</td>\n",
       "      <td>44134365</td>\n",
       "      <td>55</td>\n",
       "      <td>-100.128625</td>\n",
       "      <td>32.407541</td>\n",
       "      <td>-100.129001</td>\n",
       "      <td>32.407664</td>\n",
       "      <td>34365</td>\n",
       "      <td>well441s</td>\n",
       "      <td>441</td>\n",
       "      <td>Oil/Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534459</th>\n",
       "      <td>POINT (-101.31300 32.10108)</td>\n",
       "      <td>1179120</td>\n",
       "      <td>11</td>\n",
       "      <td>22736155</td>\n",
       "      <td>40</td>\n",
       "      <td>-101.312997</td>\n",
       "      <td>32.101082</td>\n",
       "      <td>-101.313394</td>\n",
       "      <td>32.101209</td>\n",
       "      <td>36155</td>\n",
       "      <td>well227s</td>\n",
       "      <td>227</td>\n",
       "      <td>Injection/Disposal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73671</th>\n",
       "      <td>POINT (-97.71920 29.73028)</td>\n",
       "      <td>208710</td>\n",
       "      <td>7</td>\n",
       "      <td>055</td>\n",
       "      <td>50</td>\n",
       "      <td>-97.719198</td>\n",
       "      <td>29.730285</td>\n",
       "      <td>-97.719476</td>\n",
       "      <td>29.730511</td>\n",
       "      <td>None</td>\n",
       "      <td>well055s</td>\n",
       "      <td>055</td>\n",
       "      <td>Plugged/Shut-in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            geometry  surface_id  symnum       api reliab  \\\n",
       "1056544  POINT (-100.12863 32.40754)     1242518       4  44134365     55   \n",
       "534459   POINT (-101.31300 32.10108)     1179120      11  22736155     40   \n",
       "73671     POINT (-97.71920 29.73028)      208710       7       055     50   \n",
       "\n",
       "             long27      lat27      long83      lat83 wellid source_file  \\\n",
       "1056544 -100.128625  32.407541 -100.129001  32.407664  34365    well441s   \n",
       "534459  -101.312997  32.101082 -101.313394  32.101209  36155    well227s   \n",
       "73671    -97.719198  29.730285  -97.719476  29.730511   None    well055s   \n",
       "\n",
       "        county_code           well_type  \n",
       "1056544         441             Oil/Gas  \n",
       "534459          227  Injection/Disposal  \n",
       "73671           055     Plugged/Shut-in  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1359173 entries, 0 to 1359172\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count    Dtype   \n",
      "---  ------       --------------    -----   \n",
      " 0   geometry     1359173 non-null  geometry\n",
      " 1   surface_id   1359173 non-null  int64   \n",
      " 2   symnum       1359173 non-null  int64   \n",
      " 3   api          1359173 non-null  object  \n",
      " 4   reliab       1359173 non-null  object  \n",
      " 5   long27       1359173 non-null  float64 \n",
      " 6   lat27        1359173 non-null  float64 \n",
      " 7   long83       1359173 non-null  float64 \n",
      " 8   lat83        1359173 non-null  float64 \n",
      " 9   wellid       994978 non-null   object  \n",
      " 10  source_file  1359173 non-null  object  \n",
      " 11  county_code  1359173 non-null  object  \n",
      " 12  well_type    1359173 non-null  object  \n",
      "dtypes: float64(4), geometry(1), int64(2), object(6)\n",
      "memory usage: 549.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the GeoDataFrames in well_dict into a single GeoDataFrame\n",
    "swell_data_gdf = concat_gdf_from_dict(swell_dict)\n",
    "\n",
    "# Convert the column names to snake case for consistency\n",
    "swell_data_gdf.columns = [pascal_to_snake(col) for col in swell_data_gdf.columns]\n",
    "# get the county code from the source_file column\n",
    "swell_data_gdf[\"county_code\"] = swell_data_gdf[\"source_file\"].str.extract(r\"(\\d{3})\")\n",
    "# map the dictionary to the SYMNUM column and fill the rare values with 'Other'\n",
    "swell_data_gdf[\"well_type\"] = (\n",
    "    swell_data_gdf[\"symnum\"].map(well_symnum_dict).fillna(\"Other\")\n",
    ")\n",
    "\n",
    "# Display a sample of 3 rows from the DataFrame\n",
    "display(swell_data_gdf.sample(3))\n",
    "\n",
    "# Display information about the DataFrame, including the number of non-null entries in each column\n",
    "swell_data_gdf.info(\n",
    "    memory_usage=\"deep\"\n",
    ")  \n",
    "# shp_dict = extract_specific_gdf_from_zip_url(shp_zip_urls, patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "well_type\n",
       "Plugged/Shut-in       392946\n",
       "Oil/Gas               353912\n",
       "Dry Hole              287253\n",
       "Horizontal            153381\n",
       "Permitted Location     88198\n",
       "Injection/Disposal     40512\n",
       "Canceled Location      39465\n",
       "Water Supply            1227\n",
       "Storage                  783\n",
       "Core Test                763\n",
       "Other                    632\n",
       "Brine Mining             101\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swell_data_gdf[\"well_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='11cbb1df-cd16-4d35-84c8-b0f876af09c0'>\n",
       "  <div id=\"a58bee30-5244-449f-a7fb-499061280380\" data-root-id=\"11cbb1df-cd16-4d35-84c8-b0f876af09c0\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"0279c8ed-fdc2-46ac-b122-cfa0a6e8fa19\":{\"version\":\"3.3.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"11cbb1df-cd16-4d35-84c8-b0f876af09c0\",\"attributes\":{\"name\":\"Row01755\",\"tags\":[\"embedded\"],\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"5a3e9374-f22e-4b6d-ac30-5e9fadbad49d\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.1/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"3e1a222c-1749-48d1-9a7a-704ed945b55c\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.1/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"d93aca51-919a-420c-97ce-2d205bb4c929\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.1/dist/bundled/theme/default.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"52d7091a-f1fe-493f-a074-c5a5650d46ce\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.3.1/dist/bundled/theme/native.css\"}}],\"min_width\":600,\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Spacer\",\"id\":\"714cd089-b0ce-42d6-996d-b052b528a868\",\"attributes\":{\"name\":\"HSpacer01766\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"5a3e9374-f22e-4b6d-ac30-5e9fadbad49d\"},{\"id\":\"d93aca51-919a-420c-97ce-2d205bb4c929\"},{\"id\":\"52d7091a-f1fe-493f-a074-c5a5650d46ce\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\"}},{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"61613c2e-e0e2-4d8c-8088-274f94a5abc4\",\"attributes\":{\"height\":400,\"margin\":[5,10],\"sizing_mode\":\"fixed\",\"align\":\"start\",\"x_range\":{\"type\":\"object\",\"name\":\"Range1d\",\"id\":\"db7cd20c-f6f1-41d7-8033-3ff1ab65d540\",\"attributes\":{\"tags\":[[[\"count\",\"count\",null]],[]],\"end\":432230.5,\"reset_start\":0.0,\"reset_end\":432230.5}},\"y_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"238009ec-6612-48c6-b3c9-2df3dff85743\",\"attributes\":{\"tags\":[[[\"well_type\",\"well_type\",null]],{\"type\":\"map\",\"entries\":[[\"invert_yaxis\",false],[\"autorange\",false]]}],\"factors\":[\"Plugged/Shut-in\",\"Oil/Gas\",\"Dry Hole\",\"Horizontal\",\"Permitted Location\",\"Injection/Disposal\",\"Canceled Location\",\"Water Supply\",\"Storage\",\"Core Test\",\"Other\",\"Brine Mining\"]}},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"f8253016-0131-4687-8459-66c5791f1bb0\"},\"y_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"c26c24ff-2723-4fee-8f46-02ac67245931\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"1d15d99f-44aa-4510-9d99-df1c548541d1\",\"attributes\":{\"text\":\"Surface Well Types Count\",\"text_color\":\"black\",\"text_font_size\":\"12pt\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"06939a45-b117-4a06-baf6-4d1efb850ad0\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"635602d3-1790-43f5-8d3f-069d25529de1\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"407fe997-b19e-4c5c-8900-1d7c9eca2bd7\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"b38859b0-0c16-4e64-90ba-eac22756063d\"},\"data\":{\"type\":\"map\",\"entries\":[[\"well_type\",[\"Plugged/Shut-in\",\"Oil/Gas\",\"Dry Hole\",\"Horizontal\",\"Permitted Location\",\"Injection/Disposal\",\"Canceled Location\",\"Water Supply\",\"Storage\",\"Core Test\",\"Other\",\"Brine Mining\"]],[\"count\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"8v4FAHhmBQAVYgQAJVcCAIZYAQBAngAAKZoAAMsEAAAPAwAA+wIAAHgCAABlAAAA\"},\"shape\":[12],\"dtype\":\"int32\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"983ff4d4-5a9b-467d-b4b9-864de9537a2a\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"4c3b4355-646d-4336-b496-de11ca5528da\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"53b01a88-d84e-4f43-b361-e56cb5bbf027\",\"attributes\":{\"tags\":[\"apply_ranges\"],\"y\":{\"type\":\"field\",\"field\":\"well_type\"},\"height\":{\"type\":\"value\",\"value\":0.8},\"right\":{\"type\":\"field\",\"field\":\"count\"},\"fill_color\":{\"type\":\"value\",\"value\":\"#30a2da\"},\"hatch_color\":{\"type\":\"value\",\"value\":\"#30a2da\"}}},\"selection_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"6c2038e8-de9e-4886-b624-4a0320e4bbfc\",\"attributes\":{\"tags\":[\"apply_ranges\"],\"y\":{\"type\":\"field\",\"field\":\"well_type\"},\"height\":{\"type\":\"value\",\"value\":0.8},\"left\":{\"type\":\"value\",\"value\":0},\"right\":{\"type\":\"field\",\"field\":\"count\"},\"line_color\":{\"type\":\"value\",\"value\":\"black\"},\"line_alpha\":{\"type\":\"value\",\"value\":1.0},\"line_width\":{\"type\":\"value\",\"value\":1},\"line_join\":{\"type\":\"value\",\"value\":\"bevel\"},\"line_cap\":{\"type\":\"value\",\"value\":\"butt\"},\"line_dash\":{\"type\":\"value\",\"value\":[]},\"line_dash_offset\":{\"type\":\"value\",\"value\":0},\"fill_color\":{\"type\":\"value\",\"value\":\"#30a2da\"},\"fill_alpha\":{\"type\":\"value\",\"value\":1.0},\"hatch_color\":{\"type\":\"value\",\"value\":\"#30a2da\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":1.0},\"hatch_scale\":{\"type\":\"value\",\"value\":12.0},\"hatch_pattern\":{\"type\":\"value\",\"value\":null},\"hatch_weight\":{\"type\":\"value\",\"value\":1.0}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"6acad1aa-de4f-4c01-a985-5c069188d5e5\",\"attributes\":{\"tags\":[\"apply_ranges\"],\"y\":{\"type\":\"field\",\"field\":\"well_type\"},\"height\":{\"type\":\"value\",\"value\":0.8},\"right\":{\"type\":\"field\",\"field\":\"count\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"#30a2da\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_color\":{\"type\":\"value\",\"value\":\"#30a2da\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"HBar\",\"id\":\"6cd5db42-94e1-4c7b-aaaa-2f9fe69cbf80\",\"attributes\":{\"tags\":[\"apply_ranges\"],\"y\":{\"type\":\"field\",\"field\":\"well_type\"},\"height\":{\"type\":\"value\",\"value\":0.8},\"right\":{\"type\":\"field\",\"field\":\"count\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"#30a2da\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_color\":{\"type\":\"value\",\"value\":\"#30a2da\"},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"04f56f10-bc18-41a6-ac8b-a885cd661088\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"1164bb03-8482-4d16-b8b1-da1f66e3fa50\",\"attributes\":{\"tags\":[\"hv_created\"],\"renderers\":\"auto\",\"zoom_together\":\"none\"}},{\"type\":\"object\",\"name\":\"HoverTool\",\"id\":\"3518adc7-b253-4f47-9f70-13202f30afab\",\"attributes\":{\"tags\":[\"hv_created\"],\"renderers\":[{\"id\":\"06939a45-b117-4a06-baf6-4d1efb850ad0\"}],\"tooltips\":[[\"well_type\",\"@{well_type}\"],[\"count\",\"@{count}\"]]}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"8f0ed2ec-3b5d-4129-9c2f-54ba91cf9aa2\"},{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"5e6f2188-f41d-43eb-a873-7fb16814a18e\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"18960431-f246-4bca-84f9-ee87246a3c72\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"a583a12d-a032-4e2e-99c4-ad4eb27db00d\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"92bdd3c8-8d52-472a-8048-0f92c5a768eb\"}],\"active_drag\":{\"id\":\"18960431-f246-4bca-84f9-ee87246a3c72\"}}},\"toolbar_location\":\"above\",\"left\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"caef07bb-204c-4efe-9683-6e0d9b7923a6\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"e5a994ac-6613-4ee5-aa53-2061ff0a1bfd\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"7c9ee417-0292-478a-959c-5e3236d70fc1\"},\"axis_label\":\"\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"f91e3e39-c8ca-44ba-8940-987e1aa81af6\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"31dc93a1-f736-4d1a-98ab-d219eb879b42\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"38dc765b-9ae1-4e2d-9eb2-4b082cdeb105\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"52afff14-7e3d-4738-9ad5-fe4dd499fd4e\"},\"axis_label\":\"\",\"axis_label_text_font_size\":\"0pt\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"fad32f47-ac72-474d-8a13-0eca8df53f05\"},\"major_label_text_font_size\":\"0pt\",\"major_tick_line_color\":null,\"minor_tick_line_color\":null}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"18008a7a-66a7-4030-86e1-9097342bc97d\",\"attributes\":{\"axis\":{\"id\":\"31dc93a1-f736-4d1a-98ab-d219eb879b42\"},\"grid_line_color\":null}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"555d7c02-630d-41bd-8ab4-a0bf1b35cfeb\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"caef07bb-204c-4efe-9683-6e0d9b7923a6\"},\"grid_line_color\":null}}],\"min_border_top\":10,\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"output_backend\":\"webgl\"}},{\"type\":\"object\",\"name\":\"Spacer\",\"id\":\"4070df16-6b6a-4c50-a35d-7e48e59bd49c\",\"attributes\":{\"name\":\"HSpacer01769\",\"stylesheets\":[\"\\n:host(.pn-loading.pn-arc):before, .pn-loading.pn-arc:before {\\n  background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHN0eWxlPSJtYXJnaW46IGF1dG87IGJhY2tncm91bmQ6IG5vbmU7IGRpc3BsYXk6IGJsb2NrOyBzaGFwZS1yZW5kZXJpbmc6IGF1dG87IiB2aWV3Qm94PSIwIDAgMTAwIDEwMCIgcHJlc2VydmVBc3BlY3RSYXRpbz0ieE1pZFlNaWQiPiAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSIjYzNjM2MzIiBzdHJva2Utd2lkdGg9IjEwIiByPSIzNSIgc3Ryb2tlLWRhc2hhcnJheT0iMTY0LjkzMzYxNDMxMzQ2NDE1IDU2Ljk3Nzg3MTQzNzgyMTM4Ij4gICAgPGFuaW1hdGVUcmFuc2Zvcm0gYXR0cmlidXRlTmFtZT0idHJhbnNmb3JtIiB0eXBlPSJyb3RhdGUiIHJlcGVhdENvdW50PSJpbmRlZmluaXRlIiBkdXI9IjFzIiB2YWx1ZXM9IjAgNTAgNTA7MzYwIDUwIDUwIiBrZXlUaW1lcz0iMDsxIj48L2FuaW1hdGVUcmFuc2Zvcm0+ICA8L2NpcmNsZT48L3N2Zz4=\\\");\\n  background-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"5a3e9374-f22e-4b6d-ac30-5e9fadbad49d\"},{\"id\":\"d93aca51-919a-420c-97ce-2d205bb4c929\"},{\"id\":\"52d7091a-f1fe-493f-a074-c5a5650d46ce\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\"}}]}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"toggle_value1\",\"properties\":[{\"name\":\"active_icons\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"options\",\"kind\":\"Any\",\"default\":{\"type\":\"map\",\"entries\":[[\"favorite\",\"heart\"]]}},{\"name\":\"value\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"_reactions\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"_base_url\",\"kind\":\"Any\",\"default\":\"https://tabler-icons.io/static/tabler-icons/icons/\"}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"value\",\"kind\":\"Any\",\"default\":null},{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"0279c8ed-fdc2-46ac-b122-cfa0a6e8fa19\",\"roots\":{\"11cbb1df-cd16-4d35-84c8-b0f876af09c0\":\"a58bee30-5244-449f-a7fb-499061280380\"},\"root_ids\":[\"11cbb1df-cd16-4d35-84c8-b0f876af09c0\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root['Tabulator'] !== undefined) && ( root['Tabulator'] !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":Bars   [well_type]   (count)"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "11cbb1df-cd16-4d35-84c8-b0f876af09c0"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the well types on a horizontal bar chart\n",
    "swell_data_gdf[\"well_type\"].value_counts().hvplot.barh(\n",
    "    height=400,\n",
    "    width=600,\n",
    "    title=\"Surface Well Types Count\",\n",
    "    xlabel=\"\",\n",
    "    ylabel=\"\",\n",
    "    xaxis=\"bare\",\n",
    "    hover_cols=\"all\",\n",
    ").opts(\n",
    "    active_tools=[\"box_zoom\"],\n",
    "    toolbar=\"above\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot on a map the dry holes\n",
    "dry_hole_gdf = swell_data_gdf[swell_data_gdf[\"well_type\"] == \"Dry Hole\"]\n",
    "\n",
    "# vertorize the coordinates\n",
    "dry_hole_mer = platecaree_to_mercator_vectorised(\n",
    "    dry_hole_gdf[\"geometry\"].x, dry_hole_gdf[\"geometry\"].y\n",
    ")\n",
    "dry_hole_coords = pd.DataFrame(dry_hole_mer, columns=[\"x\", \"y\"])\n",
    "\n",
    "bg_map = get_background_map()\n",
    "# plot the dry holes on a map\n",
    "bg_map * gv.Points(\n",
    "    dry_hole_coords.reset_index(), [\"x\", \"y\"], [\"index\"], crs=ccrs.GOOGLE_MERCATOR\n",
    ").opts(width=800, height=600, title=\"Dry Hole Locations\", size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to plot the well types on a map\n",
    "def plot_well_types(gdf, well_type):\n",
    "    \"\"\"Plots the well types on a map\"\"\"\n",
    "    # filter the swell_data_gdf for the well_type\n",
    "    well_type_gdf = gdf[gdf[\"well_type\"] == well_type]\n",
    "    # vertorize the coordinates\n",
    "    well_type_mer = platecaree_to_mercator_vectorised(\n",
    "        well_type_gdf[\"geometry\"].x, well_type_gdf[\"geometry\"].y\n",
    "    )\n",
    "    well_type_coords = pd.DataFrame(well_type_mer, columns=[\"x\", \"y\"])\n",
    "    # plot the well types on a map\n",
    "    return get_background_map() * gv.Points(\n",
    "        well_type_coords.reset_index(),\n",
    "        [\"x\", \"y\"],\n",
    "        [\"index\"],\n",
    "        crs=ccrs.GOOGLE_MERCATOR,\n",
    "    ).opts(width=800, height=600, title=f\"{well_type} Locations\", size=1).opts(\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        toolbar=\"above\",\n",
    "        xaxis=\"bare\",\n",
    "        yaxis=\"bare\",\n",
    "        tools=[\"hover\"],\n",
    "    )\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# create a partial function for the plot_well_types function\n",
    "plot_well_types_partial = partial(plot_well_types, swell_data_gdf)\n",
    "\n",
    "plot_well_types_partial(\"Plugged/Shut-in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:56143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<panel.io.server.Server at 0x1b59b3e3970>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Dropping a patch because it contains a previously known reference (id='9766cbec-e16f-4fbc-ad66-e88dce21d6c7'). Most of the time this is harmless and usually a result of updating a model on one side of a communications channel while it was being removed on the other end.\n",
      "WARNING:root:Dropping a patch because it contains a previously known reference (id='d3f4c48d-5031-4c8d-89f8-2aaafd01de00'). Most of the time this is harmless and usually a result of updating a model on one side of a communications channel while it was being removed on the other end.\n",
      "WARNING:root:Dropping a patch because it contains a previously known reference (id='d3f4c48d-5031-4c8d-89f8-2aaafd01de00'). Most of the time this is harmless and usually a result of updating a model on one side of a communications channel while it was being removed on the other end.\n",
      "WARNING:root:Dropping a patch because it contains a previously known reference (id='d3f4c48d-5031-4c8d-89f8-2aaafd01de00'). Most of the time this is harmless and usually a result of updating a model on one side of a communications channel while it was being removed on the other end.\n",
      "WARNING:root:Dropping a patch because it contains a previously known reference (id='d3f4c48d-5031-4c8d-89f8-2aaafd01de00'). Most of the time this is harmless and usually a result of updating a model on one side of a communications channel while it was being removed on the other end.\n"
     ]
    }
   ],
   "source": [
    "def plot_well_types(well_type, size):\n",
    "    \"\"\"Plots the well types on a map\"\"\"\n",
    "    # filter the swell_data_gdf for the well_type\n",
    "    well_type_gdf = swell_data_gdf[swell_data_gdf[\"well_type\"] == well_type]\n",
    "    # vectorize the coordinates\n",
    "    well_type_mer = platecaree_to_mercator_vectorised(\n",
    "        well_type_gdf[\"geometry\"].x, well_type_gdf[\"geometry\"].y\n",
    "    )\n",
    "    well_type_coords = pd.DataFrame(well_type_mer, columns=[\"x\", \"y\"])\n",
    "    # plot the well types on a map\n",
    "    return get_background_map() * gv.Points(\n",
    "        well_type_coords.reset_index(),\n",
    "        [\"x\", \"y\"],\n",
    "        [\"index\"],\n",
    "        crs=ccrs.GOOGLE_MERCATOR,\n",
    "    ).opts(width=800, height=600, title=f\"{well_type} Locations\", size=size).opts(\n",
    "        active_tools=[\"box_zoom\"],\n",
    "        toolbar=\"above\",\n",
    "        xaxis=\"bare\",\n",
    "        yaxis=\"bare\",\n",
    "        tools=[\"hover\"],\n",
    "    )\n",
    "\n",
    "\n",
    "# create the interactive plot\n",
    "pn.interact(plot_well_types, well_type=well_types, size=(1, 10)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Texas RRC bottom hole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>bottom_id</th>\n",
       "      <th>surface_id</th>\n",
       "      <th>symnum</th>\n",
       "      <th>apinum</th>\n",
       "      <th>reliab</th>\n",
       "      <th>api10</th>\n",
       "      <th>api</th>\n",
       "      <th>long27</th>\n",
       "      <th>lat27</th>\n",
       "      <th>long83</th>\n",
       "      <th>lat83</th>\n",
       "      <th>out_fips</th>\n",
       "      <th>cwellnum</th>\n",
       "      <th>radioact</th>\n",
       "      <th>wellid</th>\n",
       "      <th>stcode</th>\n",
       "      <th>source_file</th>\n",
       "      <th>county_code</th>\n",
       "      <th>well_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>956685</th>\n",
       "      <td>POINT (-102.70667 30.88163)</td>\n",
       "      <td>275973</td>\n",
       "      <td>275973</td>\n",
       "      <td>3</td>\n",
       "      <td>4237135055</td>\n",
       "      <td>15</td>\n",
       "      <td>37135055</td>\n",
       "      <td>37135055</td>\n",
       "      <td>-102.706672</td>\n",
       "      <td>30.881631</td>\n",
       "      <td>-102.707120</td>\n",
       "      <td>30.881808</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>35055</td>\n",
       "      <td>None</td>\n",
       "      <td>well371b</td>\n",
       "      <td>371</td>\n",
       "      <td>Dry Hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176607</th>\n",
       "      <td>POINT (-99.27824 31.55920)</td>\n",
       "      <td>473219</td>\n",
       "      <td>473219</td>\n",
       "      <td>3</td>\n",
       "      <td>42083</td>\n",
       "      <td>15</td>\n",
       "      <td>083</td>\n",
       "      <td>083</td>\n",
       "      <td>-99.278238</td>\n",
       "      <td>31.559200</td>\n",
       "      <td>-99.278570</td>\n",
       "      <td>31.559356</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>well083b</td>\n",
       "      <td>083</td>\n",
       "      <td>Dry Hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595793</th>\n",
       "      <td>POINT (-101.27394 35.65187)</td>\n",
       "      <td>1031978</td>\n",
       "      <td>1031978</td>\n",
       "      <td>4</td>\n",
       "      <td>4223300399</td>\n",
       "      <td>15</td>\n",
       "      <td>23300399</td>\n",
       "      <td>23300399</td>\n",
       "      <td>-101.273942</td>\n",
       "      <td>35.651871</td>\n",
       "      <td>-101.274381</td>\n",
       "      <td>35.651914</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>00399</td>\n",
       "      <td>None</td>\n",
       "      <td>well233b</td>\n",
       "      <td>233</td>\n",
       "      <td>Oil/Gas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           geometry  bottom_id  surface_id  symnum  \\\n",
       "956685  POINT (-102.70667 30.88163)     275973      275973       3   \n",
       "176607   POINT (-99.27824 31.55920)     473219      473219       3   \n",
       "595793  POINT (-101.27394 35.65187)    1031978     1031978       4   \n",
       "\n",
       "            apinum reliab     api10       api      long27      lat27  \\\n",
       "956685  4237135055     15  37135055  37135055 -102.706672  30.881631   \n",
       "176607       42083     15       083       083  -99.278238  31.559200   \n",
       "595793  4223300399     15  23300399  23300399 -101.273942  35.651871   \n",
       "\n",
       "            long83      lat83 out_fips cwellnum radioact wellid stcode  \\\n",
       "956685 -102.707120  30.881808        N        3     None  35055   None   \n",
       "176607  -99.278570  31.559356        N        3     None   None   None   \n",
       "595793 -101.274381  35.651914        N        2     None  00399   None   \n",
       "\n",
       "       source_file county_code well_type  \n",
       "956685    well371b         371  Dry Hole  \n",
       "176607    well083b         083  Dry Hole  \n",
       "595793    well233b         233   Oil/Gas  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1375390 entries, 0 to 1375389\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count    Dtype   \n",
      "---  ------       --------------    -----   \n",
      " 0   geometry     1375390 non-null  geometry\n",
      " 1   bottom_id    1375390 non-null  int64   \n",
      " 2   surface_id   1375390 non-null  int64   \n",
      " 3   symnum       1375390 non-null  int64   \n",
      " 4   apinum       1375390 non-null  object  \n",
      " 5   reliab       1375390 non-null  object  \n",
      " 6   api10        1375390 non-null  object  \n",
      " 7   api          1375390 non-null  object  \n",
      " 8   long27       1375390 non-null  float64 \n",
      " 9   lat27        1375390 non-null  float64 \n",
      " 10  long83       1375390 non-null  float64 \n",
      " 11  lat83        1375390 non-null  float64 \n",
      " 12  out_fips     1375311 non-null  object  \n",
      " 13  cwellnum     1342491 non-null  object  \n",
      " 14  radioact     66484 non-null    object  \n",
      " 15  wellid       1011289 non-null  object  \n",
      " 16  stcode       169650 non-null   object  \n",
      " 17  source_file  1375390 non-null  object  \n",
      " 18  county_code  1375390 non-null  object  \n",
      " 19  well_type    1375390 non-null  object  \n",
      "dtypes: float64(4), geometry(1), int64(3), object(12)\n",
      "memory usage: 959.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the GeoDataFrames in well_dict into a single GeoDataFrame\n",
    "bwell_data_gdf = concat_gdf_from_dict(bwell_dict)\n",
    "\n",
    "# Convert the column names to snake case for consistency\n",
    "bwell_data_gdf.columns = [pascal_to_snake(col) for col in bwell_data_gdf.columns]\n",
    "# get the county code from the source_file column\n",
    "bwell_data_gdf[\"county_code\"] = bwell_data_gdf[\"source_file\"].str.extract(r\"(\\d{3})\")\n",
    "\n",
    "# map the dictionary to the SYMNUM column and fill the rare values with 'Other'\n",
    "bwell_data_gdf[\"well_type\"] = (\n",
    "    bwell_data_gdf[\"symnum\"].map(well_symnum_dict).fillna(\"Other\")\n",
    ")\n",
    "# Display a sample of 3 rows from the DataFrame\n",
    "display(bwell_data_gdf.sample(3))\n",
    "\n",
    "# Display information about the DataFrame, including the number of non-null entries in each column\n",
    "bwell_data_gdf.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "well_type\n",
       "Oil/Gas               467417\n",
       "Plugged/Shut-in       410482\n",
       "Dry Hole              293056\n",
       "Permitted Location    113777\n",
       "Canceled Location      44086\n",
       "Injection/Disposal     42881\n",
       "Water Supply            1262\n",
       "Storage                  847\n",
       "Core Test                763\n",
       "Other                    709\n",
       "Brine Mining             110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwell_data_gdf[\"well_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statewide API Data\n",
    "These file contains descriptive information about oil and gas wells which are maintained in the Railroad Commission of Texas (RRC) mapping system. This file is organized by map area and contains API number, survey name, well number, plug date, completion date, lease name, and lease I.D. The file is organized by USGS 7.5 minute quadrangle and is sorted by API number within each quadrangle. It is intended to be used along with location information extracted from the well mapping system. Records contained in this file will match the API numbers identified in the quad maps, and may not represent all known API numbers in the map area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [05:26<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "dbf_paths = glob.glob(\"../data/rrc_dbf/*.dbf\")\n",
    "\n",
    "dbfs = [gpd.read_file(file_path) for file_path in tqdm(dbf_paths)]\n",
    "\n",
    "dbf_df = pd.concat(dbfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 1471905 entries, 0 to 1471904\n",
      "Data columns (total 20 columns):\n",
      " #   Column      Non-Null Count    Dtype   \n",
      "---  ------      --------------    -----   \n",
      " 0   ABSTRACT    707806 non-null   object  \n",
      " 1   APINUM      1471905 non-null  object  \n",
      " 2   BLOCK       456972 non-null   object  \n",
      " 3   COMPLETION  1471905 non-null  object  \n",
      " 4   FIELD_NAME  1118264 non-null  object  \n",
      " 5   LEASE_NAME  1278963 non-null  object  \n",
      " 6   GAS_RRCID   1471905 non-null  object  \n",
      " 7   OIL_GAS_CO  1053499 non-null  object  \n",
      " 8   ON_OFF_SCH  1053499 non-null  object  \n",
      " 9   OPERATOR    1307889 non-null  object  \n",
      " 10  PERMIT_NUM  1471904 non-null  object  \n",
      " 11  PLUG_DATE   1471905 non-null  object  \n",
      " 12  REFER_TO_A  1471905 non-null  object  \n",
      " 13  SECTION     544908 non-null   object  \n",
      " 14  SURVEY      1041458 non-null  object  \n",
      " 15  TOTAL_DEPT  1471905 non-null  object  \n",
      " 16  WELLID      1324454 non-null  object  \n",
      " 17  QUADNUM     1281256 non-null  object  \n",
      " 18  OBJECTID_1  1471905 non-null  int64   \n",
      " 19  geometry    0 non-null        geometry\n",
      "dtypes: geometry(1), int64(1), object(18)\n",
      "memory usage: 224.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>APINUM</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>COMPLETION</th>\n",
       "      <th>FIELD_NAME</th>\n",
       "      <th>LEASE_NAME</th>\n",
       "      <th>GAS_RRCID</th>\n",
       "      <th>OIL_GAS_CO</th>\n",
       "      <th>ON_OFF_SCH</th>\n",
       "      <th>OPERATOR</th>\n",
       "      <th>PERMIT_NUM</th>\n",
       "      <th>PLUG_DATE</th>\n",
       "      <th>REFER_TO_A</th>\n",
       "      <th>SECTION</th>\n",
       "      <th>SURVEY</th>\n",
       "      <th>TOTAL_DEPT</th>\n",
       "      <th>WELLID</th>\n",
       "      <th>QUADNUM</th>\n",
       "      <th>OBJECTID_1</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1303210</th>\n",
       "      <td>None</td>\n",
       "      <td>46102471</td>\n",
       "      <td>F</td>\n",
       "      <td>19600627</td>\n",
       "      <td>MCELROY</td>\n",
       "      <td>MCELROY, J. T., CONS.</td>\n",
       "      <td>04161</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>CHEVRON U. S. A. INC.</td>\n",
       "      <td>000000</td>\n",
       "      <td>20030715</td>\n",
       "      <td>00000000</td>\n",
       "      <td>194</td>\n",
       "      <td>CCSD&amp;RGNG</td>\n",
       "      <td>3160</td>\n",
       "      <td>583 C</td>\n",
       "      <td>3102131</td>\n",
       "      <td>779646</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973013</th>\n",
       "      <td>None</td>\n",
       "      <td>35532879</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>FLOUR BLUFF (MASSIVES)</td>\n",
       "      <td>WEBB, L. A.</td>\n",
       "      <td>151261</td>\n",
       "      <td>G</td>\n",
       "      <td>Y</td>\n",
       "      <td>HEADINGTON OIL COMPANY</td>\n",
       "      <td>404883</td>\n",
       "      <td>20230320</td>\n",
       "      <td>00000000</td>\n",
       "      <td>47</td>\n",
       "      <td>FLOUR BLUFF &amp; ENCINAL FARM AND GARDEN TRACTS, ...</td>\n",
       "      <td>6650</td>\n",
       "      <td>18</td>\n",
       "      <td>2797424</td>\n",
       "      <td>1363157</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212338</th>\n",
       "      <td>None</td>\n",
       "      <td>07900038</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>SLAUGHTER</td>\n",
       "      <td>SLAUGHTER, NW. (SAN ANDRES) UNIT</td>\n",
       "      <td>19316</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>SCOUT ENERGY MANAGEMENT LLC</td>\n",
       "      <td>000000</td>\n",
       "      <td>20191219</td>\n",
       "      <td>00000000</td>\n",
       "      <td>None</td>\n",
       "      <td>LGE. 58, MARTIN CNTY SCHOOL LAND</td>\n",
       "      <td>4985</td>\n",
       "      <td>38</td>\n",
       "      <td>3302312</td>\n",
       "      <td>1320335</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ABSTRACT    APINUM BLOCK COMPLETION              FIELD_NAME  \\\n",
       "1303210     None  46102471     F   19600627                 MCELROY   \n",
       "973013      None  35532879  None          0  FLOUR BLUFF (MASSIVES)   \n",
       "212338      None  07900038  None          0               SLAUGHTER   \n",
       "\n",
       "                               LEASE_NAME GAS_RRCID OIL_GAS_CO ON_OFF_SCH  \\\n",
       "1303210             MCELROY, J. T., CONS.     04161          O          Y   \n",
       "973013                        WEBB, L. A.    151261          G          Y   \n",
       "212338   SLAUGHTER, NW. (SAN ANDRES) UNIT     19316          O          Y   \n",
       "\n",
       "                            OPERATOR PERMIT_NUM PLUG_DATE REFER_TO_A SECTION  \\\n",
       "1303210        CHEVRON U. S. A. INC.     000000  20030715   00000000     194   \n",
       "973013        HEADINGTON OIL COMPANY     404883  20230320   00000000      47   \n",
       "212338   SCOUT ENERGY MANAGEMENT LLC     000000  20191219   00000000    None   \n",
       "\n",
       "                                                    SURVEY TOTAL_DEPT WELLID  \\\n",
       "1303210                                          CCSD&RGNG       3160  583 C   \n",
       "973013   FLOUR BLUFF & ENCINAL FARM AND GARDEN TRACTS, ...       6650     18   \n",
       "212338                    LGE. 58, MARTIN CNTY SCHOOL LAND       4985     38   \n",
       "\n",
       "         QUADNUM  OBJECTID_1 geometry  \n",
       "1303210  3102131      779646     None  \n",
       "973013   2797424     1363157     None  \n",
       "212338   3302312     1320335     None  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbf_df.info()\n",
    "\n",
    "dbf_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### matching the mismatched wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "swell_columns = [\"api\", \"lat83\", \"long83\", \"well_type\"]\n",
    "mismatch_columns = [\"tx_api\", \"lon\", \"lat\", \"original_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_api</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>original_index</th>\n",
       "      <th>api</th>\n",
       "      <th>lat83</th>\n",
       "      <th>long83</th>\n",
       "      <th>well_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17732704</td>\n",
       "      <td>-92.950000</td>\n",
       "      <td>34.090000</td>\n",
       "      <td>18718</td>\n",
       "      <td>17732704</td>\n",
       "      <td>29.446890</td>\n",
       "      <td>-97.349024</td>\n",
       "      <td>Horizontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28333445</td>\n",
       "      <td>-99.247072</td>\n",
       "      <td>25.177289</td>\n",
       "      <td>18906</td>\n",
       "      <td>28333445</td>\n",
       "      <td>28.177606</td>\n",
       "      <td>-99.247488</td>\n",
       "      <td>Horizontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41931708</td>\n",
       "      <td>-93.614330</td>\n",
       "      <td>31.610560</td>\n",
       "      <td>18977</td>\n",
       "      <td>41931708</td>\n",
       "      <td>31.609584</td>\n",
       "      <td>-93.948177</td>\n",
       "      <td>Horizontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28333425</td>\n",
       "      <td>-98.682000</td>\n",
       "      <td>26.172000</td>\n",
       "      <td>19199</td>\n",
       "      <td>28333425</td>\n",
       "      <td>28.338389</td>\n",
       "      <td>-99.185575</td>\n",
       "      <td>Horizontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28333427</td>\n",
       "      <td>-98.682000</td>\n",
       "      <td>26.172000</td>\n",
       "      <td>19200</td>\n",
       "      <td>28333427</td>\n",
       "      <td>28.338362</td>\n",
       "      <td>-99.185606</td>\n",
       "      <td>Horizontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>02540913</td>\n",
       "      <td>-104.746472</td>\n",
       "      <td>30.737142</td>\n",
       "      <td>141853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>01546920</td>\n",
       "      <td>-104.105383</td>\n",
       "      <td>31.138073</td>\n",
       "      <td>148157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>01121004</td>\n",
       "      <td>-95.523224</td>\n",
       "      <td>30.509602</td>\n",
       "      <td>199347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>22238280</td>\n",
       "      <td>-101.261797</td>\n",
       "      <td>32.103056</td>\n",
       "      <td>211333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>24132476</td>\n",
       "      <td>-96.309777</td>\n",
       "      <td>30.697778</td>\n",
       "      <td>212350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tx_api         lon        lat  original_index       api      lat83  \\\n",
       "0   17732704  -92.950000  34.090000           18718  17732704  29.446890   \n",
       "1   28333445  -99.247072  25.177289           18906  28333445  28.177606   \n",
       "2   41931708  -93.614330  31.610560           18977  41931708  31.609584   \n",
       "3   28333425  -98.682000  26.172000           19199  28333425  28.338389   \n",
       "4   28333427  -98.682000  26.172000           19200  28333427  28.338362   \n",
       "..       ...         ...        ...             ...       ...        ...   \n",
       "73  02540913 -104.746472  30.737142          141853       NaN        NaN   \n",
       "74  01546920 -104.105383  31.138073          148157       NaN        NaN   \n",
       "75  01121004  -95.523224  30.509602          199347       NaN        NaN   \n",
       "76  22238280 -101.261797  32.103056          211333       NaN        NaN   \n",
       "77  24132476  -96.309777  30.697778          212350       NaN        NaN   \n",
       "\n",
       "       long83   well_type  \n",
       "0  -97.349024  Horizontal  \n",
       "1  -99.247488  Horizontal  \n",
       "2  -93.948177  Horizontal  \n",
       "3  -99.185575  Horizontal  \n",
       "4  -99.185606  Horizontal  \n",
       "..        ...         ...  \n",
       "73        NaN         NaN  \n",
       "74        NaN         NaN  \n",
       "75        NaN         NaN  \n",
       "76        NaN         NaN  \n",
       "77        NaN         NaN  \n",
       "\n",
       "[78 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch_geo_tx[mismatch_columns].merge(\n",
    "    swell_data_gdf[swell_columns], how=\"left\", left_on=\"tx_api\", right_on=\"api\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_mismatch_tx = mismatch_geo_tx[mismatch_columns].merge(\n",
    "    swell_data_gdf[swell_columns], how=\"left\", left_on=\"tx_api\", right_on=\"api\"\n",
    ")\n",
    "\n",
    "# set the index to the original_index column\n",
    "joined_mismatch_tx.set_index(\"original_index\", inplace=True)\n",
    "\n",
    "# replace the lat and lon values with the lat83 and lon83 values if not nan\n",
    "joined_mismatch_tx.loc[joined_mismatch_tx[\"lat83\"].notna(), \"lat\"] = joined_mismatch_tx[\n",
    "    \"lat83\"\n",
    "]\n",
    "joined_mismatch_tx.loc[\n",
    "    joined_mismatch_tx[\"long83\"].notna(), \"lon\"\n",
    "] = joined_mismatch_tx[\"long83\"]\n",
    "\n",
    "# Update 'lat' and 'lon' in the original DataFrame\n",
    "\n",
    "\n",
    "registry_gdf.loc[joined_mismatch_tx.index, \"lat\"] = joined_mismatch_tx[\"lat\"]\n",
    "registry_gdf.loc[joined_mismatch_tx.index, \"lon\"] = joined_mismatch_tx[\"lon\"]\n",
    "\n",
    "\n",
    "# Update 'geometry' in the original DataFrame\n",
    "registry_gdf.loc[joined_mismatch_tx.index, \"geometry\"] = [\n",
    "    Point(xy) for xy in zip(joined_mismatch_tx.lon, joined_mismatch_tx.lat)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with mismatched state values: 77\n"
     ]
    }
   ],
   "source": [
    "# Repeat the spatial join with registry_gdf and county_fips_gdf\n",
    "registry_county_gdf_2 = registry_gdf.sjoin(\n",
    "    county_fips_gdf, how=\"left\", predicate=\"intersects\"\n",
    ").drop(columns=[\"index_right\"])\n",
    "\n",
    "mismatched_geo_2 = registry_county_gdf_2[\n",
    "    registry_county_gdf_2[\"state_left\"] != registry_county_gdf_2[\"state_right\"]\n",
    "]\n",
    "print(f\"Number of rows with mismatched state values: {mismatched_geo_2.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another check is for rows where the `county_code` is an even number. Although the API number does not follow the state fips code as its first 2 numbers, the next 3 numbers do follow the county fips code. County fips codes are mostly odd numbers (almost exclusively) so any even number in the `county_code` column is most likely incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>api</th>\n",
       "      <th>well</th>\n",
       "      <th>state_left</th>\n",
       "      <th>state_right</th>\n",
       "      <th>county_left</th>\n",
       "      <th>county_right</th>\n",
       "      <th>county_code</th>\n",
       "      <th>countyfp</th>\n",
       "      <th>operator</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210599</th>\n",
       "      <td>04228337070000</td>\n",
       "      <td>PAVLICEK UNIT 2H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Santa Cruz Offshore Islands</td>\n",
       "      <td>Lavaca County</td>\n",
       "      <td>228</td>\n",
       "      <td>285</td>\n",
       "      <td>PENN VIRGINIA CORPORATION</td>\n",
       "      <td>-97.149289</td>\n",
       "      <td>29.538730</td>\n",
       "      <td>POINT (-97.14929 29.53873)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211666</th>\n",
       "      <td>04218530868000</td>\n",
       "      <td>NGR FIVELAND 1H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - San Clemente Offshore Islands</td>\n",
       "      <td>Grimes County</td>\n",
       "      <td>218</td>\n",
       "      <td>185</td>\n",
       "      <td>NEW GULF RESOURCES, LLC</td>\n",
       "      <td>-96.152663</td>\n",
       "      <td>30.653893</td>\n",
       "      <td>POINT (-96.15266 30.65389)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212374</th>\n",
       "      <td>04226131591000</td>\n",
       "      <td>MRS SK EAST  229</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Santa Catalina Offshore Islands</td>\n",
       "      <td>Kenedy County</td>\n",
       "      <td>226</td>\n",
       "      <td>261</td>\n",
       "      <td>HEADINGTON ENERGY PARTNERS, LLC</td>\n",
       "      <td>-97.867600</td>\n",
       "      <td>27.024900</td>\n",
       "      <td>POINT (-97.86760 27.02490)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212761</th>\n",
       "      <td>04216334169000</td>\n",
       "      <td>WHITWELL G 119H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Anacapa Offshore Islands</td>\n",
       "      <td>Frio County</td>\n",
       "      <td>216</td>\n",
       "      <td>163</td>\n",
       "      <td>TRINITY OPERATING (USG), LLC</td>\n",
       "      <td>-99.320600</td>\n",
       "      <td>28.728100</td>\n",
       "      <td>POINT (-99.32060 28.72810)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212762</th>\n",
       "      <td>04216334169000</td>\n",
       "      <td>WHITWELL G 119H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Anacapa Offshore Islands</td>\n",
       "      <td>Frio County</td>\n",
       "      <td>216</td>\n",
       "      <td>163</td>\n",
       "      <td>TRINITY OPERATING (USG), LLC</td>\n",
       "      <td>-99.320600</td>\n",
       "      <td>28.728100</td>\n",
       "      <td>POINT (-99.32060 28.72810)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212765</th>\n",
       "      <td>04228336790000</td>\n",
       "      <td>MARTINEZ NORTH D 102H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Santa Cruz Offshore Islands</td>\n",
       "      <td>Dimmit County</td>\n",
       "      <td>228</td>\n",
       "      <td>127</td>\n",
       "      <td>TRINITY OPERATING (USG), LLC</td>\n",
       "      <td>-99.401100</td>\n",
       "      <td>28.618400</td>\n",
       "      <td>POINT (-99.40110 28.61840)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212766</th>\n",
       "      <td>04228336790000</td>\n",
       "      <td>MARTINEZ NORTH D 102H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Santa Cruz Offshore Islands</td>\n",
       "      <td>Dimmit County</td>\n",
       "      <td>228</td>\n",
       "      <td>127</td>\n",
       "      <td>TRINITY OPERATING (USG), LLC</td>\n",
       "      <td>-99.401100</td>\n",
       "      <td>28.618400</td>\n",
       "      <td>POINT (-99.40110 28.61840)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212767</th>\n",
       "      <td>04228336792000</td>\n",
       "      <td>MARTINEZ NORTH D 103H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Santa Cruz Offshore Islands</td>\n",
       "      <td>Dimmit County</td>\n",
       "      <td>228</td>\n",
       "      <td>127</td>\n",
       "      <td>TRINITY OPERATING (USG), LLC</td>\n",
       "      <td>-99.401100</td>\n",
       "      <td>28.618400</td>\n",
       "      <td>POINT (-99.40110 28.61840)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212768</th>\n",
       "      <td>04228336789000</td>\n",
       "      <td>MARTINEZ NORTH D 101H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Santa Cruz Offshore Islands</td>\n",
       "      <td>Dimmit County</td>\n",
       "      <td>228</td>\n",
       "      <td>127</td>\n",
       "      <td>TRINITY OPERATING (USG), LLC</td>\n",
       "      <td>-99.401200</td>\n",
       "      <td>28.618300</td>\n",
       "      <td>POINT (-99.40120 28.61830)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212769</th>\n",
       "      <td>04228336789000</td>\n",
       "      <td>MARTINEZ NORTH D 101H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Santa Cruz Offshore Islands</td>\n",
       "      <td>Dimmit County</td>\n",
       "      <td>228</td>\n",
       "      <td>127</td>\n",
       "      <td>TRINITY OPERATING (USG), LLC</td>\n",
       "      <td>-99.401200</td>\n",
       "      <td>28.618300</td>\n",
       "      <td>POINT (-99.40120 28.61830)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212783</th>\n",
       "      <td>04230133660000</td>\n",
       "      <td>PRICELESS C26-1 UNIT C 6H</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - Santa Rosa Offshore Islands</td>\n",
       "      <td>Loving County</td>\n",
       "      <td>230</td>\n",
       "      <td>301</td>\n",
       "      <td>ANADARKO PETROLEUM CORPORATION</td>\n",
       "      <td>-103.430352</td>\n",
       "      <td>31.828690</td>\n",
       "      <td>POINT (-103.43035 31.82869)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211333</th>\n",
       "      <td>04222382800000</td>\n",
       "      <td>CHALK, G. O.-D- 29</td>\n",
       "      <td>California</td>\n",
       "      <td>Texas</td>\n",
       "      <td>State Waters - San Nicolas Offshore Islands</td>\n",
       "      <td>Howard County</td>\n",
       "      <td>222</td>\n",
       "      <td>227</td>\n",
       "      <td>CONOCOPHILLIPS COMPANY/BURLINGTON RESOURCES</td>\n",
       "      <td>-101.261797</td>\n",
       "      <td>32.103056</td>\n",
       "      <td>POINT (-101.26180 32.10306)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   api                       well  state_left state_right  \\\n",
       "210599  04228337070000           PAVLICEK UNIT 2H  California       Texas   \n",
       "211666  04218530868000            NGR FIVELAND 1H  California       Texas   \n",
       "212374  04226131591000           MRS SK EAST  229  California       Texas   \n",
       "212761  04216334169000            WHITWELL G 119H  California       Texas   \n",
       "212762  04216334169000            WHITWELL G 119H  California       Texas   \n",
       "212765  04228336790000      MARTINEZ NORTH D 102H  California       Texas   \n",
       "212766  04228336790000      MARTINEZ NORTH D 102H  California       Texas   \n",
       "212767  04228336792000      MARTINEZ NORTH D 103H  California       Texas   \n",
       "212768  04228336789000      MARTINEZ NORTH D 101H  California       Texas   \n",
       "212769  04228336789000      MARTINEZ NORTH D 101H  California       Texas   \n",
       "212783  04230133660000  PRICELESS C26-1 UNIT C 6H  California       Texas   \n",
       "211333  04222382800000         CHALK, G. O.-D- 29  California       Texas   \n",
       "\n",
       "                                           county_left   county_right  \\\n",
       "210599      State Waters - Santa Cruz Offshore Islands  Lavaca County   \n",
       "211666    State Waters - San Clemente Offshore Islands  Grimes County   \n",
       "212374  State Waters - Santa Catalina Offshore Islands  Kenedy County   \n",
       "212761         State Waters - Anacapa Offshore Islands    Frio County   \n",
       "212762         State Waters - Anacapa Offshore Islands    Frio County   \n",
       "212765      State Waters - Santa Cruz Offshore Islands  Dimmit County   \n",
       "212766      State Waters - Santa Cruz Offshore Islands  Dimmit County   \n",
       "212767      State Waters - Santa Cruz Offshore Islands  Dimmit County   \n",
       "212768      State Waters - Santa Cruz Offshore Islands  Dimmit County   \n",
       "212769      State Waters - Santa Cruz Offshore Islands  Dimmit County   \n",
       "212783      State Waters - Santa Rosa Offshore Islands  Loving County   \n",
       "211333     State Waters - San Nicolas Offshore Islands  Howard County   \n",
       "\n",
       "       county_code countyfp                                     operator  \\\n",
       "210599         228      285                    PENN VIRGINIA CORPORATION   \n",
       "211666         218      185                      NEW GULF RESOURCES, LLC   \n",
       "212374         226      261              HEADINGTON ENERGY PARTNERS, LLC   \n",
       "212761         216      163                 TRINITY OPERATING (USG), LLC   \n",
       "212762         216      163                 TRINITY OPERATING (USG), LLC   \n",
       "212765         228      127                 TRINITY OPERATING (USG), LLC   \n",
       "212766         228      127                 TRINITY OPERATING (USG), LLC   \n",
       "212767         228      127                 TRINITY OPERATING (USG), LLC   \n",
       "212768         228      127                 TRINITY OPERATING (USG), LLC   \n",
       "212769         228      127                 TRINITY OPERATING (USG), LLC   \n",
       "212783         230      301               ANADARKO PETROLEUM CORPORATION   \n",
       "211333         222      227  CONOCOPHILLIPS COMPANY/BURLINGTON RESOURCES   \n",
       "\n",
       "               lon        lat                     geometry  \n",
       "210599  -97.149289  29.538730   POINT (-97.14929 29.53873)  \n",
       "211666  -96.152663  30.653893   POINT (-96.15266 30.65389)  \n",
       "212374  -97.867600  27.024900   POINT (-97.86760 27.02490)  \n",
       "212761  -99.320600  28.728100   POINT (-99.32060 28.72810)  \n",
       "212762  -99.320600  28.728100   POINT (-99.32060 28.72810)  \n",
       "212765  -99.401100  28.618400   POINT (-99.40110 28.61840)  \n",
       "212766  -99.401100  28.618400   POINT (-99.40110 28.61840)  \n",
       "212767  -99.401100  28.618400   POINT (-99.40110 28.61840)  \n",
       "212768  -99.401200  28.618300   POINT (-99.40120 28.61830)  \n",
       "212769  -99.401200  28.618300   POINT (-99.40120 28.61830)  \n",
       "212783 -103.430352  31.828690  POINT (-103.43035 31.82869)  \n",
       "211333 -101.261797  32.103056  POINT (-101.26180 32.10306)  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the the county_code which are even numbers\n",
    "mismatched_geo_2[\n",
    "    mismatched_geo_2[\"county_code\"].astype(int).apply(lambda x: x % 2 == 0)\n",
    "][trimmed_column_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which other wells may have a state value which did not agree with the spatial join result again\n",
    "registry_county_gdf = registry_gdf.sjoin(\n",
    "    county_fips_gdf, how=\"left\", predicate=\"intersects\"\n",
    ").drop(columns=[\"index_right\"])\n",
    "mismatch_geo = registry_county_gdf[registry_county_gdf[\"state_right\"].isna()]\n",
    "mismatch_geo.shape\n",
    "print(f\"Number of rows with mismatched state values: {mismatch_geo.shape[0]}\")\n",
    "if mismatch_geo.shape[0] > 0:\n",
    "    display(mismatch_geo.sample(3))\n",
    "else:\n",
    "    print(\"No rows with mismatched state values\")\n",
    "# display(mismatch_geo.sample(3))\n",
    "\n",
    "# drop the rows with null values in the state_right column of mismatch_geo from the registry_gdf\n",
    "print(f\"Number of rows before dropping: {registry_gdf.shape[0]}\")\n",
    "registry_gdf.drop(mismatch_geo.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows after dropping: {registry_gdf.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_gdf.sjoin(county_fips_gdf, how=\"left\", predicate=\"intersects\").drop(\n",
    "    columns=[\"index_right\"]\n",
    ")[trimmed_column_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the row where the county_left and county_right columns do not match\n",
    "trimmed_joined_gdf = registry_gdf.sjoin(\n",
    "    county_fips_gdf, how=\"left\", predicate=\"intersects\"\n",
    ").drop(columns=[\"index_right\"])[trimmed_column_set]\n",
    "state_mismatch_mask = (\n",
    "    trimmed_joined_gdf[\"state_left\"] != trimmed_joined_gdf[\"state_right\"]\n",
    ")\n",
    "state_mismatch_gdf = trimmed_joined_gdf[state_mismatch_mask]\n",
    "print(f\"Number of rows with mismatched county values: {state_mismatch_gdf.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mismatch_gdf.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the columns to keep\n",
    "columns_we_want = [\n",
    "    \"api\",\n",
    "    \"well\",\n",
    "    \"state_code\",\n",
    "    \"state_left\",\n",
    "    \"state_right\",\n",
    "    \"county_code\",\n",
    "    \"county_left\",\n",
    "    \"countyfp\",\n",
    "    \"name\",\n",
    "    \"operator\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"geoid\",\n",
    "    \"geometry\",\n",
    "]\n",
    "registry_county_gdf = registry_gdf.sjoin(\n",
    "    county_fips_gdf, how=\"left\", predicate=\"intersects\"\n",
    ").drop(columns=[\"index_right\"])[columns_we_want]\n",
    "\n",
    "print(f\"Number of rows: {registry_county_gdf.shape[0]}\")\n",
    "registry_county_gdf[\n",
    "    registry_county_gdf[\"state_left\"] != registry_county_gdf[\"state_right\"]\n",
    "][columns_we_want].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rows where the state_left is California with the state_right being Texas\n",
    "# This would represent where the geometry said Texas but the api or original dataset had California\n",
    "# we check the api with\n",
    "cali_tx_query = registry_county_gdf.query(\n",
    "    'state_left == \"California\" & state_right == \"Texas\"'\n",
    ")\n",
    "# from the query, take the last 9 of the api (well_id) with 42 at beginning\n",
    "# with county_code from county that was matched with the geometry\n",
    "cali_tx_query[\"state_code\"] = \"42\"\n",
    "cali_tx_query[\"county_code\"] = cali_tx_query[\"countyfp\"]\n",
    "cali_tx_query[\"well_id\"] = cali_tx_query[\"api\"].str[-9:]\n",
    "cali_tx_query[\"api\"] = (\n",
    "    cali_tx_query[\"state_code\"]\n",
    "    + cali_tx_query[\"county_code\"]\n",
    "    + cali_tx_query[\"well_id\"]\n",
    ")\n",
    "\n",
    "# put api, county_code and state_code into the registry_gdf\n",
    "registry_gdf.loc[\n",
    "    cali_tx_query.index, [\"api\", \"county_code\", \"state_code\"]\n",
    "] = cali_tx_query[[\"api\", \"county_code\", \"state_code\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_county_gdf[\n",
    "    registry_county_gdf[columns_we_want][\"state_left\"]\n",
    "    != registry_county_gdf[columns_we_want][\"state_right\"]\n",
    "][columns_we_want]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swell_data_gdf[\"well_type\"].value_counts()\n",
    "# well_data_gdf[well_data_gdf[\"well_type\"] == \"Other\"][\"symnum\"].value_counts()\n",
    "# look for the mismatch_geo_tx api in the swell_data_gdf and get those rrows\n",
    "\n",
    "mismatch_geo_tx_sw = swell_data_gdf[\n",
    "    swell_data_gdf[\"api\"].isin(mismatch_geo_tx[\"tx_api\"])\n",
    "].copy()\n",
    "mismatch_geo_tx_sw\n",
    "# convert the long83 and lat83 columns to geomety Points\n",
    "mismatch_geo_tx_sw[\"geometry\"] = [\n",
    "    Point(xy) for xy in zip(mismatch_geo_tx_sw.long83, mismatch_geo_tx_sw.lat83)\n",
    "]\n",
    "# create a GeoDataFrame from the mismatch_geo_tx_sw dataframe\n",
    "mismatch_geo_tx_sw = gpd.GeoDataFrame(\n",
    "    mismatch_geo_tx_sw, geometry=\"geometry\", crs=\"EPSG:4269\"\n",
    ")\n",
    "# plot the mismatch_geo_tx_sw GeoDataFrame\n",
    "# bg_map * gv.Points(mismatch_geo_tx_sw).opts(height=500, width=800, tools=[\"hover\"])\n",
    "\n",
    "mismatch_geo_tx_sw.sjoin(county_fips_gdf, how=\"left\", predicate=\"intersects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the length of the tx_api values\n",
    "swell_data_gdf[\"api\"].astype(\"string\").str.len().value_counts()\n",
    "\n",
    "# drop the rows with the api number length of 3\n",
    "swell_data_gdf.drop(\n",
    "    swell_data_gdf[swell_data_gdf[\"api\"].astype(\"string\").str.len() == 3].index,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_map = get_background_map()\n",
    "\n",
    "ok_counties = county_fips_gdf.query('state.str.contains(\"Oklahoma\")').copy()\n",
    "ok_counties.to_crs(\"EPSG:3857\", inplace=True)\n",
    "\n",
    "tx_counties = county_fips_gdf.query('state.str.contains(\"Texas\")').copy()\n",
    "tx_counties.to_crs(\"EPSG:3857\", inplace=True)\n",
    "\n",
    "ok_polys = gv.Polygons(ok_counties, crs=ccrs.GOOGLE_MERCATOR).opts(\n",
    "    projection=ccrs.GOOGLE_MERCATOR,\n",
    "    line_color=\"black\",\n",
    "    fill_alpha=0,\n",
    "    height=500,\n",
    "    width=500,\n",
    ")\n",
    "bg_map * ok_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of states that are in the Permian Basin.\n",
    "nm_tx = [\"New Mexico\", \"Texas\"]\n",
    "\n",
    "# Filter the county_fips_gdf DataFrame to include only the counties in the Permian states.\n",
    "counties_nm_tx_gdf = county_fips_gdf[county_fips_gdf[\"state\"].isin(nm_tx)]\n",
    "\n",
    "# Perform a spatial join between the registry_gdf and counties_nm_tx_gdf DataFrames.\n",
    "# This will add the data from counties_nm_tx_gdf to registry_gdf for matching locations.\n",
    "# After the join, drop the 'index_right' column as it's not needed.\n",
    "registry_nm_tx_gdf = registry_gdf.sjoin(counties_nm_tx_gdf).drop(\n",
    "    columns=[\"index_right\"]\n",
    ")\n",
    "registry_nm_tx_gdf.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_nm_tx_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_nm_tx_gdf[\"operator_name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pivot table with the count of operators for each year\n",
    "operator_year_count = registry_nm_tx_gdf.pivot_table(\n",
    "    index=\"operator_name\", columns=\"job_start_year\", values=\"api\", aggfunc=\"count\"\n",
    ")\n",
    "# See which operators were active every year\n",
    "# operator_year_count[operator_year_count.count(axis=1) == 11]\n",
    "\n",
    "# See who has been active for the last 5 years\n",
    "operator_active_5y = operator_year_count.loc[\n",
    "    ~operator_year_count.iloc[:, -5:].isna().any(axis=1)\n",
    "].fillna(0)\n",
    "\n",
    "# do some styler table formatting from pandas\n",
    "style = operator_active_5y.style.background_gradient(\n",
    "    cmap=\"cet_CET_L2_r\", axis=1, vmin=0, vmax=operator_year_count.max().max()\n",
    ")\n",
    "# Format the numbers in the table as integers\n",
    "style = style.format(\"{:.0f}\")\n",
    "print(f\"Number of operators active for the last 5 years: {len(operator_active_5y)}\")\n",
    "style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for rows where the first 2 characters of the api number are not 42 nor 30.\n",
    "# This is done to filter out rows that do not belong to the states we are interested in (Texas and New Mexico).\n",
    "api_mask = ~registry_nm_tx_gdf[\"api\"].str[0:2].isin([\"42\", \"30\"])\n",
    "\n",
    "# Apply the mask to the registry_nm_tx_gdf DataFrame to get the rows that match the condition.\n",
    "mismatch_state = registry_nm_tx_gdf[api_mask]\n",
    "\n",
    "# Display selected columns from the mismatch_state DataFrame.\n",
    "# These columns provide information about the well, its location, and the job start date.\n",
    "display(\n",
    "    mismatch_state[\n",
    "        [\n",
    "            \"api\",\n",
    "            \"api_number\",\n",
    "            \"state_right\",\n",
    "            \"state_name\",\n",
    "            \"state_number\",\n",
    "            \"well_name\",\n",
    "            \"operator_name\",\n",
    "            \"county_name\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"geometry\",\n",
    "            \"crs\",\n",
    "            \"job_start_date\",\n",
    "            # \"county\",\n",
    "            \"countyfp\",\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# get a background map\n",
    "bg_map = get_background_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the coordinates to Mercator\n",
    "mercator_coords = platecaree_to_mercator_vectorised(\n",
    "    registry_nm_tx_gdf[\"geometry\"].x, registry_nm_tx_gdf[\"geometry\"].y\n",
    ")\n",
    "\n",
    "# Round the coordinates and create a DataFrame\n",
    "mer_points = pd.DataFrame(np.round(mercator_coords), columns=[\"x\", \"y\"])\n",
    "\n",
    "# Create a Points object for plotting\n",
    "gpoints = gv.Points(\n",
    "    mer_points.reset_index(), [\"x\", \"y\"], [\"index\"], crs=ccrs.GOOGLE_MERCATOR\n",
    ").opts(height=600, width=800, color=\"skyblue\", size=1, tools=[\"hover\"])\n",
    "\n",
    "# Create a layout with the background map and the points\n",
    "layout = bg_map * gpoints\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map files taken from the EIA website.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function 'extract_gdfs_from_zip_url_concurrent' to get GeoDataFrames from the URLs in 'basins_url_list'\n",
    "# This function concurrently downloads and extracts GeoDataFrames from the given URLs\n",
    "basins_dict = extract_gdfs_from_zip_url_concurrent(basins_url_list)\n",
    "\n",
    "# Display the keys of 'basins_dict' to see the names of the basins\n",
    "display(basins_dict.keys())\n",
    "\n",
    "# Concatenate the GeoDataFrames in 'basins_dict' into a single GeoDataFrame using the function 'concat_gdf_from_dict'\n",
    "basins_gdf = concat_gdf_from_dict(basins_dict)\n",
    "\n",
    "# Convert the column names of 'basins_gdf' to snake case for consistency\n",
    "# The function 'pascal_to_snake' is used to convert PascalCase or camelCase to snake_case\n",
    "basins_gdf.columns = [pascal_to_snake(col) for col in basins_gdf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of sub basins/ geodataframes: {len(basins_dict)}\\n\")\n",
    "\n",
    "for k, gdf in basins_dict.items():\n",
    "    print(f\"{k}| Shape:{gdf.shape}| CRS:{gdf.crs.to_string()}\")\n",
    "    display(gdf.sample())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the shapefile of the basin boundaries\n",
    "basins_dict = extract_gdfs_from_zip_url_concurrent(basins_url_list)\n",
    "display(basins_dict.keys())\n",
    "basins_gdf = concat_gdf_from_dict(basins_dict)\n",
    "# scrub the column names\n",
    "basins_gdf.columns = [pascal_to_snake(col) for col in basins_gdf.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot shale plays and basin boundaries of the different formations in the Permian Basin\n",
    "bg_map * basins_gdf.hvplot(\n",
    "    geo=True,\n",
    "    alpha=0.5,\n",
    "    title=\"Shale Plays in the Permian Basin\",\n",
    "    legend=True,\n",
    "    by=\"shale_play\",\n",
    "    muted_alpha=0.01,\n",
    ").opts(\n",
    "    tools=[\"hover\", \"tap\"],\n",
    "    legend_position=\"right\",\n",
    "    height=600,\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from holoviews import opts\n",
    "\n",
    "# Dissolve the geometries of the basins_gdf GeoDataFrame into a single geometry\n",
    "\n",
    "\n",
    "shale_plays_gdf = basins_gdf[[\"geometry\"]].dissolve()\n",
    "# get the counties in the Permian Basin\n",
    "permian_counties = county_fips_gdf.intersects(shale_plays_gdf)\n",
    "# plot the counties in the Permian Basin\n",
    "bg_map * gv.Polygons(county_fips_gdf[permian_counties]).opts(\n",
    "    title=\"Counties in the Permian Basin\",\n",
    "    tools=[\"hover\"],\n",
    "    height=600,\n",
    "    width=800,\n",
    "    alpha=0.5,\n",
    "    color=\"skyblue\",\n",
    ")\n",
    "# plot an outline of the Permian Basin over the counties\n",
    "overlay = (\n",
    "    bg_map\n",
    "    * gv.Polygons(county_fips_gdf[permian_counties])\n",
    "    * gv.Path(shale_plays_gdf)\n",
    "    # * gpoints\n",
    ")\n",
    "\n",
    "overlay.opts(\n",
    "    opts.Polygons(alpha=0.5, cmap=[\"#73d2ff\"], line_color=\"gray\"),\n",
    "    opts.Path(alpha=0.5, color=\"black\"),\n",
    "    opts.Overlay(tools=[\"hover\"], height=600, width=800),\n",
    "    opts.Points(color=\"crimson\"),\n",
    ")\n",
    "\n",
    "\n",
    "# plot to confirm that the geometries have been dissolved\n",
    "# bg_map * gv.Polygons(shale_plays_gdf).opts(\n",
    "#     # geo=True,\n",
    "#     title=\"Dissolved Shale play in the Permian Basin\",\n",
    "#     height=600,\n",
    "#     width=800,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State land leases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Mexico:\n",
    "> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the extract_gdfs_from_zip_url_concurrent function to download and extract GeoDataFrames\n",
    "# from the shapefile zip files at the URLs in the shp_url_list. The function returns a dictionary\n",
    "# where the keys are the names of the shapefiles and the values are the corresponding GeoDataFrames.\n",
    "nm_slo_dict = extract_gdfs_from_zip_url_concurrent(nm_slo_url_list)\n",
    "\n",
    "# Display the keys of the land_map_dict dictionary. These are the names of the shapefiles\n",
    "# that were downloaded and extracted.\n",
    "nm_slo_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# land_map_dict = extract_gdfs_from_zip_url_concurrent(shp_url_list)\n",
    "# land_map_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample the gdfs in the dictionary\n",
    "for k, gdf in nm_slo_dict.items():\n",
    "    print(f\"{k}| Shape:{gdf.shape}| CRS:{gdf.crs.to_string()}\")\n",
    "    display(gdf.sample(3))\n",
    "    display(gdf.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 separate gdfs instead of concatenating them as they have distinct columns\n",
    "nm_slo_gdfs = list(nm_slo_dict.values())\n",
    "# first one is the geologic regions\n",
    "nm_slo_geo = nm_slo_gdfs[0]\n",
    "# scrub the columns\n",
    "nm_slo_geo.columns = [pascal_to_snake(col) for col in nm_slo_geo.columns]\n",
    "\n",
    "# Define  a dictionary for the opts to include in plot function\n",
    "poly_opts = dict(\n",
    "    alpha=0.8,\n",
    "    height=600,\n",
    "    width=800,\n",
    "    line_width=0,\n",
    "    line_color=\"lightgray\",\n",
    "    tools=[\"hover\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Adjust opts for this plot\n",
    "poly_opts_copy = poly_opts.copy()\n",
    "poly_opts_copy[\"line_width\"] = 1\n",
    "\n",
    "# plot the geologic regions gdf\n",
    "bg_map * gv.Polygons(nm_slo_geo.to_crs(\"EPSG:4269\"), vdims=[\"label\"]).opts(\n",
    "    **poly_opts_copy, cmap=[\"#73d2ff\"] * 256, title=\"New Mexico Geologic Regions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second one is the oil and gas leases on New Mexico State Trust Lands\n",
    "nm_slo_lease = nm_slo_gdfs[1]\n",
    "# scrub the columns\n",
    "nm_slo_lease.columns = [pascal_to_snake(col) for col in nm_slo_lease.columns]\n",
    "# create a new column for the area of the lease\n",
    "nm_slo_lease[\"area\"] = nm_slo_lease[\"geometry\"].area\n",
    "# groupby the ogrid_nam and sum the area\n",
    "# add the transformed area to the gdf\n",
    "nm_slo_lease[\"ogrid_area\"] = (\n",
    "    nm_slo_lease.groupby(\"ogrid_nam\")[\"area\"].transform(\"sum\") / 1e6\n",
    ")\n",
    "\n",
    "# plot the oil and gas leases gdf for New Mexico State Trust Lands\n",
    "bg_map * gv.Polygons(\n",
    "    nm_slo_lease.to_crs(\"EPSG:4269\"), vdims=[\"ogrid_nam\", \"ogrid_area\"]\n",
    ").opts(\n",
    "    **poly_opts,\n",
    "    cnorm=\"eq_hist\",\n",
    "    colorbar=True,\n",
    "    title=\"Oil and Gas Leases on New Mexico State Trust Lands\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(land_map_dict.values())\n",
    "# [gdf['geometry'] for gdf in land_map_dict.values()]\n",
    "random_color_list = [\n",
    "    \"#\" + \"\".join([random.choice(\"0123456789ABCDEF\") for j in range(6)])\n",
    "    for i in range(len(nm_slo_dict))\n",
    "]\n",
    "plots = []\n",
    "new_map = get_background_map()\n",
    "plots.append(new_map)\n",
    "for color, (name, gdf) in zip(random_color_list, nm_slo_dict.items()):\n",
    "    # Add new column with the name of the shapefile for the hover tool\n",
    "    gdf[\"label\"] = name\n",
    "    plot = gv.Polygons(gdf.to_crs(\"EPSG:4269\"), vdims=[\"label\"]).opts(\n",
    "        tools=[\"hover\"], height=600, width=800, alpha=0.5, title=\"\"\n",
    "    )\n",
    "    plots.append(plot)\n",
    "\n",
    "overlay = hv.Overlay(plots)\n",
    "overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm_slo_lease.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the GeoDataFrames in well_dict into a single GeoDataFrame\n",
    "swell_data_gdf = concat_gdf_from_dict(swell_dict)\n",
    "\n",
    "# Convert the column names to snake case for consistency\n",
    "swell_data_gdf.columns = [pascal_to_snake(col) for col in swell_data_gdf.columns]\n",
    "# get the county code from the source_file column\n",
    "swell_data_gdf[\"county_code\"] = swell_data_gdf[\"source_file\"].str.extract(r\"(\\d{3})\")\n",
    "\n",
    "# Display a sample of 3 rows from the DataFrame\n",
    "display(swell_data_gdf.sample(3))\n",
    "\n",
    "# Display information about the DataFrame, including the number of non-null entries in each column\n",
    "swell_data_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the surv_data_gdf with the county number\n",
    "# the county_number wil be the numbers in the source_file column\n",
    "surv_data_gdf[\"county_number\"] = surv_data_gdf[\"source_file\"].str.extract(r\"(\\d{3})\")\n",
    "\n",
    "# using just the geometry and the county_number columns, intersect with the permian basin gdf\n",
    "surv_permian_gdf = surv_data_gdf[[\"geometry\", \"county_number\"]].sjoin(\n",
    "    shale_plays_gdf[[\"geometry\"]], how=\"inner\", predicate=\"intersects\"\n",
    ")\n",
    "# see which counties are in the permian basin\n",
    "pb_county_numbers = surv_permian_gdf[\"county_number\"].unique().tolist()\n",
    "\n",
    "# plot the survey lines in the permian basin\n",
    "bg_map * gv.Polygons(\n",
    "    surv_permian_gdf.to_crs(\"EPSG:4269\"), vdims=[\"county_number\"]\n",
    ").opts(\n",
    "    tools=[\"hover\"],\n",
    "    height=600,\n",
    "    width=800,\n",
    "    alpha=0.5,\n",
    "    line_width=0,\n",
    "    title=\"Permian Basin Survey Lines\",\n",
    ")\n",
    "\n",
    "# surv_data_gdf.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how land survey polygon data looks on map\n",
    "pb_plot = shale_plays_gdf.hvplot(geo=True, color=\"red\", alpha=0.5, line_width=0).opts(\n",
    "    height=600, width=800\n",
    ")\n",
    "survey_plot = surv_data_gdf.hvplot(geo=True, color=\"blue\", alpha=0.5, line_width=0)\n",
    "\n",
    "# bg_map * survey_plot * pb_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intersection of the survey polygons and the Permian Basin polygon\n",
    "survey_pb_gdf = gpd.overlay(surv_data_gdf, shale_plays_gdf, how=\"intersection\")\n",
    "survey_pb_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survey_pb_gdf.explore()\n",
    "# surv_data_gdf.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join of the registry_gdf(from fracfocus) and surv_data_gdf\n",
    "registry_join_gdf = gpd.sjoin(\n",
    "    registry_gdf[\n",
    "        [\n",
    "            \"geometry\",\n",
    "            \"api\",\n",
    "            \"operator_name\",\n",
    "            \"well_name\",\n",
    "            \"state\",\n",
    "            \"county_name\",\n",
    "            \"county_number\",\n",
    "        ]\n",
    "    ],\n",
    "    surv_data_gdf,\n",
    ").drop(columns=[\"index_right\"])\n",
    "\n",
    "\n",
    "registry_join_gdf.sort_values(by=\"api\")\n",
    "\n",
    "registry_join_gdf.county_name.value_counts()\n",
    "\n",
    "# create a well_id column from the api column\n",
    "\n",
    "registry_join_gdf[\"tx_api\"] = registry_join_gdf[\"api\"].str[2:10]\n",
    "\n",
    "\n",
    "# merge the welltype column from well_data_gdf to registry_join_gdf on the api_short column\n",
    "swell_data_gdf[\"tx_api\"] = swell_data_gdf[\"api\"].copy()\n",
    "\n",
    "registry_join_gdf = (\n",
    "    registry_join_gdf.merge(swell_data_gdf[[\"tx_api\", \"well_type\"]], on=\"tx_api\")\n",
    "    .drop(columns=[\"scrap_file\", \"level4_sur\"])\n",
    "    .rename(columns={\"level2_blo\": \"block\"})\n",
    ")\n",
    "# registry_join_gdf.explore()\n",
    "# plot polygons using geoviews\n",
    "# bg_map * gv.Polygons(registry_join_gdf.to_crs(\"EPSG:4269\"), vdims=[\"well_type\"]).opts(\n",
    "#     **poly_opts, color=\"well_type\", title=\"Well Types in the Permian Basin\"\n",
    "# )\n",
    "\n",
    "bg_map * registry_join_gdf.hvplot(\n",
    "    geo=True,\n",
    "    by=\"well_type\",\n",
    "    alpha=0.8,\n",
    "    legend=\"right\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    size=1,\n",
    "    muted_alpha=0.01,\n",
    "    tools=[\"box_select\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geodatabase files taken from the Texas GLO (General Land Office.)\n",
    "\n",
    "These files contained both the Oil and Gas Leases (active only), managed by the Texas GLO, and Oil & Gas units (active only) which is Oil and Gas pooling agreements managed by the Texas GLO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the geodataframe of the active leases\n",
    "# active_gdb_dict = read_gdb_from_zip_url(gdb_zip_urls)\n",
    "\n",
    "# get the geodataframe of the active leases using concurrent futures\n",
    "active_gdb_dict = read_gdb_from_zip_url_concurrent(GDB_ZIP_URLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_gdb_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, gdf in active_gdb_dict.items():\n",
    "    print(f\"{k}| Shape:{gdf.shape}| CRS:{gdf.crs.to_string()}\")\n",
    "    display(gdf.sample(3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the active lease geodatabase\n",
    "active_leases_gdf = active_gdb_dict[\"OAG_Leases_Active\"]\n",
    "# clean column names\n",
    "active_leases_gdf.columns = [pascal_to_snake(col) for col in active_leases_gdf.columns]\n",
    "active_leases_gdf.describe(include=\"all\").T.sort_values(\n",
    "    by=\"unique\", ascending=False\n",
    ").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the columns with the date in it using regex\n",
    "date_cols = [col for col in active_leases_gdf.columns if re.search(r\"date\", col)]\n",
    "# add any other columns that should be dates\n",
    "date_cols.extend([\"lease_input\"])\n",
    "\n",
    "date_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the date columns to datetime\n",
    "active_leases_gdf[date_cols] = pd.concat(\n",
    "    [pd.to_datetime(active_leases_gdf[col]) for col in date_cols], axis=1\n",
    ")\n",
    "# active_leases_gdf[date_cols] = active_leases_gdf[date_cols].fillna(\n",
    "#     pd.Timestamp(\"1900-06-28\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the columns interested in seeing\n",
    "columns_of_interest = date_cols + [\n",
    "    \"county\",\n",
    "    \"geometry\",\n",
    "    \"land_type\",\n",
    "    \"primary_term_year\",\n",
    "    \"original_lessee\",\n",
    "    \"lessor\",\n",
    "    \"field_name\",\n",
    "    \"lease_type\",\n",
    "    \"lease_status\",\n",
    "    \"lease_number\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_leases_gdf[columns_of_interest].info()\n",
    "active_leases_gdf[active_leases_gdf[columns_of_interest].isna().any(axis=1)][\n",
    "    columns_of_interest\n",
    "].sort_values(by=\"effective_date\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_leases_gdf_trimmed = active_leases_gdf[columns_of_interest]\n",
    "\n",
    "active_leases_gdf_trimmed[\"lease_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_date_cols = list(set(columns_of_interest) - set(date_cols))\n",
    "pd.concat(\n",
    "    [\n",
    "        active_leases_gdf[non_date_cols],\n",
    "        active_leases_gdf[date_cols].astype(\n",
    "            str\n",
    "        ),  # the .explore() does not work with NaT in datetime columns\n",
    "    ],\n",
    "    axis=1,\n",
    ").explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the active units geodatabase\n",
    "active_units_gdf = active_gdb_dict[\"OAG_Units_Active\"]\n",
    "# clean column names\n",
    "active_units_gdf.columns = [pascal_to_snake(col) for col in active_units_gdf.columns]\n",
    "active_units_gdf.describe(include=\"all\").T.sort_values(\n",
    "    by=\"unique\", ascending=False\n",
    ").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_units_gdf.field_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_units_gdf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Production Data Query Dump from RRC\n",
    "\n",
    "| Table | Description|\n",
    "|---|---|\n",
    "|GP_COUNTY | General purpose table that stores county information.|\n",
    "|GP_DATE_RANGE_CYCLE | General purpose table of PDQ data range ( Jan. 1993-current production report month/year). |\n",
    "|GP_DISTRICT | General purpose table that contains district information. |\n",
    "|OG_COUNTY_CYCLE | Contains production report data reported by lease and month (YYYYMM) aggregated by the county in which the wells are located.  |This is an estimate only based on allowables and potentials.\n",
    "|OG_COUNTY_LEASE_CYCLE | Contains production report data reported by lease and month (YYYYMM) aggregated by lease and county in which the wells  |are located. This is an estimate only based on allowables and potentials.\n",
    "|OG_DISTRICT_CYCLE | Contains production report data reported by lease and month (YYYYMM) aggregated by the completion district for the lease ID. |\n",
    "|OG_FIELD_CYCLE | Contains production report data reported by lease and month (YYYYMM) aggregated by the field in which the well(s) for the lease  |are completed.\n",
    "|OG_FIELD_DW | Table of field identifying data. |\n",
    "|OG_LEASE_CYCLE | Contains production report data reported by lease and month (YYYYMM). |\n",
    "|OG_LEASE_CYCLE_DISP | Contains production report disposition data reported by lease and month (YYYYMM). |\n",
    "|OG_OPERATOR_CYCLE | Contains production report data reported by lease and month (YYYYMM) aggregated by the operator of the lease. |\n",
    "|OG_OPERATOR_DW | This table contains identifying operator information. |\n",
    "|OG_REGULATORY_LEASE_DW | This table contains identifying lease information. |\n",
    "|OG_SUMMARY_MASTER_LARGE | Summary table. (Used for query purposes at the operator level) |\n",
    "|OG_SUMMARY_ONSHORE_LEASE | Summary table. (Used for query purposes on the leases in onshore counties) |\n",
    "|OG_WELL_COMPLETION | This table contains identifying well completion information. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data i from GCS by downloading the zip file to disk and then unipping it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "    # The ID of your GCS object\n",
    "    # source_blob_name = \"storage-object-name\"\n",
    "\n",
    "    # The path to which the file should be downloaded\n",
    "    # destination_file_name = \"local/path/to/file\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    # Construct a client side representation of a blob.\n",
    "    # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
    "    # any content from Google Cloud Storage. As we don't need additional data,\n",
    "    # using `Bucket.blob` is preferred here.\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print(\n",
    "        \"Downloaded storage object {} from bucket {} to local file {}.\".format(\n",
    "            source_blob_name, bucket_name, destination_file_name\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"mrprime_dataset\"\n",
    "blob_name = \"capstone_journey/rrc/PDQ_DSV.zip\"\n",
    "dl_file = Path(\"../data/PDQ_DSV.zip\")\n",
    "\n",
    "# Check if the directory exists\n",
    "if not dl_file.parent.exists():\n",
    "    # If the directory does not exist, create it\n",
    "    dl_file.parent.mkdir(parents=True)\n",
    "\n",
    "download_blob(bucket_name, blob_name, str(dl_file))\n",
    "\n",
    "# Create a new directory with the same name as the stem of the zip file\n",
    "extract_dir = dl_file.parent / dl_file.stem\n",
    "extract_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "with ZipFile(dl_file, \"r\") as zip_ref:\n",
    "    for name in zip_ref.namelist():\n",
    "        zip_ref.extract(name, extract_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data as parquet files from GCS. We were able to bring in the data without loading it on to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 16/16 [00:50<00:00,  3.14s/it]\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "# Create a client\n",
    "client = storage.Client()\n",
    "\n",
    "# Define the bucket name and the prefix\n",
    "bucket_name = \"mrprime_dataset\"\n",
    "prefix = \"capstone_journey/rrc/processed/\"\n",
    "\n",
    "# Get the bucket\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "# Get the blobs (files) in the bucket that match the prefix\n",
    "blobs = bucket.list_blobs(prefix=prefix)\n",
    "\n",
    "# Get the URLs of the data tables\n",
    "data_tables = set(\n",
    "    blob.name.rsplit(\"/\", 2)[1] for blob in blobs if \"_DATA_TABLE.parquet\" in blob.name\n",
    ")\n",
    "\n",
    "# Load each data table into a separate DataFrame\n",
    "dfs = {\n",
    "    data_table: dd.read_parquet(\n",
    "        f\"gs://{bucket_name}/{prefix}{data_table}/*.parquet\", engine=\"pyarrow\"\n",
    "    )\n",
    "    for data_table in tqdm(data_tables)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['OG_FIELD_DW_DATA_TABLE.parquet', 'OG_DISTRICT_CYCLE_DATA_TABLE.parquet', 'OG_LEASE_CYCLE_DATA_TABLE.parquet', 'OG_WELL_COMPLETION_DATA_TABLE.parquet', 'OG_REGULATORY_LEASE_DW_DATA_TABLE.parquet', 'OG_COUNTY_CYCLE_DATA_TABLE.parquet', 'OG_SUMMARY_ONSHORE_LEASE_DATA_TABLE.parquet', 'OG_COUNTY_LEASE_CYCLE_DATA_TABLE.parquet', 'GP_DATE_RANGE_CYCLE_DATA_TABLE.parquet', 'OG_LEASE_CYCLE_DISP_DATA_TABLE.parquet', 'OG_OPERATOR_DW_DATA_TABLE.parquet', 'GP_DISTRICT_DATA_TABLE.parquet', 'GP_COUNTY_DATA_TABLE.parquet', 'OG_OPERATOR_CYCLE_DATA_TABLE.parquet', 'OG_FIELD_CYCLE_DATA_TABLE.parquet', 'OG_SUMMARY_MASTER_LARGE_DATA_TABLE.parquet'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OG_FIELD_DW_DATA_TABLE',\n",
       " 'OG_DISTRICT_CYCLE_DATA_TABLE',\n",
       " 'OG_LEASE_CYCLE_DATA_TABLE',\n",
       " 'OG_WELL_COMPLETION_DATA_TABLE',\n",
       " 'OG_REGULATORY_LEASE_DW_DATA_TABLE',\n",
       " 'OG_COUNTY_CYCLE_DATA_TABLE',\n",
       " 'OG_SUMMARY_ONSHORE_LEASE_DATA_TABLE',\n",
       " 'OG_COUNTY_LEASE_CYCLE_DATA_TABLE',\n",
       " 'GP_DATE_RANGE_CYCLE_DATA_TABLE',\n",
       " 'OG_LEASE_CYCLE_DISP_DATA_TABLE',\n",
       " 'OG_OPERATOR_DW_DATA_TABLE',\n",
       " 'GP_DISTRICT_DATA_TABLE',\n",
       " 'GP_COUNTY_DATA_TABLE',\n",
       " 'OG_OPERATOR_CYCLE_DATA_TABLE',\n",
       " 'OG_FIELD_CYCLE_DATA_TABLE',\n",
       " 'OG_SUMMARY_MASTER_LARGE_DATA_TABLE']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIELD_NO</th>\n",
       "      <th>FIELD_NAME</th>\n",
       "      <th>DISTRICT_NO</th>\n",
       "      <th>DISTRICT_NAME</th>\n",
       "      <th>FIELD_CLASS</th>\n",
       "      <th>FIELD_H2S_FLAG</th>\n",
       "      <th>FIELD_MANUAL_REV_FLAG</th>\n",
       "      <th>WILDCAT_FLAG</th>\n",
       "      <th>O_DERIVED_RULE_TYPE_CODE</th>\n",
       "      <th>G_DERIVED_RULE_TYPE_CODE</th>\n",
       "      <th>O_RESCIND_DT</th>\n",
       "      <th>G_RESCIND_DT</th>\n",
       "      <th>O_SALT_DOME_FLAG</th>\n",
       "      <th>G_SALT_DOME_FLAG</th>\n",
       "      <th>O_OFFSHORE_CODE</th>\n",
       "      <th>G_OFFSHORE_CODE</th>\n",
       "      <th>O_DONT_PERMIT</th>\n",
       "      <th>G_DONT_PERMIT</th>\n",
       "      <th>O_NOA_MAN_REV_RULE</th>\n",
       "      <th>G_NOA_MAN_REV_RULE</th>\n",
       "      <th>O_COUNTY_NO</th>\n",
       "      <th>G_COUNTY_NO</th>\n",
       "      <th>O_DISCOVERY_DT</th>\n",
       "      <th>G_DISCOVERY_DT</th>\n",
       "      <th>O_SCHED_REMARKS</th>\n",
       "      <th>G_SCHED_REMARKS</th>\n",
       "      <th>O_COMMENTS</th>\n",
       "      <th>G_COMMENTS</th>\n",
       "      <th>CREATE_BY</th>\n",
       "      <th>CREATE_DT</th>\n",
       "      <th>MODIFY_BY</th>\n",
       "      <th>MODIFY_DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>WILDCAT-COMMISSION USE ONLY</td>\n",
       "      <td>4</td>\n",
       "      <td>04</td>\n",
       "      <td>O</td>\n",
       "      <td>N</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>N</td>\n",
       "      <td>SW</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-AUG-04</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FLU390 mainframe</td>\n",
       "      <td>19-OCT-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>WILDCAT</td>\n",
       "      <td>4</td>\n",
       "      <td>04</td>\n",
       "      <td>B</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>SW</td>\n",
       "      <td>SW</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01-MAR-72</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FLU390 mainframe</td>\n",
       "      <td>19-OCT-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8666</td>\n",
       "      <td>WILDCAT-COMMISSION USE ONLY</td>\n",
       "      <td>4</td>\n",
       "      <td>04</td>\n",
       "      <td>O</td>\n",
       "      <td>N</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>N</td>\n",
       "      <td>SW</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-AUG-04</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FLU390 mainframe</td>\n",
       "      <td>19-OCT-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8997</td>\n",
       "      <td>WILDCAT-COMMISSION USE ONLY</td>\n",
       "      <td>4</td>\n",
       "      <td>04</td>\n",
       "      <td>O</td>\n",
       "      <td>N</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>N</td>\n",
       "      <td>SW</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>355.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-AUG-04</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FLU390 mainframe</td>\n",
       "      <td>19-OCT-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8998</td>\n",
       "      <td>WILDCAT-COMMISSION USE ONLY</td>\n",
       "      <td>4</td>\n",
       "      <td>04</td>\n",
       "      <td>O</td>\n",
       "      <td>N</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>N</td>\n",
       "      <td>SW</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-AUG-04</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FLU390 mainframe</td>\n",
       "      <td>19-OCT-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIELD_NO                   FIELD_NAME  DISTRICT_NO DISTRICT_NAME  \\\n",
       "0      8000  WILDCAT-COMMISSION USE ONLY            4            04   \n",
       "1      8001                      WILDCAT            4            04   \n",
       "2      8666  WILDCAT-COMMISSION USE ONLY            4            04   \n",
       "3      8997  WILDCAT-COMMISSION USE ONLY            4            04   \n",
       "4      8998  WILDCAT-COMMISSION USE ONLY            4            04   \n",
       "\n",
       "  FIELD_CLASS FIELD_H2S_FLAG FIELD_MANUAL_REV_FLAG WILDCAT_FLAG  \\\n",
       "0           O              N                  <NA>            N   \n",
       "1           B              Y                     N            Y   \n",
       "2           O              N                  <NA>            N   \n",
       "3           O              N                  <NA>            N   \n",
       "4           O              N                  <NA>            N   \n",
       "\n",
       "  O_DERIVED_RULE_TYPE_CODE G_DERIVED_RULE_TYPE_CODE O_RESCIND_DT G_RESCIND_DT  \\\n",
       "0                       SW                     <NA>         <NA>         <NA>   \n",
       "1                       SW                       SW         <NA>         <NA>   \n",
       "2                       SW                     <NA>         <NA>         <NA>   \n",
       "3                       SW                     <NA>         <NA>         <NA>   \n",
       "4                       SW                     <NA>         <NA>         <NA>   \n",
       "\n",
       "  O_SALT_DOME_FLAG G_SALT_DOME_FLAG O_OFFSHORE_CODE G_OFFSHORE_CODE  \\\n",
       "0                N                N              L             <NA>   \n",
       "1                N                N              L               L    \n",
       "2                N                N              L             <NA>   \n",
       "3                N                N              L             <NA>   \n",
       "4                N                N              L             <NA>   \n",
       "\n",
       "  O_DONT_PERMIT G_DONT_PERMIT  O_NOA_MAN_REV_RULE  G_NOA_MAN_REV_RULE  \\\n",
       "0             Y             N                 NaN                 NaN   \n",
       "1             N             N                 NaN                 NaN   \n",
       "2             Y             N                 NaN                 NaN   \n",
       "3             Y             N                 NaN                 NaN   \n",
       "4             Y             N                 NaN                 NaN   \n",
       "\n",
       "   O_COUNTY_NO  G_COUNTY_NO O_DISCOVERY_DT G_DISCOVERY_DT  O_SCHED_REMARKS  \\\n",
       "0         47.0          NaN      11-AUG-04           <NA>              NaN   \n",
       "1        273.0          NaN      01-MAR-72           <NA>              NaN   \n",
       "2         47.0          NaN      11-AUG-04           <NA>              NaN   \n",
       "3        355.0          NaN      11-AUG-04           <NA>              NaN   \n",
       "4        215.0          NaN      11-AUG-04           <NA>              NaN   \n",
       "\n",
       "   G_SCHED_REMARKS O_COMMENTS G_COMMENTS         CREATE_BY  CREATE_DT  \\\n",
       "0              NaN       <NA>       <NA>  FLU390 mainframe  19-OCT-23   \n",
       "1              NaN       <NA>       <NA>  FLU390 mainframe  19-OCT-23   \n",
       "2              NaN       <NA>       <NA>  FLU390 mainframe  19-OCT-23   \n",
       "3              NaN       <NA>       <NA>  FLU390 mainframe  19-OCT-23   \n",
       "4              NaN       <NA>       <NA>  FLU390 mainframe  19-OCT-23   \n",
       "\n",
       "   MODIFY_BY  MODIFY_DT  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shortent the keys for brevity\n",
    "dfs = {k.split(\".\")[0]: v for k, v in dfs.items()}\n",
    "data_table_list = list(dfs.keys())\n",
    "display(data_table_list)\n",
    "dfs[data_table_list[0]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['og_field_dw',\n",
       " 'og_district_cycle',\n",
       " 'og_lease_cycle',\n",
       " 'og_well_completion',\n",
       " 'og_regulatory_lease_dw',\n",
       " 'og_county_cycle',\n",
       " 'og_summary_onshore_lease',\n",
       " 'og_county_lease_cycle',\n",
       " 'gp_date_range_cycle',\n",
       " 'og_lease_cycle_disp',\n",
       " 'og_operator_dw',\n",
       " 'gp_district',\n",
       " 'gp_county',\n",
       " 'og_operator_cycle',\n",
       " 'og_field_cycle',\n",
       " 'og_summary_master_large']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tables = [\n",
    "#     \"GP_COUNTY_DATA_TABLE\",\n",
    "#     \"GP_DISTRICT_DATA_TABLE\",\n",
    "#     \"GP_DATE_RANGE_CYCLE_DATA_TABLE\",\n",
    "#     \"OG_COUNTY_CYCLE_DATA_TABLE\",\n",
    "#     \"OG_COUNTY_LEASE_CYCLE_DATA_TABLE\",\n",
    "#     \"OG_LEASE_CYCLE_DATA_TABLE\",\n",
    "#     \"OG_LEASE_CYCLE_DISP_DATA_TABLE\",\n",
    "#     \"OG_DISTRICT_CYCLE_DATA_TABLE\",\n",
    "#     \"OG_FIELD_CYCLE_DATA_TABLE\",\n",
    "#     \"OG_OPERATOR_CYCLE_DATA_TABLE\",\n",
    "#     \"OG_FIELD_DW_DATA_TABLE\",\n",
    "#     \"OG_OPERATOR_DW_DATA_TABLE\",\n",
    "#     \"OG_REGULATORY_LEASE_DW_DATA_TABLE\",\n",
    "#     \"OG_WELL_COMPLETION_DATA_TABLE\",\n",
    "#     \"OG_SUMMARY_MASTER_LARGE_DATA_TABLE\",\n",
    "#     \"OG_SUMMARY_ONSHORE_LEASE_DATA_TABLE\",\n",
    "# ]\n",
    "\n",
    "\n",
    "short_table = [item.replace(\"_DATA_TABLE\", \"\").lower() for item in data_table_list]\n",
    "\n",
    "\n",
    "table_zip = zip(short_table, data_table_list)\n",
    "\n",
    "\n",
    "# Make the short table names the keys with dfs dict values\n",
    "data_tables_dict = {k: dfs[v] for k, v in table_zip}\n",
    "list(data_tables_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# general purpose table paths\n",
    "gp_county_path = Path(\"../data/PDQ_DSV/GP_COUNTY_DATA_TABLE.dsv\")\n",
    "gp_district_path = Path(\"../data/PDQ_DSV/GP_DISTRICT_DATA_TABLE.dsv\")\n",
    "gp_date_range_path = Path(\"../data/PDQ_DSV/GP_DATE_RANGE_CYCLE_DATA_TABLE.dsv\")\n",
    "\n",
    "\n",
    "# production data estimates based potentials and allowables paths\n",
    "og_county_cycle_path = Path(\"../data/PDQ_DSV/OG_COUNTY_CYCLE_DATA_TABLE.dsv\")\n",
    "og_county_lease_cycle_path = Path(\n",
    "    \"../data/PDQ_DSV/OG_COUNTY_LEASE_CYCLE_DATA_TABLE.dsv\"\n",
    ")\n",
    "\n",
    "# production disposition data by lease and month paths\n",
    "og_lease_cycle_disp_path = Path(\"../data/PDQ_DSV/OG_LEASE_CYCLE_DISP_DATA_TABLE.dsv\")\n",
    "\n",
    "\n",
    "# production report data by lease paths\n",
    "og_lease_cycle_path = Path(\"../data/PDQ_DSV/OG_LEASE_CYCLE_DATA_TABLE.dsv\")\n",
    "\n",
    "# production data by lease aggregated by another feature\n",
    "og_district_cycle_path = Path(\"../data/PDQ_DSV/OG_DISTRICT_CYCLE_DATA_TABLE.dsv\")\n",
    "og_field_cycle_path = Path(\"../data/PDQ_DSV/OG_FIELD_CYCLE_DATA_TABLE.dsv\")\n",
    "og_operator_cycle_path = Path(\"../data/PDQ_DSV/OG_OPERATOR_CYCLE_DATA_TABLE.dsv\")\n",
    "\n",
    "\n",
    "# identifying tables paths\n",
    "og_field_dw_path = Path(\"../data/PDQ_DSV/OG_FIELD_DW_DATA_TABLE.dsv\")\n",
    "og_operator_dw_path = Path(\"../data/PDQ_DSV/OG_OPERATOR_DW_DATA_TABLE.dsv\")\n",
    "og_regulatory_lease_dw_path = Path(\n",
    "    \"../data/PDQ_DSV/OG_REGULATORY_LEASE_DW_DATA_TABLE.dsv\"\n",
    ")\n",
    "# well completion data\n",
    "og_well_completion_path = Path(\"../data/PDQ_DSV/OG_WELL_COMPLETION_DATA_TABLE.dsv\")\n",
    "\n",
    "\n",
    "# summary tables\n",
    "og_summary_master_large_path = Path(\n",
    "    \"../data/PDQ_DSV/OG_SUMMARY_MASTER_LARGE_DATA_TABLE.dsv\"\n",
    ")\n",
    "og_summary_onshore_lease_path = Path(\n",
    "    \"../data/PDQ_DSV/OG_SUMMARY_ONSHORE_LEASE_DATA_TABLE.dsv\"\n",
    ")\n",
    "\n",
    "pdq_dsv_paths = [\n",
    "    gp_county_path,\n",
    "    gp_district_path,\n",
    "    gp_date_range_path,\n",
    "    og_county_cycle_path,\n",
    "    og_county_lease_cycle_path,\n",
    "    og_lease_cycle_path,\n",
    "    og_lease_cycle_disp_path,\n",
    "    og_district_cycle_path,\n",
    "    og_field_cycle_path,\n",
    "    og_operator_cycle_path,\n",
    "    og_field_dw_path,\n",
    "    og_operator_dw_path,\n",
    "    og_regulatory_lease_dw_path,\n",
    "    og_well_completion_path,\n",
    "    og_summary_master_large_path,\n",
    "    og_summary_onshore_lease_path,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# def get_csv_dtypes(path, sep=\"}\", nrows=10000):\n",
    "#     \"\"\"Reads in a csv file and returns the dtypes of the columns\"\"\"\n",
    "#     data = pd.read_csv(path, sep=sep, nrows=nrows)\n",
    "#     return data.dtypes.to_dict()\n",
    "from convert_to_parquet import get_csv_dtypes_for_all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def format_in_B(num):\n",
    "    \"\"\"Formats a number in thousands\"\"\"\n",
    "    for unit in [\"\", \"k\", \"M\", \"G\", \"T\"]:\n",
    "        if abs(num) < 1024:\n",
    "            return f\"{num:3.2f} {unit}B\"\n",
    "        num /= 1024\n",
    "    return f\"{num:.1f} TB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_table_overview_from_frame(table_name_dict, table_name):\n",
    "    \"\"\"Returns an overview of the data in a dask dataframe\"\"\"\n",
    "\n",
    "    # get the dask dataframe from the dictionary\n",
    "    ddf = table_name_dict[table_name]\n",
    "    # get the number of rows and columns\n",
    "    num_rows = ddf.shape[0]\n",
    "    # get the size on disk\n",
    "    size = ddf.memory_usage(deep=True).sum()\n",
    "    # get the column names\n",
    "    columns = ddf.columns.tolist()\n",
    "    # get the column dtypes\n",
    "    dtypes = ddf.dtypes.to_list()\n",
    "    # get the number of partitions\n",
    "\n",
    "    # compute values and put these properties in 1 row of a dataframe\n",
    "    num_rows, size = dask.compute(num_rows, size)\n",
    "    # create a dataframe with the properties\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"table\": [table_name],\n",
    "            \"rows\": [f\"{num_rows:,}\"],\n",
    "            \"cols\": [len(columns)],\n",
    "            \"columns\": [columns],\n",
    "            \"size\": [format_in_B(size)],\n",
    "            \"col_dtypes\": [dtypes],\n",
    "        }\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_table_overview(path, path_name, column_types={}):\n",
    "    \"\"\"\n",
    "    Returns an overview of the data in the file at the given path.\n",
    "\n",
    "    This function returns a dictionary containing the file name, the number of rows,\n",
    "    the column names, the first five rows of the data, and the column data types.\n",
    "    It uses Dask to efficiently compute the number of rows in the file, which makes\n",
    "    it suitable for large files.\n",
    "\n",
    "    Parameters:\n",
    "    path (Path or str): The path to the data file.\n",
    "\n",
    "    Returns:\n",
    "    dict: A pandas DataFrame containing the file overview.\n",
    "    \"\"\"\n",
    "    # column_types = {}\n",
    "    # Initialize ddf as an empty Dask DataFrame\n",
    "    while True:\n",
    "        try:\n",
    "            ddf = dd.read_csv(path, sep=\"}\", dtype=column_types)\n",
    "            num_rows = len(ddf)\n",
    "            break\n",
    "        except ValueError as e:\n",
    "            match = re.search(r\"dtype=\\{'(.*?)': '(.*?)'\", str(e))\n",
    "            # match = re.search(r\"dtype=\\{'(.*?)': 'object'\", str(e))\n",
    "            if match:\n",
    "                column_name = match.group(1)\n",
    "                column_types[column_name] = \"object\"\n",
    "\n",
    "    big_sample_data = pd.read_csv(path, sep=\"}\", nrows=10000, dtype=column_types)\n",
    "    if num_rows < 4:\n",
    "        sample_data = big_sample_data.sample(num_rows)\n",
    "    else:\n",
    "        sample_data = big_sample_data.sample(3)\n",
    "    # columns = sample_data.columns.tolist()\n",
    "\n",
    "    # column_dtypes = ddf.dtypes.tolist()\n",
    "    column_dtypes = ddf.dtypes.to_dict()\n",
    "    file_size = format_in_B(path.stat().st_size)\n",
    "\n",
    "    overview = pd.DataFrame(\n",
    "        {\n",
    "            \"table_var\": [path_name],\n",
    "            \"file_name\": [path.stem],\n",
    "            \"num_rows\": [f\"{num_rows:,}\"],\n",
    "            \"num_cols\": [len(column_dtypes)],\n",
    "            \"size_on_disk\": [file_size],\n",
    "            \"cols\": [list(column_dtypes.keys())],\n",
    "            \"col_dtypes\": [list(column_dtypes.values())],\n",
    "            \"file_path\": [path],\n",
    "            \"file_extension\": [path.suffix],\n",
    "            \"sample_data\": [sample_data.to_json()],\n",
    "        },\n",
    "    )\n",
    "    return overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_table_description(path, column_types={}):\n",
    "    \"\"\"\n",
    "    Returns a Dask dataframe with the statistical description of the data in the file at the given path.\n",
    "    \"\"\"\n",
    "    columns_needed = pd.read_csv(path, sep=\"}\", nrows=1).columns.tolist()\n",
    "    # create a new dict with only the keys needed\n",
    "    column_types_needed = {k: column_types[k] for k in columns_needed}\n",
    "    # Read the CSV file into a Dask dataframe\n",
    "    ddf = dd.read_csv(path, sep=\"}\", dtype=column_types_needed)\n",
    "\n",
    "    # Compute the descriptive statistics for the numeric columns\n",
    "    desc_ddf = ddf.describe(include=\"all\")\n",
    "    # add row with value in each of the columns in the describe dataframe for the dtype\n",
    "    num_dtypes = dd.from_pandas(\n",
    "        pd.DataFrame(desc_ddf.dtypes.apply(lambda x: x.name), columns=[\"dtype\"]).T,\n",
    "        npartitions=1,\n",
    "    )\n",
    "    # Return the descriptive statistics as a tuple of Dask dataframes\n",
    "    desc_ddf = dd.concat([desc_ddf, num_dtypes])\n",
    "\n",
    "    return desc_ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_table_description_from_frame(table_name_dict, table_name):\n",
    "    \"\"\"Returns a Dask Dataframe with the statistical description of the data in the table\"\"\"\n",
    "    # get the dask dataframe from the dictionary\n",
    "    ddf = table_name_dict[table_name]\n",
    "    # compute the descriptive statistics for the numeric columns\n",
    "    desc_ddf = ddf.describe(include=\"all\")\n",
    "    # add row with value in each of the columns in the describe dataframe for the dtype\n",
    "    ddf_dtypes = dd.from_pandas(\n",
    "        pd.DataFrame(desc_ddf.dtypes.apply(lambda x: x.name), columns=[\"dtype\"]).T,\n",
    "        npartitions=1,\n",
    "    )\n",
    "    # Return the descriptive statistics as a tuple of Dask dataframes\n",
    "    desc_ddf = dd.concat([desc_ddf, ddf_dtypes])\n",
    "    return desc_ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_data_for_plots(ddf):\n",
    "    \"\"\"takes in a dask dataframe and returns the df data to be used for plotting\"\"\"\n",
    "    # define order for the columns\n",
    "    column_order = [\n",
    "        \"dtype\",\n",
    "        \"count\",\n",
    "        \"unique\",\n",
    "        \"top\",\n",
    "        \"freq\",\n",
    "        \"mean\",\n",
    "        \"std\",\n",
    "        \"min\",\n",
    "        \"25%\",\n",
    "        \"50%\",\n",
    "        \"75%\",\n",
    "        \"max\",\n",
    "    ]\n",
    "    # get the data for the plots\n",
    "    computed_ddf = ddf.compute()\n",
    "    return computed_ddf.T[column_order].sort_values(by=\"dtype\", ascending=False)\n",
    "\n",
    "\n",
    "def plot_statistics_table_nonmissing_hbar(ddf, title=\"\"):\n",
    "    \"\"\"Plots a barh plot and a table in a layout.\"\"\"\n",
    "\n",
    "    # state opts of barh plot\n",
    "    hbar_opts = dict(\n",
    "        title=title,\n",
    "        ylabel=\"\",\n",
    "        xlabel=\"\",\n",
    "        xaxis=\"bare\",\n",
    "        tools=[\"hover\"],\n",
    "    )\n",
    "    df = pd.DataFrame()\n",
    "    df = get_data_for_plots(ddf)\n",
    "    # turn the count column into an int dtype column\n",
    "    df[\"count\"] = pd.to_numeric(df[\"count\"]).astype(int)\n",
    "    # round the values of the floats to integers\n",
    "    float_cols = [\"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"max\"]\n",
    "    for col in float_cols:\n",
    "        df[col] = pd.to_numeric(df[col].fillna(\"0.0\"), errors=\"coerce\").astype(int)\n",
    "    # df[float_cols] = df[float_cols].round(0)\n",
    "    # create a horizontal bartplot of the count column using hvplot\n",
    "    df[\"fraction_nonmissing\"] = round(df[\"count\"] / df[\"count\"].max(), 4)\n",
    "\n",
    "    element_height = (1 + df.shape[0]) * 33\n",
    "\n",
    "    # set the index to the query_field column\n",
    "\n",
    "    # hv_table = df.hvplot.table(\n",
    "    #     df.reset_index().columns.tolist(), width=1110, height=element_height\n",
    "    # )\n",
    "    table_panel = pnw.Tabulator(df.iloc[::-1], height=element_height)\n",
    "\n",
    "    barh_plot = df.hvplot.barh(\n",
    "        y=\"fraction_nonmissing\", height=element_height, **hbar_opts\n",
    "    ).opts(active_tools=[\"box_zoom\"], toolbar=\"above\")\n",
    "    barh_panel = pn.panel(barh_plot)\n",
    "\n",
    "    # return a panel row with the tabulator table and the bar plot\n",
    "    return pn.Row(\n",
    "        barh_panel,\n",
    "        table_panel,\n",
    "        sizing_mode=\"stretch_width\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def display_table_overview_from_frame(\n",
    "    persisted_overviews, table_name_dict, table_name, nrows=15, column_types={}\n",
    "):\n",
    "    \"\"\"Display an overview of the data in a Dask DataFrame.\"\"\"\n",
    "    over_view_table = persisted_overviews[table_name]\n",
    "    # over_view_table = get_table_overview_from_frame(\n",
    "    #     table_name_dict, table_name, column_types\n",
    "    # )\n",
    "\n",
    "    # display the shape of the table with decorative ~*~ around it\n",
    "    num_rows = over_view_table[\"rows\"].values[0]\n",
    "    num_cols = over_view_table[\"cols\"].values[0]\n",
    "    print(f\"~*~ {table_name} ~*~\")\n",
    "    print(f\"{num_rows} rows, {num_cols} columns\")\n",
    "\n",
    "    # get ddf from the dictionary\n",
    "    ddf = table_name_dict[table_name]\n",
    "    # display nrows of the dask dataframe\n",
    "    display(ddf.head(nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def display_table_overview(path, nrows=15, column_types={}):\n",
    "    \"\"\"\n",
    "    Displays an overview of the data in the file at the given path.\n",
    "\n",
    "    This function prints the file name, the number of rows, the column names,\n",
    "    and the first five rows of the data. It uses Dask to efficiently compute\n",
    "    the number of rows in the file, which makes it suitable for large files.\n",
    "\n",
    "    Parameters:\n",
    "    path (Path or str): The path to the data file.\n",
    "    \"\"\"\n",
    "    # make a decorative line\n",
    "    decor_length = len(path.name) + 8\n",
    "    decor = \"~*~\" * (decor_length // 3)\n",
    "\n",
    "    print(f\"{decor}\")\n",
    "    print(f\"File: {path.name}\")\n",
    "    print(f\"{decor}\")\n",
    "\n",
    "    # column_types = {}\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            ddf = dd.read_csv(path, sep=\"}\", dtype=column_types)\n",
    "            print(f\"Number of rows: {len(ddf):,}\")\n",
    "            break\n",
    "        except ValueError as e:\n",
    "            # print(e)\n",
    "            # If a ValueError occurs, parse the error message to get the column name\n",
    "            match = re.search(r\"dtype=\\{'(.*?)': '(.*?)'\", str(e))\n",
    "            # match = re.search(r\"dtype=\\{'(.*?)': 'object'\", str(e))\n",
    "            if match:\n",
    "                column_name = match.group(1)\n",
    "                print(f\"Problematic column: {column_name}\")\n",
    "                # Add the problematic column to the column types dictionary\n",
    "                column_types[column_name] = \"object\"\n",
    "\n",
    "    column_dtypes = ddf.dtypes.to_dict()\n",
    "    print(f\"File size: {format_in_B(path.stat().st_size)}\")\n",
    "    print(f\"Number of columns: {len(column_dtypes)}\")\n",
    "    # display(pd.DataFrame.from_dict(column_dtypes, orient=\"index\", columns=[\"dtype\"]))\n",
    "    print()\n",
    "\n",
    "    print(f\"Sample of data in {path.name}:\")\n",
    "    display(pd.read_csv(path, delimiter=\"}\", nrows=nrows, dtype=column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# define a function that combines get_table_description, plot_statistics_table_nonmissing_hbar\n",
    "# returns a panel card with the table and the bar plot\n",
    "def get_table_card(path, column_types={}):\n",
    "    \"\"\"returns a panel card with the table and the bar plot\"\"\"\n",
    "    results = get_table_description(path, column_types)\n",
    "    bar_table = plot_statistics_table_nonmissing_hbar(results, title=path.stem)\n",
    "    return pn.Card(bar_table, title=path.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def get_table_card_from_frame(table_name_dict, table_name):\n",
    "    \"\"\"returns a panel card with the table and the bar plot\"\"\"\n",
    "    results = get_table_description_from_frame(table_name_dict, table_name)\n",
    "    bar_table = plot_statistics_table_nonmissing_hbar(results, title=table_name)\n",
    "    return pn.Card(bar_table, title=table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a default diction to store the dtypes of the columns\n",
    "csv_dtypes = get_csv_dtypes_for_all_files()\n",
    "\n",
    "# # loop through the paths and get the dtypes of the columns\n",
    "# for fpath in pdq_dsv_paths:\n",
    "#     temp_dict = get_csv_dtypes(fpath)\n",
    "#     # only update values if the key is not in the dictionary\n",
    "#     for k, v in temp_dict.items():\n",
    "#         if k not in csv_dtypes:\n",
    "#             csv_dtypes[k] = v\n",
    "\n",
    "# csv_dtypes = {k: v.name for k, v in csv_dtypes.items()}\n",
    "# # csv_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable name is the path stem before _DATA_TABLE in lowercase\n",
    "# regular_expression?\n",
    "# pattern = r\"(\\w+)_DATA_TABLE\"\n",
    "\n",
    "# # find the variable pair from in the pdq_dsv_paths\n",
    "# variable_pairs = [\n",
    "#     (my_path, re.match(pattern, my_path.stem.upper()).group(1).lower())\n",
    "#     for my_path in pdq_dsv_paths\n",
    "#     if re.match(pattern, my_path.stem.upper())\n",
    "# ]\n",
    "# variable_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview list of data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of 1-row snips of the size of the data tables\n",
    "# overview_dfs_list = [\n",
    "#     get_table_overview(*pair, column_types=csv_dtypes) for pair in tqdm(variable_pairs)\n",
    "# ]\n",
    "# concaternate summary rows into a single dataframe\n",
    "# overview_dfs = pd.concat(overview_dfs_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview_dfs.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dask Client "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some tables are as large as 11GB, and this is why we use Dask. Dask enables us to handle large data files by spliting the data into chunks so that all the data is not loaded into memory at once. Dask also enables parallel processing when possible and enable us to manage the computational resources via a `Client` object. It can do a lot more too but that is outside our scope for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8788/status\n"
     ]
    }
   ],
   "source": [
    "# Create a Dask client with specified configuration\n",
    "# This client will use 4 workers, each with 1 thread and a memory limit of 2GB\n",
    "# The Dask diagnostic dashboard will be served at the address \":8788\"\n",
    "client = Client(\n",
    "    n_workers=4, threads_per_worker=1, memory_limit=\"3GB\", dashboard_address=\":8788\"\n",
    ")\n",
    "\n",
    "# Print the link to the Dask diagnostic dashboard\n",
    "# This link can be used to monitor the progress and performance of Dask computations\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 16/16 [08:10<00:00, 30.63s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>rows</th>\n",
       "      <th>cols</th>\n",
       "      <th>columns</th>\n",
       "      <th>size</th>\n",
       "      <th>col_dtypes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>og_field_dw</td>\n",
       "      <td>65,803</td>\n",
       "      <td>32</td>\n",
       "      <td>[FIELD_NO, FIELD_NAME, DISTRICT_NO, DISTRICT_N...</td>\n",
       "      <td>15.76 MB</td>\n",
       "      <td>[int64, string, int64, string, string, string,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>og_district_cycle</td>\n",
       "      <td>4,823</td>\n",
       "      <td>9</td>\n",
       "      <td>[DISTRICT_NO, CYCLE_YEAR, CYCLE_MONTH, CYCLE_Y...</td>\n",
       "      <td>367.38 kB</td>\n",
       "      <td>[int64, int64, int64, int64, string, int64, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>og_lease_cycle</td>\n",
       "      <td>70,708,285</td>\n",
       "      <td>32</td>\n",
       "      <td>[OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, CYCLE_YE...</td>\n",
       "      <td>19.69 GB</td>\n",
       "      <td>[string, int64, int64, int64, int64, int64, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>og_well_completion</td>\n",
       "      <td>796,550</td>\n",
       "      <td>16</td>\n",
       "      <td>[OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, WELL_NO,...</td>\n",
       "      <td>92.11 MB</td>\n",
       "      <td>[string, int64, int64, string, int64, int64, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>og_regulatory_lease_dw</td>\n",
       "      <td>532,918</td>\n",
       "      <td>12</td>\n",
       "      <td>[OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, DISTRICT...</td>\n",
       "      <td>68.75 MB</td>\n",
       "      <td>[string, int64, int64, string, string, int64, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>og_county_cycle</td>\n",
       "      <td>223,715</td>\n",
       "      <td>24</td>\n",
       "      <td>[COUNTY_NO, DISTRICT_NO, CYCLE_YEAR, CYCLE_MON...</td>\n",
       "      <td>42.22 MB</td>\n",
       "      <td>[int64, int64, int64, int64, int64, int64, flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>og_summary_onshore_lease</td>\n",
       "      <td>1,040,422</td>\n",
       "      <td>10</td>\n",
       "      <td>[OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, OPERATOR...</td>\n",
       "      <td>130.68 MB</td>\n",
       "      <td>[string, int64, int64, int64, int64, int64, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>og_county_lease_cycle</td>\n",
       "      <td>68,969,454</td>\n",
       "      <td>33</td>\n",
       "      <td>[OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, CYCLE_YE...</td>\n",
       "      <td>19.88 GB</td>\n",
       "      <td>[string, int64, int64, int64, int64, int64, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gp_date_range_cycle</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[OLDEST_PROD_CYCLE_YEAR_MONTH, NEWEST_PROD_CYC...</td>\n",
       "      <td>58.00 B</td>\n",
       "      <td>[int64, int64, int64, string, string]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>og_lease_cycle_disp</td>\n",
       "      <td>44,002,513</td>\n",
       "      <td>52</td>\n",
       "      <td>[OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, CYCLE_YE...</td>\n",
       "      <td>19.09 GB</td>\n",
       "      <td>[string, int64, int64, int64, int64, int64, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>og_operator_dw</td>\n",
       "      <td>76,383</td>\n",
       "      <td>14</td>\n",
       "      <td>[OPERATOR_NO, OPERATOR_NAME, P5_STATUS_CODE, P...</td>\n",
       "      <td>11.04 MB</td>\n",
       "      <td>[int64, string, string, int64, string, string,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gp_district</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>[DISTRICT_NO, DISTRICT_NAME, OFFICE_PHONE_NO, ...</td>\n",
       "      <td>599.00 B</td>\n",
       "      <td>[int64, string, int64, string]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gp_county</td>\n",
       "      <td>277</td>\n",
       "      <td>7</td>\n",
       "      <td>[COUNTY_NO, COUNTY_FIPS_CODE, COUNTY_NAME, DIS...</td>\n",
       "      <td>15.98 kB</td>\n",
       "      <td>[int64, int64, string, int64, string, string, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>og_operator_cycle</td>\n",
       "      <td>3,447,208</td>\n",
       "      <td>9</td>\n",
       "      <td>[OPERATOR_NO, CYCLE_YEAR, CYCLE_MONTH, CYCLE_Y...</td>\n",
       "      <td>317.90 MB</td>\n",
       "      <td>[int64, int64, int64, int64, string, int64, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>og_field_cycle</td>\n",
       "      <td>10,412,430</td>\n",
       "      <td>11</td>\n",
       "      <td>[DISTRICT_NO, FIELD_NO, CYCLE_YEAR, CYCLE_MONT...</td>\n",
       "      <td>1.08 GB</td>\n",
       "      <td>[int64, int64, int64, int64, int64, string, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>og_summary_master_large</td>\n",
       "      <td>1,049,072</td>\n",
       "      <td>11</td>\n",
       "      <td>[OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, OPERATOR...</td>\n",
       "      <td>137.64 MB</td>\n",
       "      <td>[string, int64, int64, int64, int64, int64, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       table        rows  cols  \\\n",
       "0                og_field_dw      65,803    32   \n",
       "1          og_district_cycle       4,823     9   \n",
       "2             og_lease_cycle  70,708,285    32   \n",
       "3         og_well_completion     796,550    16   \n",
       "4     og_regulatory_lease_dw     532,918    12   \n",
       "5            og_county_cycle     223,715    24   \n",
       "6   og_summary_onshore_lease   1,040,422    10   \n",
       "7      og_county_lease_cycle  68,969,454    33   \n",
       "8        gp_date_range_cycle           1     5   \n",
       "9        og_lease_cycle_disp  44,002,513    52   \n",
       "10            og_operator_dw      76,383    14   \n",
       "11               gp_district          14     4   \n",
       "12                 gp_county         277     7   \n",
       "13         og_operator_cycle   3,447,208     9   \n",
       "14            og_field_cycle  10,412,430    11   \n",
       "15   og_summary_master_large   1,049,072    11   \n",
       "\n",
       "                                              columns       size  \\\n",
       "0   [FIELD_NO, FIELD_NAME, DISTRICT_NO, DISTRICT_N...   15.76 MB   \n",
       "1   [DISTRICT_NO, CYCLE_YEAR, CYCLE_MONTH, CYCLE_Y...  367.38 kB   \n",
       "2   [OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, CYCLE_YE...   19.69 GB   \n",
       "3   [OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, WELL_NO,...   92.11 MB   \n",
       "4   [OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, DISTRICT...   68.75 MB   \n",
       "5   [COUNTY_NO, DISTRICT_NO, CYCLE_YEAR, CYCLE_MON...   42.22 MB   \n",
       "6   [OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, OPERATOR...  130.68 MB   \n",
       "7   [OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, CYCLE_YE...   19.88 GB   \n",
       "8   [OLDEST_PROD_CYCLE_YEAR_MONTH, NEWEST_PROD_CYC...    58.00 B   \n",
       "9   [OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, CYCLE_YE...   19.09 GB   \n",
       "10  [OPERATOR_NO, OPERATOR_NAME, P5_STATUS_CODE, P...   11.04 MB   \n",
       "11  [DISTRICT_NO, DISTRICT_NAME, OFFICE_PHONE_NO, ...   599.00 B   \n",
       "12  [COUNTY_NO, COUNTY_FIPS_CODE, COUNTY_NAME, DIS...   15.98 kB   \n",
       "13  [OPERATOR_NO, CYCLE_YEAR, CYCLE_MONTH, CYCLE_Y...  317.90 MB   \n",
       "14  [DISTRICT_NO, FIELD_NO, CYCLE_YEAR, CYCLE_MONT...    1.08 GB   \n",
       "15  [OIL_GAS_CODE, DISTRICT_NO, LEASE_NO, OPERATOR...  137.64 MB   \n",
       "\n",
       "                                           col_dtypes  \n",
       "0   [int64, string, int64, string, string, string,...  \n",
       "1   [int64, int64, int64, int64, string, int64, in...  \n",
       "2   [string, int64, int64, int64, int64, int64, in...  \n",
       "3   [string, int64, int64, string, int64, int64, i...  \n",
       "4   [string, int64, int64, string, string, int64, ...  \n",
       "5   [int64, int64, int64, int64, int64, int64, flo...  \n",
       "6   [string, int64, int64, int64, int64, int64, in...  \n",
       "7   [string, int64, int64, int64, int64, int64, in...  \n",
       "8               [int64, int64, int64, string, string]  \n",
       "9   [string, int64, int64, int64, int64, int64, in...  \n",
       "10  [int64, string, string, int64, string, string,...  \n",
       "11                     [int64, string, int64, string]  \n",
       "12  [int64, int64, string, int64, string, string, ...  \n",
       "13  [int64, int64, int64, int64, string, int64, in...  \n",
       "14  [int64, int64, int64, int64, int64, string, st...  \n",
       "15  [string, int64, int64, int64, int64, int64, in...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persisted_overviews = {}\n",
    "\n",
    "for table_name in tqdm(data_tables_dict.keys()):\n",
    "    overview_table = get_table_overview_from_frame(data_tables_dict, table_name)\n",
    "    (persisted_overview,) = persist(overview_table)\n",
    "    persisted_overviews[table_name] = persisted_overview\n",
    "\n",
    "persisted_overviews_list = [\n",
    "    persisted_overviews[table_name] for table_name in data_tables_dict\n",
    "]\n",
    "overview_dfs_from_frame = pd.concat(persisted_overviews_list, ignore_index=True)\n",
    "overview_dfs_from_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 0 - County\n",
    "\n",
    "General purpose table that stores county information.\n",
    "\n",
    "Below is the district_no, a number representing the RRC district_name in the RRC system associated with lease reporting.\n",
    "\n",
    " DISTRICT_no (RRC VALUE) | DISTRICT_NAME |\n",
    "|--|--|\n",
    "01|01 \n",
    "02|02 \n",
    "04|04 \n",
    "05|05 \n",
    "06|06 \n",
    "07|6E (oil only)\n",
    "|08|7B\n",
    "|10|08\n",
    "|11|8A\n",
    "|13|09\n",
    "|14|10\n",
    "This value is not used. 12 | 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_table_overview_from_frame(persisted_overviews, data_tables_dict, \"gp_county\")\n",
    "get_table_card_from_frame(data_tables_dict, \"gp_county\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dask dataframe\n",
    "# gp_county_ddf = dd.read_csv(file_path_0, sep=\"}\", dtype=csv_dtypes)\n",
    "gp_county_ddf = data_tables_dict[\"gp_county\"]\n",
    "\n",
    "gp_county_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the the column names to snake case\n",
    "gp_county_ddf.columns = [pascal_to_snake(col) for col in gp_county_ddf.columns]\n",
    "# create column is_onshore based on on_shore_flag column\n",
    "gp_county_ddf[\"is_onshore\"] = gp_county_ddf[\"on_shore_flag\"].map(\n",
    "    {\"Y\": True, \"N\": False}\n",
    ")\n",
    "gp_county_ddf[\"is_onshore_assc_cnty\"] = gp_county_ddf[\"onshore_assc_cnty_flag\"].map(\n",
    "    {\"Y\": True, \"N\": False}\n",
    ")\n",
    "\n",
    "# create a small table to link the district_no to the district_name\n",
    "gp_district_name = (\n",
    "    gp_county_ddf[[\"district_no\", \"district_name\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(by=\"district_no\")\n",
    "    .reset_index(drop=True)\n",
    "    .compute()\n",
    ")\n",
    "gp_district_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some of the extra columns\n",
    "column_to_drop = [\n",
    "    \"county_fips_code\",\n",
    "    \"district_name\",\n",
    "    \"on_shore_flag\",\n",
    "    \"onshore_assc_cnty_flag\",\n",
    "]\n",
    "columns_to_keep = [col for col in gp_county_ddf.columns if col not in column_to_drop]\n",
    "gp_county_ddf = gp_county_ddf[columns_to_keep]\n",
    "gp_county_ddf.info(memory_usage=\"deep\")\n",
    "gp_county_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of counties in each district\n",
    "district_county_count = (\n",
    "    gp_county_ddf.groupby(\"district_no\")\n",
    "    .county_no.nunique()\n",
    "    .rename(\"county_count\")\n",
    "    .compute()\n",
    ")\n",
    "\n",
    "district_county_count.hvplot.bar(\n",
    "    title=\"Count of Counties in each District\", xlabel=\"\", ylabel=\"\", hover_cols=\"all\"\n",
    ").opts(\n",
    "    toolbar=\"above\",\n",
    "    active_tools=[\"box_zoom\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp_county_ddf[\"is_onshore_assc_cnty\"] = gp_county_ddf[\"is_onshore_assc_cnty\"].astype(\n",
    "#     int\n",
    "# )\n",
    "# gp_county_ddf[\"is_onshore\"] = gp_county_ddf[\"is_onshore\"].astype(int)\n",
    "\n",
    "counts = (\n",
    "    gp_county_ddf.groupby([\"district_no\", \"is_onshore\", \"is_onshore_assc_cnty\"])\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_labels(var_1, var_2, col1, col2):\n",
    "    # Filter the data for the given 'is_onshore' value\n",
    "    data = counts[(counts[col1] == var_1) & (counts[col2] == var_2)]\n",
    "\n",
    "    # Create a bar plot\n",
    "    bar_plot = data.hvplot.bar(\n",
    "        x=\"district_no\",\n",
    "        y=\"county_no\",\n",
    "        stacked=True,\n",
    "        xlabel=\"\",\n",
    "        yaxis=\"bare\",\n",
    "        title=f\"Count of Counties in each District No. where {col1}={var_1} & {col2}={var_2}\",\n",
    "    )\n",
    "\n",
    "    # Create a list to hold the text elements\n",
    "    texts = []\n",
    "\n",
    "    # Loop over the DataFrame and create a text element for each row\n",
    "    for row in data.itertuples():\n",
    "        # The position of the text is the center of the bar\n",
    "        x = getattr(row, \"district_no\")\n",
    "        y = getattr(row, \"county_no\") / 2\n",
    "        # The text is the height of the bar\n",
    "        text = str(getattr(row, \"county_no\"))\n",
    "        # Create the text element and add it to the list\n",
    "        texts.append(hv.Text(x, y, text).opts(text_color=\"white\"))\n",
    "\n",
    "    # Overlay the text elements on the plot\n",
    "    labelled_plot = bar_plot * hv.Overlay(texts)\n",
    "\n",
    "    return labelled_plot\n",
    "\n",
    "\n",
    "# Create a DynamicMap with the 'plot_with_labels' function\n",
    "dynamic_map = hv.DynamicMap(\n",
    "    lambda var_1, var_2: plot_with_labels(\n",
    "        var_1, var_2, \"is_onshore\", \"is_onshore_assc_cnty\"\n",
    "    ),\n",
    "    kdims=[\n",
    "        hv.Dimension(\"var_1\", label=\"is_onshore\"),\n",
    "        hv.Dimension(\"var_2\", label=\"is_onshore_assc_cnty\"),\n",
    "    ],\n",
    ").redim.range(\n",
    "    var_1=(0, 1),\n",
    "    var_2=(0, 1),\n",
    ")\n",
    "dynamic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gp_county_ddf[gp_county_ddf[\"is_onshore\"] == 0].compute()\n",
    "gp_county_ddf[gp_county_ddf[\"is_onshore_assc_cnty\"] == 1].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that each county is only in 1 district\n",
    "district_counties_dict = (\n",
    "    gp_county_ddf.compute().groupby(\"district_no\")[\"county_no\"].apply(set).to_dict()\n",
    ")\n",
    "# district_counties_dict[1]\n",
    "\n",
    "keys = list(district_counties_dict.keys())\n",
    "found_common = False\n",
    "\n",
    "# Convert the values in district_counties_dict to sets\n",
    "district_counties_dict = {k: set(v) for k, v in district_counties_dict.items()}\n",
    "\n",
    "# Iterate over each key in the list\n",
    "for i in range(len(keys)):\n",
    "    # Get the key and values for the current index\n",
    "    key1 = keys[i]\n",
    "    values1 = district_counties_dict[key1]\n",
    "\n",
    "    # Iterate over all subsequent keys in the list\n",
    "    for j in range(i + 1, len(keys)):\n",
    "        # Get the key and values for the subsequent index\n",
    "        key2 = keys[j]\n",
    "        values2 = district_counties_dict[key2]\n",
    "\n",
    "        # Check if any value from the first pair is in the values of the second pair\n",
    "        common_values = values1.intersection(values2)\n",
    "        if common_values:\n",
    "            print(f\"Key {key1} has common values with key {key2}: {common_values}\")\n",
    "            found_common = True\n",
    "if not found_common:\n",
    "    print(\"No common values found\")\n",
    "\n",
    "# district_counties_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 1\n",
    "\n",
    "General purpose table that contains district information.\n",
    "\n",
    "Includes the info of the office phone number and which town they are located in per that district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_table_overview_from_frame(persisted_overviews, data_tables_dict, \"gp_district\")\n",
    "get_table_card_from_frame(data_tables_dict, \"gp_district\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 2\n",
    "\n",
    "General purpose table of PDQ data range (Jan. 1993-current production report month/year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_tables_dict[\"gp_date_range_cycle\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 3 - County Cycle\n",
    "\n",
    "Contains production report data reported by lease and month (YYYYMM) aggregated by the county in which the wells are located. This is an estimate only based on allowables and potentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_county_cycle\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_county_cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns with any null value in the first row\n",
    "og_county_cycle_ddf = data_tables_dict[\"og_county_cycle\"]\n",
    "og_county_cycle_ddf = og_county_cycle_ddf.drop(\n",
    "    og_county_cycle_ddf.columns[og_county_cycle_ddf.isnull().any()], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change column to lower case\n",
    "og_county_cycle_ddf.columns = [\n",
    "    pascal_to_snake(col) for col in og_county_cycle_ddf.columns\n",
    "]\n",
    "# create column is_gas based on the oil_gas_code column\n",
    "og_county_cycle_ddf[\"is_gas\"] = (\n",
    "    og_county_cycle_ddf[\"oil_gas_code\"].map({\"G\": True, \"O\": False}).astype(\"int8\")\n",
    ")\n",
    "\n",
    "non_null_columns = [\n",
    "    col\n",
    "    for col in og_county_cycle_ddf.columns\n",
    "    if col\n",
    "    not in [\"district_name\", \"county_name\", \"cycle_month\", \"cycle_year\", \"oil_gas_code\"]\n",
    "]\n",
    "# drop the columns we don't want from the ddf\n",
    "og_county_cycle_ddf = og_county_cycle_ddf[non_null_columns]\n",
    "# drop rows with the cycle_year_month < 2013\n",
    "og_county_cycle_ddf = og_county_cycle_ddf[og_county_cycle_ddf.cycle_year_month > 201300]\n",
    "\n",
    "# get shape of the ddf\n",
    "num_rows = og_county_cycle_ddf.shape[0]\n",
    "num_cols = og_county_cycle_ddf.shape[1]\n",
    "\n",
    "# get the size of the ddf\n",
    "size = og_county_cycle_ddf.memory_usage(deep=True).sum()\n",
    "\n",
    "# compute values and put these properties in 1 row of a dataframe\n",
    "num_rows, size = dask.compute(num_rows, size)\n",
    "\n",
    "print(\n",
    "    f\"Shape of og_county_cycle_ddf: ({og_county_cycle_ddf.shape[0].compute()} , {og_county_cycle_ddf.shape[1]})\"\n",
    ")\n",
    "print(f\"Size of og_county_cycle_ddf: {format_in_B(size)}\")\n",
    "og_county_cycle_ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 4 - County Lease Cycle\n",
    "\n",
    "Contains production report data reported by lease and month (YYYYMM) aggregated by lease and county in which the wells are located. This is an estimate only based on allowables and potentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_county_lease_cycle\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_county_lease_cycle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 5 - Lease Cycle\n",
    "\n",
    "Contains production report data reported by lease and month (YYYYMM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_lease_cycle\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_lease_cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dask dataframe\n",
    "og_lease_cycle_ddf = data_tables_dict[\"og_lease_cycle\"]\n",
    "# read in the dask dataframe\n",
    "# og_lease_cycle_ddf = dd.read_csv(file_path_5, sep=\"}\", dtype=csv_dtypes)\n",
    "# convert the column names to lower case\n",
    "og_lease_cycle_ddf = og_lease_cycle_ddf.rename(columns=str.lower)\n",
    "columns_list = og_lease_cycle_ddf.columns.tolist()\n",
    "# drop certain columns based on substrings\n",
    "# create column is_gas based on the oil_gas_code column\n",
    "og_lease_cycle_ddf[\"is_gas\"] = (\n",
    "    og_lease_cycle_ddf[\"oil_gas_code\"].map({\"G\": True, \"O\": False}).astype(\"int8\")\n",
    ")\n",
    "\n",
    "# Define the regex pattern\n",
    "pattern = re.compile(r\"_code$|_name$|cycle_month|cycle_year$|^district_no|lease_no$\")\n",
    "\n",
    "# Filter the columns\n",
    "columns_to_keep = [col for col in columns_list if not pattern.search(col)]\n",
    "og_lease_cycle_ddf = og_lease_cycle_ddf[columns_to_keep]\n",
    "# filter out the row with cycle_year_month < 201300\n",
    "og_lease_cycle_ddf = og_lease_cycle_ddf[og_lease_cycle_ddf.cycle_year_month > 201300]\n",
    "\n",
    "# get shape\n",
    "num_rows = og_lease_cycle_ddf.shape[0]\n",
    "num_cols = og_lease_cycle_ddf.shape[1]\n",
    "# lease_no are unique within districts\n",
    "num_lease_districts = og_lease_cycle_ddf.lease_no_district_no.nunique()\n",
    "# get the memory size of the new filtered ddf\n",
    "mem_size = og_lease_cycle_ddf.memory_usage(deep=True).sum()\n",
    "\n",
    "num_rows, num_lease_districts, mem_size = dask.compute(\n",
    "    num_rows, num_lease_districts, mem_size\n",
    ")\n",
    "print(f\"Shape of og_lease_cycle_ddf: ({num_rows} , {num_cols})\")\n",
    "print(f\"Number of unique lease_no_district_no: {num_lease_districts:,}\")\n",
    "print(f\"Memory size of og_lease_cycle_ddf: {format_in_B(mem_size)}\")\n",
    "og_lease_cycle_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_lease_cycle_ddf[\"district_no\"] = (\n",
    "    og_lease_cycle_ddf[\"lease_no_district_no\"].astype(str).str[-2:]\n",
    ")\n",
    "# total production numbers by district\n",
    "og_lease_cycle_ddf.groupby(\"district_no\")[\n",
    "    [\n",
    "        \"lease_oil_prod_vol\",\n",
    "        \"lease_gas_prod_vol\",\n",
    "        \"lease_cond_prod_vol\",\n",
    "        \"lease_csgd_prod_vol\",\n",
    "    ]\n",
    "].sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 6 - Lease Cycle Disposition\n",
    "\n",
    "Contains production report disposition data reported by lease and month (YYYYMM).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_lease_cycle_disp\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_lease_cycle_disp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dask dataframe\n",
    "og_lease_cycle_disp_ddf = data_tables_dict[\"og_lease_cycle_disp\"]\n",
    "# og_lease_cycle_disp_ddf = dd.read_csv(file_path_6, sep=\"}\", dtype=csv_dtypes)\n",
    "# convert the column names to lower case\n",
    "og_lease_cycle_disp_ddf.columns = [\n",
    "    pascal_to_snake(col) for col in og_lease_cycle_disp_ddf.columns\n",
    "]\n",
    "# columns_list = og_lease_cycle_disp_ddf.columns.tolist()\n",
    "\n",
    "# og_lease_cycle_disp_ddf = og_lease_cycle_disp_ddf.rename(columns=str.lower)\n",
    "# create column is_gas based on the oil_gas_code column\n",
    "og_lease_cycle_disp_ddf[\"is_gas\"] = (\n",
    "    og_lease_cycle_disp_ddf[\"oil_gas_code\"].map({\"G\": True, \"O\": False}).astype(\"int8\")\n",
    ")\n",
    "og_lease_cycle_disp_ddf[\"lease_no_district_no\"] = og_lease_cycle_disp_ddf[\n",
    "    \"lease_no\"\n",
    "].astype(str) + og_lease_cycle_disp_ddf[\"district_no\"].astype(str).str.zfill(2)\n",
    "og_lease_cycle_disp_ddf[\"lease_no_district_no\"] = og_lease_cycle_disp_ddf[\n",
    "    \"lease_no_district_no\"\n",
    "].astype(int)\n",
    "\n",
    "# Define the regex pattern\n",
    "pattern = re.compile(r\"_code$|_name$|cycle_month|cycle_year$|^district_no|lease_no$\")\n",
    "\n",
    "# Filter the columns\n",
    "columns_to_keep = [\n",
    "    col for col in og_lease_cycle_disp_ddf.columns if not pattern.search(col)\n",
    "]\n",
    "og_lease_cycle_disp_ddf = og_lease_cycle_disp_ddf[columns_to_keep]\n",
    "# filter out the row with cycle_year_month < 201300\n",
    "og_lease_cycle_disp_ddf = og_lease_cycle_disp_ddf[\n",
    "    og_lease_cycle_disp_ddf.cycle_year_month > 201300\n",
    "]\n",
    "\n",
    "num_rows = og_lease_cycle_disp_ddf.shape[0]\n",
    "num_cols = og_lease_cycle_disp_ddf.shape[1]\n",
    "# group by district_no and get the nunique of lease_no\n",
    "num_lease_districts = og_lease_cycle_disp_ddf[\"lease_no_district_no\"].nunique()\n",
    "memory_usage = og_lease_cycle_disp_ddf.memory_usage(index=True, deep=True).sum()\n",
    "num_rows, num_lease_districts, memory_usage = dask.compute(\n",
    "    num_rows, num_lease_districts, memory_usage\n",
    ")\n",
    "print(\n",
    "    f\"Shape of og_lease_cycle_disp_ddf: ({num_rows} , {num_cols})\\nNumber of unique lease_no_district_no: {num_lease_districts}\"\n",
    ")\n",
    "print(f\"Total number of leases: {num_lease_districts}\")\n",
    "print(f\"Total memory usage: {format_in_B(memory_usage)}\")\n",
    "# og_lease_cycle_disp_ddf.info(memory_usage=\"deep\")\n",
    "og_lease_cycle_disp_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# og_lease_cycle_disp_ddf.memory_usage(index=True, deep=True).compute()\n",
    "og_lease_cycle_disp_ddf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 7 - District Cycle\n",
    "\n",
    "Contains production report data reported by lease and month (YYYYMM) aggregated by the completion district for the lease ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_district_cycle\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_district_cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dask dataframe\n",
    "og_district_cycle_ddf = data_tables_dict[\"og_district_cycle\"]\n",
    "# og_district_cycle_ddf = dd.read_csv(file_path_7, sep=\"}\", dtype=csv_dtypes)\n",
    "# convert the column names to lower case\n",
    "og_district_cycle_ddf = og_district_cycle_ddf.rename(columns=str.lower)\n",
    "# get list of columns\n",
    "columns_list = og_district_cycle_ddf.columns.tolist()\n",
    "\n",
    "# drop the columns we don't want from columns list\n",
    "columns_list = [\n",
    "    col\n",
    "    for col in columns_list\n",
    "    if col not in [\"district_name\", \"cycle_month\", \"cycle_year\"]\n",
    "]\n",
    "# drop the column from the dataframe\n",
    "og_district_cycle_ddf = og_district_cycle_ddf[columns_list]\n",
    "\n",
    "# drop  row with cycle_year < 2013\n",
    "og_district_cycle_ddf = og_district_cycle_ddf[\n",
    "    og_district_cycle_ddf.cycle_year_month > 201300\n",
    "]\n",
    "num_rows = og_district_cycle_ddf.shape[0]\n",
    "memory_usage = og_district_cycle_ddf.memory_usage(index=True, deep=True).sum()\n",
    "# compute the number of rows and memory usage\n",
    "num_rows, memory_usage = dask.compute(num_rows, memory_usage)\n",
    "# show first few rows and shape\n",
    "print(f\"Shape of og_district_cycle_ddf: ({num_rows} , {len(columns_list)}\")\n",
    "print(f\"Total memory usage: {format_in_B(memory_usage)}\")\n",
    "\n",
    "og_district_cycle_ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 8 - Field Cycle\n",
    "\n",
    "Contains production report data reported by lease and month (YYYYMM) aggregated by the field in which the well(s) for the lease are completed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_field_cycle\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_field_cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dask dataframe\n",
    "og_field_cycle_ddf = data_tables_dict[\"og_field_cycle\"]\n",
    "\n",
    "# og_field_cycle_ddf = dd.read_csv(file_path_8, sep=\"}\", dtype=csv_dtypes)\n",
    "\n",
    "# convert the column names to lower case\n",
    "\n",
    "og_field_cycle_ddf = og_field_cycle_ddf.rename(columns=str.lower)\n",
    "\n",
    "# drop the columns we don't want from columns list\n",
    "\n",
    "columns_list = og_field_cycle_ddf.columns.tolist()\n",
    "\n",
    "columns_to_keep = [\n",
    "    col\n",
    "    for col in columns_list\n",
    "    if col not in [\"district_name\", \"county_name\", \"cycle_month\", \"cycle_year\"]\n",
    "]\n",
    "\n",
    "# drop the column from the dataframe\n",
    "\n",
    "og_field_cycle_ddf = og_field_cycle_ddf[columns_to_keep]\n",
    "\n",
    "# drop  row with cycle_year_month < 201300\n",
    "\n",
    "og_field_cycle_ddf = og_field_cycle_ddf[og_field_cycle_ddf.cycle_year_month > 201300]\n",
    "\n",
    "# drop the rows with null values for the field_name column\n",
    "\n",
    "og_field_cycle_ddf = og_field_cycle_ddf.dropna(subset=[\"field_name\"])\n",
    "\n",
    "\n",
    "# get new number of rows and memory usage\n",
    "\n",
    "num_rows = og_field_cycle_ddf.shape[0]\n",
    "\n",
    "memory_usage = og_field_cycle_ddf.memory_usage(index=True, deep=True).sum()\n",
    "\n",
    "# compute the number of rows and memory usage\n",
    "\n",
    "num_rows, memory_usage = dask.compute(num_rows, memory_usage)\n",
    "\n",
    "# show first few rows and shape\n",
    "\n",
    "print(\n",
    "    f\"Shape of og_field_cycle_ddf: ({num_rows} , {len(columns_list)})\\nTotal memory usage: {format_in_B(memory_usage)}\"\n",
    ")\n",
    "\n",
    "\n",
    "og_field_cycle_ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 9 - Operator Cycle\n",
    "\n",
    "Contains production report data reported by lease and month (YYYYMM) aggregated by the operator of the lease.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_operator_cycle\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_operator_cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dask dataframe\n",
    "# og_operator_cycle_ddf = dd.read_csv(file_path_9, sep=\"}\", dtype=csv_dtypes)\n",
    "og_operator_cycle_ddf = data_tables_dict[\"og_operator_cycle\"]\n",
    "# convert the column names to lower case\n",
    "og_operator_cycle_ddf = og_operator_cycle_ddf.rename(columns=str.lower)\n",
    "# drop the 'cycle_month' and 'cycle_year' columns\n",
    "columns_to_keep = [\n",
    "    col\n",
    "    for col in og_operator_cycle_ddf.columns\n",
    "    if col not in [\"cycle_month\", \"cycle_year\"]\n",
    "]\n",
    "og_operator_cycle_ddf = og_operator_cycle_ddf[columns_to_keep]\n",
    "# filter out the row with cycle_year_month < 201300\n",
    "og_operator_cycle_ddf = og_operator_cycle_ddf[\n",
    "    og_operator_cycle_ddf.cycle_year_month > 201300\n",
    "]\n",
    "# drop the rows with null values for the operator_name column\n",
    "og_operator_cycle_ddf = og_operator_cycle_ddf.dropna(subset=[\"operator_name\"])\n",
    "# show first few rows and get shape\n",
    "num_rows = og_operator_cycle_ddf.shape[0]\n",
    "num_cols = og_operator_cycle_ddf.shape[1]\n",
    "memory_usage = og_operator_cycle_ddf.memory_usage(index=True, deep=True).sum()\n",
    "num_rows, memory_usage = dask.compute(num_rows, memory_usage)\n",
    "print(\n",
    "    f\"Shape of og_operator_cycle_ddf: ({num_rows} , {num_cols})\\nTotal memory usage: {format_in_B(memory_usage)}\"\n",
    ")\n",
    "og_operator_cycle_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for the total production to filter out the non producing operators\n",
    "og_operator_cycle_ddf[\"total_oper_prod_vol\"] = (\n",
    "    og_operator_cycle_ddf[\"oper_oil_prod_vol\"]\n",
    "    + og_operator_cycle_ddf[\"oper_gas_prod_vol\"]\n",
    "    + og_operator_cycle_ddf[\"oper_cond_prod_vol\"]\n",
    "    + og_operator_cycle_ddf[\"oper_csgd_prod_vol\"]\n",
    ")\n",
    "og_operator_cycle_ddf[\"is_producing\"] = og_operator_cycle_ddf[\"total_oper_prod_vol\"] > 0\n",
    "producing_operator_nos = (\n",
    "    og_operator_cycle_ddf[og_operator_cycle_ddf[\"is_producing\"]][\"operator_no\"]\n",
    "    .unique()\n",
    "    .values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 10 - Field DW\n",
    "\n",
    "\n",
    "Table of field identifying data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path_10 = overview_dfs.loc[10, \"file_path\"]\n",
    "# display_table_overview(file_path_10, column_types=csv_dtypes)\n",
    "# get_table_description(file_path_10, column_types=csv_dtypes).compute().T\n",
    "# get_table_card(file_path_10, column_types=csv_dtypes)\n",
    "display_table_overview_from_frame(persisted_overviews, data_tables_dict, \"og_field_dw\")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_field_dw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dask dataframe\n",
    "# og_field_dw_df = dd.read_csv(file_path_10, sep=\"}\", dtype=csv_dtypes)\n",
    "og_field_dw_ddf = data_tables_dict[\"og_field_dw\"]\n",
    "\n",
    "# can load the whole dataframe into memory as it is small\n",
    "og_field_dw_df = og_field_dw_ddf.compute()\n",
    "\n",
    "# convert the column names to lower case\n",
    "og_field_dw_df = og_field_dw_df.rename(columns=str.lower)\n",
    "\n",
    "columns_list = og_field_dw_df.columns.tolist()\n",
    "\n",
    "# drop the columns with all nans and get the columns list\n",
    "substrings = {\"modify\", \"remarks\", \"rev_rule\", \"create\", \"district_name\"}\n",
    "columns_list = [\n",
    "    col for col in columns_list if not any(substring in col for substring in substrings)\n",
    "]\n",
    "\n",
    "# convert field_no to an int then zfill(8)\n",
    "og_field_dw_df[\"field_no\"] = (\n",
    "    og_field_dw_df[\"field_no\"].astype(int).astype(str).str.zfill(8)\n",
    ")\n",
    "\n",
    "\n",
    "# convert the o_discovery_dt and g_discovery_dt to datetime\n",
    "def parse_dates(date_string):\n",
    "    if pd.isnull(date_string):\n",
    "        return pd.NaT\n",
    "    dt = datetime.strptime(date_string, \"%d-%b-%y\")\n",
    "    if dt.year > 2023:  # replace with the current year\n",
    "        dt = dt.replace(year=dt.year - 100)\n",
    "    return dt\n",
    "\n",
    "\n",
    "og_field_dw_df[\"o_discovery_dt\"] = og_field_dw_df[\"o_discovery_dt\"].apply(parse_dates)\n",
    "og_field_dw_df[\"g_discovery_dt\"] = og_field_dw_df[\"g_discovery_dt\"].apply(parse_dates)\n",
    "\n",
    "\n",
    "# drop the column from the dataframe\n",
    "og_field_dw_df = og_field_dw_df[columns_list]\n",
    "# get the number of rows and memory usage\n",
    "num_rows = og_field_dw_df.shape[0]\n",
    "memory_usage = og_field_dw_df.memory_usage(index=True, deep=True).sum()\n",
    "\n",
    "# show first few rows and shape\n",
    "print(f\"Shape of og_field_dw_df: ({og_field_dw_df.shape}\")\n",
    "print(f\"Total memory usage: {format_in_B(memory_usage)}\")\n",
    "og_field_dw_df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 11 - Operator DW\n",
    "\n",
    "This table contains identifying operator information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path_11 = overview_dfs.loc[11, \"file_path\"]\n",
    "# display_table_overview(file_path_11, column_types=csv_dtypes)\n",
    "# # get_table_description(file_path_11, column_types=csv_dtypes).compute().T\n",
    "# get_table_card(file_path_11, column_types=csv_dtypes)\n",
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_operator_dw\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_operator_dw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dask dataframe\n",
    "# og_operator_dw_ddf = dd.read_csv(file_path_11, sep=\"}\", dtype=csv_dtypes)\n",
    "og_operator_dw_ddf = data_tables_dict[\"og_operator_dw\"]\n",
    "\n",
    "# load in as pandas dataframe as it is small\n",
    "og_operator_dw_df = og_operator_dw_ddf.compute()\n",
    "\n",
    "\n",
    "# convert the column names to lower case\n",
    "og_operator_dw_df.columns = [pascal_to_snake(col) for col in og_operator_dw_df.columns]\n",
    "\n",
    "# drop the columns with all nans and other useless columns\n",
    "pattern = re.compile(r\"modify|efile|record|create\")\n",
    "columns_to_keep = [col for col in og_operator_dw_df.columns if not pattern.search(col)]\n",
    "\n",
    "# convert p5Llast_filed_dt to datetime\n",
    "og_operator_dw_df[\"p5_last_filed_dt\"] = pd.to_datetime(\n",
    "    og_operator_dw_df[\"p5_last_filed_dt\"].astype(str), errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# drop the column from the dataframe\n",
    "og_operator_dw_df = og_operator_dw_df[columns_to_keep]\n",
    "\n",
    "# strip the excess space from the Letter in the p5_status_code column\n",
    "og_operator_dw_df[\"p5_status_code\"] = og_operator_dw_df[\"p5_status_code\"].str.strip()\n",
    "\n",
    "# get the number of rows and memory usage\n",
    "num_rows = og_operator_dw_df.shape[0]\n",
    "memory_usage = og_operator_dw_df.memory_usage(index=True, deep=True).sum()\n",
    "\n",
    "# show first few rows and shape\n",
    "print(f\"Shape of og_operator_dw_df: ({num_rows} , {len(columns_to_keep)})\")\n",
    "print(f\"Total memory usage: {format_in_B(memory_usage)}\")\n",
    "og_operator_dw_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a table with the operator_no and operator_name\n",
    "rrc_pattern = \"RAILROAD COMMISSION\"\n",
    "operator_no_name = og_operator_dw_df[\n",
    "    ~og_operator_dw_df[\"operator_name\"].str.contains(rrc_pattern, regex=True)\n",
    "][[\"operator_no\", \"operator_name\"]]\n",
    "\n",
    "\n",
    "operator_no_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "producing_operator_nos_list = producing_operator_nos.compute().tolist()\n",
    "og_operator_dw_df[og_operator_dw_df[\"operator_no\"].isin(producing_operator_nos_list)]\n",
    "\n",
    "# get the operator_name of the producing_operator_nos\n",
    "# filtered_df = og_operator_dw_ddf[\n",
    "#     og_operator_dw_ddf[\"operator_no\"].isin(producing_operator_nos)\n",
    "# ].persist()\n",
    "\n",
    "# filtered_df.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 12 - Regulatory Lease DW\n",
    "\n",
    "This table contains identifying lease information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_regulatory_lease_dw\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_regulatory_lease_dw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dask dataframe\n",
    "# og_regulatory_lease_dw_ddf = dd.read_csv(file_path_12, sep=\"}\", dtype=csv_dtypes)\n",
    "og_regulatory_lease_dw_ddf = data_tables_dict[\"og_regulatory_lease_dw\"]\n",
    "# convert the column names to lower case\n",
    "og_regulatory_lease_dw_ddf.columns = [\n",
    "    pascal_to_snake(col) for col in og_regulatory_lease_dw_ddf.columns\n",
    "]\n",
    "# create column is_gas based on the oil_gas_code column\n",
    "og_regulatory_lease_dw_ddf[\"is_gas\"] = og_regulatory_lease_dw_ddf[\"oil_gas_code\"].map(\n",
    "    {\"G\": True, \"O\": False}\n",
    ")\n",
    "# drop the columns we do not need to keep\n",
    "pattern = re.compile(r\"field_name|operator_name|district_name|oil_gas_code|field_name\")\n",
    "columns_to_keep = [\n",
    "    col for col in og_regulatory_lease_dw_ddf.columns if not pattern.search(col)\n",
    "]\n",
    "# drop the column from the dataframe\n",
    "og_regulatory_lease_dw_ddf = og_regulatory_lease_dw_ddf[columns_to_keep]\n",
    "# get the number of rows and memory usage\n",
    "num_rows = og_regulatory_lease_dw_ddf.shape[0]\n",
    "memory_usage = og_regulatory_lease_dw_ddf.memory_usage(index=True, deep=True).sum()\n",
    "num_rows, memory_usage = dask.compute(num_rows, memory_usage)\n",
    "# show first few rows and shape\n",
    "print(\n",
    "    f\"Shape of og_regulatory_lease_dw_ddf: ({num_rows} , {len(columns_to_keep)})\\nTotal memory usage: {format_in_B(memory_usage)}\"\n",
    ")\n",
    "og_regulatory_lease_dw_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_regulatory_lease_dw_df = og_regulatory_lease_dw_ddf.compute()\n",
    "\n",
    "\n",
    "counts_df = (\n",
    "    og_regulatory_lease_dw_df.groupby([\"district_no\", \"is_gas\"])[\"lease_no\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .set_index(\"district_no\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df[counts_df[\"is_gas\"] == 1][\"lease_no\"].hvplot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.state.kill_all_servers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.pandas\n",
    "\n",
    "\n",
    "def plot_data(gas):\n",
    "    filtered_data = og_regulatory_lease_dw_df[\n",
    "        og_regulatory_lease_dw_df[\"is_gas\"] == gas\n",
    "    ]\n",
    "    counts_df = filtered_data.groupby(\"district_no\")[\"lease_no\"].count().reset_index()\n",
    "    counts_df.columns = [\"district_no\", \"lease_count\"]\n",
    "    return counts_df.hvplot.bar(\n",
    "        x=\"district_no\",\n",
    "        y=\"lease_count\",\n",
    "        title=f\"Count of Leases in each District whre is_gas={gas}\",\n",
    "    ).opts(\n",
    "        toolbar=\"above\",\n",
    "        active_tools=[\"box_zoom\"],\n",
    "    )\n",
    "\n",
    "\n",
    "is_gas_slider = pn.widgets.IntSlider(name=\"is_gas\", start=0, end=1, step=1, value=0)\n",
    "ibars = pn.panel(pn.bind(plot_data, gas=is_gas_slider), width=880)\n",
    "\n",
    "pn.Card(is_gas_slider, ibars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.dask\n",
    "import hvplot.pandas\n",
    "\n",
    "lease_count = (\n",
    "    og_regulatory_lease_dw_ddf.compute()\n",
    "    .groupby([\"district_no\", \"is_gas\"])[\"lease_no\"]\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "# create a dynamic map to plot the number of leases in each district bar plot and is_gas widget controller\n",
    "def lease_plot_with_labels(var1, col1):\n",
    "    # Filter the data for the given 'is_gas' value\n",
    "    data = lease_count[(lease_count[col1] == var1)]\n",
    "\n",
    "    # Create a bar plot\n",
    "    bar_plot = data.hvplot.bar(\n",
    "        x=\"district_no\",\n",
    "        y=\"lease_no\",\n",
    "        stacked=True,\n",
    "        xlabel=\"\",\n",
    "        yaxis=\"bare\",\n",
    "        title=f\"Count of Leases in each District No. where {col1}={var1}\",\n",
    "        hover_cols=\"all\",\n",
    "    )\n",
    "\n",
    "    # Create a list to hold the text elements\n",
    "    texts = []\n",
    "\n",
    "    # Loop over the DataFrame and create a text element for each row\n",
    "    for row in data.itertuples():\n",
    "        # The position of the text is center of bar\n",
    "        x = getattr(row, \"district_no\")\n",
    "        y = getattr(row, \"lease_no\") * 1.01\n",
    "        # The text is the height of the bar\n",
    "        text = str(getattr(row, \"lease_no\"))\n",
    "        # Create the text element and add it to the list\n",
    "        texts.append(hv.Text(x, y, text, valign=\"bottom\").opts(text_color=\"black\"))\n",
    "\n",
    "    # Overlay the text elements on the plot\n",
    "    labelled_plot = bar_plot * hv.Overlay(texts)\n",
    "\n",
    "    return labelled_plot\n",
    "\n",
    "\n",
    "lease_dmap = hv.DynamicMap(\n",
    "    lambda var1: lease_plot_with_labels(var1, \"is_gas\"),\n",
    "    kdims=[\n",
    "        hv.Dimension(\"var1\", label=\"is_gas\"),\n",
    "    ],\n",
    ").redim.range(var1=(0, 1))\n",
    "pn.panel(lease_dmap).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 13 - Well Completion\n",
    "\n",
    "This table contains identifying well completion information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~*~ og_well_completion ~*~\n",
      "796,550 rows, 16 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OIL_GAS_CODE</th>\n",
       "      <th>DISTRICT_NO</th>\n",
       "      <th>LEASE_NO</th>\n",
       "      <th>WELL_NO</th>\n",
       "      <th>API_COUNTY_CODE</th>\n",
       "      <th>API_UNIQUE_NO</th>\n",
       "      <th>ONSHORE_ASSC_CNTY</th>\n",
       "      <th>DISTRICT_NAME</th>\n",
       "      <th>COUNTY_NAME</th>\n",
       "      <th>OIL_WELL_UNIT_NO</th>\n",
       "      <th>WELL_ROOT_NO</th>\n",
       "      <th>WELLBORE_SHUTIN_DT</th>\n",
       "      <th>WELL_SHUTIN_DT</th>\n",
       "      <th>WELL_14B2_STATUS_CODE</th>\n",
       "      <th>WELL_SUBJECT_14B2_FLAG</th>\n",
       "      <th>WELLBORE_LOCATION_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>67641</td>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>31091</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>348113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>67642</td>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>31080</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>348114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68026</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>31282</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>352816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68027</td>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>31280</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>352817</td>\n",
       "      <td>201207</td>\n",
       "      <td>201207</td>\n",
       "      <td>Y</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68028</td>\n",
       "      <td>3</td>\n",
       "      <td>435</td>\n",
       "      <td>31281</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>352818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68088</td>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>31255</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>351880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68123</td>\n",
       "      <td>0012S</td>\n",
       "      <td>435</td>\n",
       "      <td>31048</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>352819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68133</td>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>31275</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>351882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68225</td>\n",
       "      <td>2 T</td>\n",
       "      <td>435</td>\n",
       "      <td>31170</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>350031</td>\n",
       "      <td>0</td>\n",
       "      <td>200703</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68247</td>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>31245</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>352469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68263</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>80012</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>347862</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68290</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>31300</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>351883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68469</td>\n",
       "      <td>2 C</td>\n",
       "      <td>435</td>\n",
       "      <td>31170</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>350001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68525</td>\n",
       "      <td>2 C</td>\n",
       "      <td>435</td>\n",
       "      <td>31256</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>353076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>G</td>\n",
       "      <td>9</td>\n",
       "      <td>68526</td>\n",
       "      <td>2 T</td>\n",
       "      <td>435</td>\n",
       "      <td>31256</td>\n",
       "      <td>435</td>\n",
       "      <td>7C</td>\n",
       "      <td>SUTTON</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>351884</td>\n",
       "      <td>0</td>\n",
       "      <td>200010</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OIL_GAS_CODE  DISTRICT_NO  LEASE_NO WELL_NO  API_COUNTY_CODE  \\\n",
       "0             G            9     67641       2              435   \n",
       "1             G            9     67642       2              435   \n",
       "2             G            9     68026       1              435   \n",
       "3             G            9     68027       2              435   \n",
       "4             G            9     68028       3              435   \n",
       "5             G            9     68088       2              435   \n",
       "6             G            9     68123   0012S              435   \n",
       "7             G            9     68133       2              435   \n",
       "8             G            9     68225     2 T              435   \n",
       "9             G            9     68247       2              435   \n",
       "10            G            9     68263       1              435   \n",
       "11            G            9     68290       1              435   \n",
       "12            G            9     68469     2 C              435   \n",
       "13            G            9     68525     2 C              435   \n",
       "14            G            9     68526     2 T              435   \n",
       "\n",
       "    API_UNIQUE_NO  ONSHORE_ASSC_CNTY DISTRICT_NAME COUNTY_NAME  \\\n",
       "0           31091                435            7C      SUTTON   \n",
       "1           31080                435            7C      SUTTON   \n",
       "2           31282                435            7C      SUTTON   \n",
       "3           31280                435            7C      SUTTON   \n",
       "4           31281                435            7C      SUTTON   \n",
       "5           31255                435            7C      SUTTON   \n",
       "6           31048                435            7C      SUTTON   \n",
       "7           31275                435            7C      SUTTON   \n",
       "8           31170                435            7C      SUTTON   \n",
       "9           31245                435            7C      SUTTON   \n",
       "10          80012                435            7C      SUTTON   \n",
       "11          31300                435            7C      SUTTON   \n",
       "12          31170                435            7C      SUTTON   \n",
       "13          31256                435            7C      SUTTON   \n",
       "14          31256                435            7C      SUTTON   \n",
       "\n",
       "   OIL_WELL_UNIT_NO  WELL_ROOT_NO  WELLBORE_SHUTIN_DT  WELL_SHUTIN_DT  \\\n",
       "0              <NA>        348113                   0               0   \n",
       "1              <NA>        348114                   0               0   \n",
       "2              <NA>        352816                   0               0   \n",
       "3              <NA>        352817              201207          201207   \n",
       "4              <NA>        352818                   0               0   \n",
       "5              <NA>        351880                   0               0   \n",
       "6              <NA>        352819                   0               0   \n",
       "7              <NA>        351882                   0               0   \n",
       "8              <NA>        350031                   0          200703   \n",
       "9              <NA>        352469                   0               0   \n",
       "10             <NA>        347862                   0               0   \n",
       "11             <NA>        351883                   0               0   \n",
       "12             <NA>        350001                   0               0   \n",
       "13             <NA>        353076                   0               0   \n",
       "14             <NA>        351884                   0          200010   \n",
       "\n",
       "   WELL_14B2_STATUS_CODE WELL_SUBJECT_14B2_FLAG WELLBORE_LOCATION_CODE  \n",
       "0                      N                      N                      L  \n",
       "1                      N                      N                      L  \n",
       "2                      N                      N                      L  \n",
       "3                      Y                      A                      L  \n",
       "4                      N                      N                      L  \n",
       "5                      N                      N                      L  \n",
       "6                      N                      N                      L  \n",
       "7                      N                      N                      L  \n",
       "8                      N                      N                      L  \n",
       "9                      N                      N                      L  \n",
       "10                     N                      N                      L  \n",
       "11                     N                      N                      L  \n",
       "12                     N                      N                      L  \n",
       "13                     N                      N                      L  \n",
       "14                     N                      N                      L  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcad351877344ff8aafafebd5f8e60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'5b017654-cc51-4832-b2d1-3b969967e2c7': {'version"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_well_completion\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_well_completion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of og_well_completion_ddf: (796550 , 14\n",
      "Total memory usage: 106.11 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_no</th>\n",
       "      <th>lease_no</th>\n",
       "      <th>well_no</th>\n",
       "      <th>api_county_code</th>\n",
       "      <th>api_unique_no</th>\n",
       "      <th>onshore_assc_cnty</th>\n",
       "      <th>oil_well_unit_no</th>\n",
       "      <th>well_root_no</th>\n",
       "      <th>wellbore_shutin_dt</th>\n",
       "      <th>well_shutin_dt</th>\n",
       "      <th>well_14b2_status_code</th>\n",
       "      <th>well_subject_14b2_flag</th>\n",
       "      <th>wellbore_location_code</th>\n",
       "      <th>is_gas</th>\n",
       "      <th>lease_no_district_no</th>\n",
       "      <th>tx_api</th>\n",
       "      <th>tx_api_count</th>\n",
       "      <th>lease_no_district_no_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>67641</td>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>31091</td>\n",
       "      <td>435</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>348113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>True</td>\n",
       "      <td>6764109</td>\n",
       "      <td>43531091</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>67642</td>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>31080</td>\n",
       "      <td>435</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>348114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>True</td>\n",
       "      <td>6764209</td>\n",
       "      <td>43531080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>68026</td>\n",
       "      <td>1</td>\n",
       "      <td>435</td>\n",
       "      <td>31282</td>\n",
       "      <td>435</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>352816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>True</td>\n",
       "      <td>6802609</td>\n",
       "      <td>43531282</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>68027</td>\n",
       "      <td>2</td>\n",
       "      <td>435</td>\n",
       "      <td>31280</td>\n",
       "      <td>435</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>352817</td>\n",
       "      <td>201207</td>\n",
       "      <td>201207</td>\n",
       "      <td>Y</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>True</td>\n",
       "      <td>6802709</td>\n",
       "      <td>43531280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>68028</td>\n",
       "      <td>3</td>\n",
       "      <td>435</td>\n",
       "      <td>31281</td>\n",
       "      <td>435</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>352818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>L</td>\n",
       "      <td>True</td>\n",
       "      <td>6802809</td>\n",
       "      <td>43531281</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   district_no  lease_no well_no  api_county_code  api_unique_no  \\\n",
       "0            9     67641       2              435          31091   \n",
       "1            9     67642       2              435          31080   \n",
       "2            9     68026       1              435          31282   \n",
       "3            9     68027       2              435          31280   \n",
       "4            9     68028       3              435          31281   \n",
       "\n",
       "   onshore_assc_cnty oil_well_unit_no  well_root_no  wellbore_shutin_dt  \\\n",
       "0                435             <NA>        348113                   0   \n",
       "1                435             <NA>        348114                   0   \n",
       "2                435             <NA>        352816                   0   \n",
       "3                435             <NA>        352817              201207   \n",
       "4                435             <NA>        352818                   0   \n",
       "\n",
       "   well_shutin_dt well_14b2_status_code well_subject_14b2_flag  \\\n",
       "0               0                     N                      N   \n",
       "1               0                     N                      N   \n",
       "2               0                     N                      N   \n",
       "3          201207                     Y                      A   \n",
       "4               0                     N                      N   \n",
       "\n",
       "  wellbore_location_code  is_gas lease_no_district_no    tx_api  tx_api_count  \\\n",
       "0                      L    True              6764109  43531091             1   \n",
       "1                      L    True              6764209  43531080             1   \n",
       "2                      L    True              6802609  43531282             1   \n",
       "3                      L    True              6802709  43531280             1   \n",
       "4                      L    True              6802809  43531281             1   \n",
       "\n",
       "   lease_no_district_no_count  \n",
       "0                           1  \n",
       "1                           1  \n",
       "2                           1  \n",
       "3                           1  \n",
       "4                           1  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the dask dataframe\n",
    "# og_well_completion_ddf = dd.read_csv(file_path_13, sep=\"}\", dtype=csv_dtypes)\n",
    "og_well_completion_ddf = data_tables_dict[\"og_well_completion\"]\n",
    "# convert the column names to lower case\n",
    "og_well_completion_ddf.columns = [\n",
    "    pascal_to_snake(col) for col in og_well_completion_ddf.columns\n",
    "]\n",
    "og_well_completion_ddf[\"is_gas\"] = og_well_completion_ddf[\"oil_gas_code\"].map(\n",
    "    {\"G\": True, \"O\": False}\n",
    ")\n",
    "\n",
    "# drop the columns we do not need to keep\n",
    "pattern = re.compile(r\"_name|oil_gas_code\")\n",
    "columns_to_keep = [\n",
    "    col for col in og_well_completion_ddf.columns if not pattern.search(col)\n",
    "]\n",
    "# drop the column from the dataframe\n",
    "og_well_completion_ddf = og_well_completion_ddf[columns_to_keep]\n",
    "\n",
    "# create column lease_no_district_no which combines the lease_no and district_no\n",
    "og_well_completion_ddf[\"lease_no_district_no\"] = og_well_completion_ddf[\n",
    "    \"lease_no\"\n",
    "].astype(str) + og_well_completion_ddf[\"district_no\"].astype(str).str.zfill(2)\n",
    "\n",
    "# create column tx_api which combines the api_county_code and api_unique_no\n",
    "og_well_completion_ddf[\"tx_api\"] = og_well_completion_ddf[\"api_county_code\"].astype(\n",
    "    str\n",
    ").str.zfill(3) + og_well_completion_ddf[\"api_unique_no\"].astype(str).str.zfill(5)\n",
    "# create a column for the tx_api count\n",
    "og_well_completion_ddf[\"tx_api_count\"] = og_well_completion_ddf.groupby(\"tx_api\")[\n",
    "    \"tx_api\"\n",
    "].transform(\"count\")\n",
    "og_well_completion_ddf[\"lease_no_district_no_count\"] = og_well_completion_ddf.groupby(\n",
    "    \"lease_no_district_no\"\n",
    ")[\"lease_no_district_no\"].transform(\"count\")\n",
    "\n",
    "\n",
    "# get the number of rows and memory usage\n",
    "num_rows = og_well_completion_ddf.shape[0]\n",
    "memory_usage = og_well_completion_ddf.memory_usage(index=True, deep=True).sum()\n",
    "num_rows, memory_usage = dask.compute(num_rows, memory_usage)\n",
    "# show first few rows and shape\n",
    "print(f\"Shape of og_well_completion_ddf: ({num_rows} , {len(columns_to_keep)}\")\n",
    "print(f\"Total memory usage: {format_in_B(memory_usage)}\")\n",
    "og_well_completion_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_well_completion_ddf[\n",
    "    og_well_completion_ddf.lease_no_district_no == \"313711\"\n",
    "].compute().sort_values([\"tx_api_count\", \"tx_api\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 14 - Summary Master Large\n",
    "\n",
    "Summary table. (Used for query purposes at the operator level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_summary_master_large\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_summary_master_large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 15 - Summary Onshore Lease\n",
    "\n",
    "Summary table. (Used for query purposes on the leases in onshore counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_table_overview_from_frame(\n",
    "    persisted_overviews, data_tables_dict, \"og_summary_onshore_lease\"\n",
    ")\n",
    "get_table_card_from_frame(data_tables_dict, \"og_summary_onshore_lease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active leases\n",
    "og_summary_onshore_lease_ddf = data_tables_dict[\"og_summary_onshore_lease\"]\n",
    "# convert the column names to lower case\n",
    "og_summary_onshore_lease_ddf.columns = [\n",
    "    pascal_to_snake(col) for col in og_summary_onshore_lease_ddf.columns\n",
    "]\n",
    "# create a lease_no_district_no column\n",
    "og_summary_onshore_lease_ddf[\"lease_no_district_no\"] = og_summary_onshore_lease_ddf[\n",
    "    \"lease_no\"\n",
    "].astype(str) + og_summary_onshore_lease_ddf[\"district_no\"].astype(str).str.zfill(2)\n",
    "# get the number of rows and memory usage\n",
    "num_rows = og_summary_onshore_lease_ddf.shape[0]\n",
    "memory_usage = og_summary_onshore_lease_ddf.memory_usage(index=True, deep=True).sum()\n",
    "num_rows, memory_usage = dask.compute(num_rows, memory_usage)\n",
    "# show first few rows and shape\n",
    "print(\n",
    "    f\"Shape of og_summary_onshore_lease_ddf: ({num_rows} , {len(og_summary_onshore_lease_ddf.columns)}\"\n",
    ")\n",
    "print(f\"Total memory usage: {format_in_B(memory_usage)}\")\n",
    "og_summary_onshore_lease_ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active wells have a cycle_year_month_max  of 202311\n",
    "og_summary_onshore_lease_ddf[\n",
    "    og_summary_onshore_lease_ddf[\"cycle_year_month_max\"] == 202311\n",
    "].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top Ranked Operators in Texas per Monthly Production numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the aggregated Operator cycle table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by cycle_year_month and get the top 5 operators for each of the prod_vol columns for 2023\n",
    "# filter for 20XX\n",
    "og_operator_cycle_ddf_20XX = og_operator_cycle_ddf[\n",
    "    og_operator_cycle_ddf.cycle_year_month > 201300\n",
    "]\n",
    "# get each of the prod_vol columns\n",
    "prod_columns = [\n",
    "    \"oper_oil_prod_vol\",\n",
    "    \"oper_gas_prod_vol\",\n",
    "    \"oper_cond_prod_vol\",\n",
    "    \"oper_csgd_prod_vol\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(og_operator_cycle_ddf_2023)\n",
    "# og_operator_cycle_ddf_2023.head()\n",
    "duplicate_operators = (\n",
    "    og_operator_cycle_ddf_20XX.groupby([\"cycle_year_month\", \"operator_name\"])\n",
    "    .size()\n",
    "    .compute()\n",
    ")\n",
    "\n",
    "# Check if any operator_name appears more than once in the same cycle_year_month\n",
    "any_duplicates = any(duplicate_operators > 1)\n",
    "\n",
    "print(\n",
    "    f\"Any operator_name appears more than once in the same cycle_year_month: {any_duplicates}\"\n",
    ")\n",
    "\n",
    "og_operator_cycle_ddf_20XX[\"total_prod_vol\"] = og_operator_cycle_ddf_20XX[\n",
    "    prod_columns\n",
    "].sum(axis=1)\n",
    "og_operator_cycle_ddf_20XX.loc[\n",
    "    (og_operator_cycle_ddf_20XX[\"cycle_year_month\"] == 202308)\n",
    "    & (og_operator_cycle_ddf_20XX[\"total_prod_vol\"] != 0)\n",
    "].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame\n",
    "og_operator_cycle_ddf_20XX = og_operator_cycle_ddf_20XX[\n",
    "    og_operator_cycle_ddf_20XX[\"cycle_year_month\"] <= 202308\n",
    "]\n",
    "\n",
    "# Group the DataFrame\n",
    "grouped_og_operator = og_operator_cycle_ddf_20XX.groupby(\"cycle_year_month\")\n",
    "\n",
    "\n",
    "# Define a function to get the top 3 rows for each product column\n",
    "def get_topn(df):\n",
    "    result = {}\n",
    "    for col in prod_columns:\n",
    "        topn = df.nlargest(1, col)[[\"operator_name\"] + prod_columns].copy()\n",
    "        topn[\"prod_column\"] = col\n",
    "        result[col] = topn\n",
    "    return pd.concat(result.values(), keys=result.keys())\n",
    "\n",
    "\n",
    "# Apply the function to each group\n",
    "topn_og_operator = grouped_og_operator.apply(\n",
    "    get_topn,\n",
    "    meta=pd.DataFrame(\n",
    "        {\n",
    "            \"operator_name\": pd.Series(dtype=\"object\"),\n",
    "            \"oper_oil_prod_vol\": pd.Series(dtype=\"float64\"),\n",
    "            \"oper_gas_prod_vol\": pd.Series(dtype=\"float64\"),\n",
    "            \"oper_cond_prod_vol\": pd.Series(dtype=\"float64\"),\n",
    "            \"oper_csgd_prod_vol\": pd.Series(dtype=\"float64\"),\n",
    "            \"prod_column\": pd.Series(dtype=\"object\"),\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Compute the result and sort by cycle_year_month\n",
    "result = topn_og_operator.compute().sort_values(\n",
    "    by=[\"cycle_year_month\", \"prod_column\"], ascending=False\n",
    ")\n",
    "result.reset_index().drop(columns=[\"level_1\", \"level_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lease cycle table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare result to if we had worked from the lease production table\n",
    "\n",
    "# create column for the total production to filter out the non-producing operators\n",
    "og_lease_cycle_ddf[\"total_lease_prod_vol\"] = (\n",
    "    og_lease_cycle_ddf[\"lease_oil_prod_vol\"]\n",
    "    + og_lease_cycle_ddf[\"lease_gas_prod_vol\"]\n",
    "    + og_lease_cycle_ddf[\"lease_cond_prod_vol\"]\n",
    "    + og_lease_cycle_ddf[\"lease_csgd_prod_vol\"]\n",
    ")\n",
    "\n",
    "# get the lease production table and filter out the rows with cycle_year_month > 202308 and 0 production\n",
    "filtered_og_lease_cycle_ddf = og_lease_cycle_ddf.loc[\n",
    "    (og_lease_cycle_ddf.cycle_year_month <= 202308)\n",
    "    & (og_lease_cycle_ddf[\"total_lease_prod_vol\"] > 0)\n",
    "]\n",
    "\n",
    "# group by the operator and the cycle_year_month and sum the prod_vol columns\n",
    "grouped_og_operator_no = (\n",
    "    filtered_og_lease_cycle_ddf[\n",
    "        [\n",
    "            \"cycle_year_month\",\n",
    "            \"operator_no\",\n",
    "            \"lease_oil_prod_vol\",\n",
    "            \"lease_gas_prod_vol\",\n",
    "            \"lease_cond_prod_vol\",\n",
    "            \"lease_csgd_prod_vol\",\n",
    "        ]\n",
    "    ]\n",
    "    .groupby([\"cycle_year_month\", \"operator_no\"])[\n",
    "        \"lease_oil_prod_vol\",\n",
    "        \"lease_gas_prod_vol\",\n",
    "        \"lease_cond_prod_vol\",\n",
    "        \"lease_csgd_prod_vol\",\n",
    "    ]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# active leases are those which have a production for 202308\n",
    "active_leases = (\n",
    "    filtered_og_lease_cycle_ddf[[\"cycle_year_month\", \"lease_no_district_no\"]][\n",
    "        filtered_og_lease_cycle_ddf[\"cycle_year_month\"] == 202308\n",
    "    ][\"lease_no_district_no\"]\n",
    "    .unique()\n",
    "    .compute()\n",
    ")\n",
    "\n",
    "# get the cumulative production for each of active_leases\n",
    "active_og_lease_cycle_ddf = filtered_og_lease_cycle_ddf[\n",
    "    filtered_og_lease_cycle_ddf[\"lease_no_district_no\"].isin(active_leases)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persisted_active_og_lease_cycle_ddf = active_og_lease_cycle_ddf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lease_prod_cols = [\n",
    "    \"lease_oil_prod_vol\",\n",
    "    \"lease_gas_prod_vol\",\n",
    "    \"lease_cond_prod_vol\",\n",
    "    \"lease_csgd_prod_vol\",\n",
    "]\n",
    "filtered_og_lease_cycle_ddf[\n",
    "    filtered_og_lease_cycle_ddf[\"lease_no_district_no\"] == 313711\n",
    "][lease_prod_cols + [\"cycle_year_month\", \"operator_no\"]].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lease_prod_cols = [\n",
    "    \"lease_oil_prod_vol\",\n",
    "    \"lease_gas_prod_vol\",\n",
    "    \"lease_cond_prod_vol\",\n",
    "    \"lease_csgd_prod_vol\",\n",
    "]\n",
    "active_lease_sums = (\n",
    "    persisted_active_og_lease_cycle_ddf.groupby(\"lease_no_district_no\")[lease_prod_cols]\n",
    "    .sum()\n",
    "    .compute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top producing leases\n",
    "for col in lease_prod_cols:\n",
    "    display(active_lease_sums.nlargest(10, col))\n",
    "# active_lease_sums.nlargest(10, \"lease_oil_prod_vol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_grouped_og_operator_no = grouped_og_operator_no.compute()\n",
    "\n",
    "lease_prod_cols = [\n",
    "    \"lease_oil_prod_vol\",\n",
    "    \"lease_gas_prod_vol\",\n",
    "    \"lease_cond_prod_vol\",\n",
    "    \"lease_csgd_prod_vol\",\n",
    "]\n",
    "\n",
    "# create a empty list to store the max rows\n",
    "max_rows = []\n",
    "# go through each of the prod_columns and get the max row for each cycle_year_month\n",
    "for col in lease_prod_cols:\n",
    "    computed_grouped_og_operator_no[\"prod_column\"] = col\n",
    "    max_index = computed_grouped_og_operator_no.groupby(\"cycle_year_month\")[\n",
    "        col\n",
    "    ].idxmax()\n",
    "\n",
    "    max_rows.append(computed_grouped_og_operator_no.loc[max_index])\n",
    "\n",
    "result = pd.concat(max_rows)\n",
    "# merge the operator_no_name table to get the operator_name\n",
    "result.merge(operator_no_name, on=\"operator_no\").sort_values(\n",
    "    by=[\"cycle_year_month\", \"prod_column\"], ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = client.scheduler_info()  # get scheduler info\n",
    "\n",
    "workers = info[\"workers\"]  # get the workers\n",
    "\n",
    "print(f\"Number of workers: {len(workers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
